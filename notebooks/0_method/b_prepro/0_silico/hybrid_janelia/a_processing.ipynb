{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "\n",
    "\n",
    "author: steeve.laquitaine@epfl.ch  \n",
    "date: 2023.09.08  \n",
    "last modified: 2023.09.08  \n",
    "status: OK  \n",
    "display-status: OK  \n",
    "regression: None  \n",
    "duration: 3 hours (first time)\n",
    "\n",
    "\n",
    "**Data description**:\n",
    "\n",
    "- Tetrode\n",
    "- drift and static\n",
    "\n",
    "## Setup\n",
    "\n",
    "create and activate env from `npx_10m_384ch_unit_classes.txt` (firing_rate ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "2023-09-08 17:54:53,670 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2023-09-08 17:54:53,681 - root - utils.py - get_config - INFO - Reading experiment config. - done\n"
     ]
    }
   ],
   "source": [
    "# listen to changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se \n",
    "import shutil \n",
    "import spikeforest as sf\n",
    "\n",
    "# move to project path\n",
    "PROJ_PATH = \"/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/bernstein_2023/\"\n",
    "os.chdir(PROJ_PATH)\n",
    "\n",
    "from src.nodes.utils import get_config\n",
    "from src.nodes.prepro import preprocess\n",
    "from src.nodes.truth.silico import ground_truth\n",
    "from src.nodes.load import load_campaign_params\n",
    "\n",
    "# SETUP PARAMETERS\n",
    "EXPERIMENT = \"buccino_2020\"   # the experiment \n",
    "SIMULATION_DATE = \"2020\"      # the run (date)\n",
    "data_conf, param_conf = get_config(EXPERIMENT, SIMULATION_DATE).values()\n",
    "NWB_PATH = data_conf[\"recording\"][\"input\"]\n",
    "WRITE_PATH = data_conf[\"probe_wiring\"][\"output\"]\n",
    "GT_SORTING_PATH = data_conf[\"sorting\"][\"simulation\"][\"ground_truth\"][\"input\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get raw data\n",
    "\n",
    "Raw data are already cast into a Recording file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Recording data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_drift_siprobe', 'hybrid_static_tetrode', 'hybrid_static_tetrode', 'hybrid_static_tetrode', 'hybrid_static_tetrode', 'hybrid_static_tetrode', 'hybrid_static_tetrode', 'hybrid_static_tetrode', 'hybrid_static_tetrode', 'hybrid_static_tetrode', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_static_siprobe', 'hybrid_drift_tetrode', 'hybrid_drift_tetrode', 'hybrid_drift_tetrode', 'hybrid_drift_tetrode', 'hybrid_drift_tetrode', 'hybrid_drift_tetrode', 'hybrid_drift_tetrode', 'hybrid_drift_tetrode', 'hybrid_drift_tetrode']\n"
     ]
    }
   ],
   "source": [
    "uri = 'sha1://43298d72b2d0860ae45fc9b0864137a976cb76e8?hybrid-janelia-spikeforest-recordings.json'\n",
    "\n",
    "# get recording\n",
    "all_recordings = sf.load_spikeforest_recordings(uri)\n",
    "\n",
    "study_name_all = []\n",
    "for ix in range(len(all_recordings)):\n",
    "    study_name = all_recordings[ix].study_name\n",
    "    study_name_all.append(study_name)\n",
    "\n",
    "print(study_name_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`IN PROGRESS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_name = all_recordings[rec_i].study_name\n",
    "# recording_name = all_recordings[rec_i].recording_name\n",
    "\n",
    "# # print(study_name)\n",
    "# # print(recording_name)\n",
    "# x = [\n",
    "#     R for R in all_recordings\n",
    "#     if R.study_name == study_name and R.recording_name == recording_name\n",
    "# ]\n",
    "# if len(x) == 0: raise Exception(f'Recording not found: {study_name}/{recording_name}')\n",
    "# R = x[0]\n",
    "\n",
    "# # load recording extractor\n",
    "# recording = R.get_recording_extractor()\n",
    "\n",
    "# # load ground truth sorting extractor\n",
    "# sorted_true = R.get_sorting_true_extractor()\n",
    "\n",
    "# # calculate firing rate\n",
    "# firing_rate = []\n",
    "# for unit_id in sorted_true.get_unit_ids():\n",
    "\n",
    "#     # get spike train\n",
    "#     st = sorted_true.get_unit_spike_train(unit_id=unit_id)\n",
    "\n",
    "#     # calculate firing rate\n",
    "#     firing_rate.append(len(st) / recording.get_total_duration())\n",
    "\n",
    "# print(\"unit count:\", len(sorted_true.get_unit_ids()))\n",
    "\n",
    "# # plot distribution \n",
    "# if plot:\n",
    "#     _, axis = plt.subplots(1,1,figsize=(5,2))\n",
    "#     axis.hist(firing_rate, bins=np.arange(0, 1.1*max(firing_rate), 0.1), width=0.2);\n",
    "#     axis.set_xticks(np.arange(0, 1.1*max(firing_rate), 1));\n",
    "#     axis.set_xlabel(\"firing rate (Hz)\");\n",
    "#     axis.set_ylabel(\"neuron (count)\");\n",
    "#     axis.spines[[\"right\", \"top\"]].set_visible(False)\n",
    "# return sorted_true, firing_rate\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wire probe to recording\n",
    "\n",
    "The probe is already wired to the recording made open sourced. We just cast the recording as a Spikeinterface RecordingExtractor for processing with SpikeInterface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess recording\n",
    "\n",
    "I found no indication that the data has been preprocessed from https://spikeinterface.github.io/blog/ground-truth-comparison-and-ensemble-sorting-of-a-synthetic-neuropixels-recording/ or https://dandiarchive.org/dandiset/000034 so I preprocess it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_binary_recording with n_jobs = 1 and chunk_size = None\n",
      "True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort ground truth spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/project/proj68/scratch/laquitai/2_bernstein_2023/envs/npx_10m_384ch_unit_classes/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/gpfs/bbp.cscs.ch/project/proj68/scratch/laquitai/2_bernstein_2023/envs/npx_10m_384ch_unit_classes/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'core' version 2.2.5 because version 2.6.0-alpha is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/gpfs/bbp.cscs.ch/project/proj68/scratch/laquitai/2_bernstein_2023/envs/npx_10m_384ch_unit_classes/lib/python3.9/site-packages/pynwb/ecephys.py:90: UserWarning: ElectricalSeries 'ElectricalSeries': The second dimension of data does not match the length of electrodes. Your data may be transposed.\n",
      "  warnings.warn(\"%s '%s': The second dimension of data does not match the length of electrodes. \"\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npx_10m_384ch_unit_classes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
