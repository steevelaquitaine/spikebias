{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time torch vs numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "activate Spikeinterf.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes 1 min\n",
    "# a = torch.normal(2, 3, size=(40000 * 600, 384))\n",
    "# a_array = a.cpu().detach().numpy()\n",
    "\n",
    "# # takes 7 min\n",
    "# b = np.random.normal(2, 3, size=(40000 * 600, 384))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiently add independent noise to an array\n",
    "\n",
    "* noise has RMS of 2 uV\n",
    "* 40 min at 40,000 Hz (40 * 60 * 40,0000)\n",
    "* warning: the node might not have sufficient memory to allocate, you can reduce n_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6m)\n",
    "n_sites = 384\n",
    "sfreq = 40000\n",
    "t_secs = 40 * 60  # 40 mins\n",
    "n_samples = t_secs * sfreq\n",
    "gain = 1000\n",
    "\n",
    "# simulate toy voltage signal\n",
    "device = torch.device(\"cuda:0\")\n",
    "signal = torch.normal(0, 3, size=(n_samples, n_sites))  # too large for GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* numpy solution is too slow (past 1 hour - 2h30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 74 mins and crashes ...\n",
    "# # noise\n",
    "# noise = np.random.normal(\n",
    "#     0,\n",
    "#     2,\n",
    "#     [384, n_samples],\n",
    "# )\n",
    "\n",
    "# # scale traces and add missing noise\n",
    "# noised = signal.T * gain + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* torch solution is much faster (10 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10m\n",
    "n_site = 384\n",
    "\n",
    "# zero - mean\n",
    "mean = torch.tensor([0], dtype=torch.float32)\n",
    "\n",
    "# missing noise stds\n",
    "l1_noise = torch.tensor(2.0).repeat(76)\n",
    "l23_noise = torch.tensor(3.0).repeat(76)\n",
    "l4_noise = torch.tensor(4.0).repeat(76)\n",
    "l5_noise = torch.tensor(5.0).repeat(76)\n",
    "l6_noise = torch.tensor(6.0).repeat(80)\n",
    "noise_std = torch.cat((l1_noise, l23_noise, l4_noise, l5_noise, l6_noise), dim=0)\n",
    "\n",
    "# create missing noise matrix\n",
    "missing_noise = torch.randn(n_samples, n_site) * noise_std + mean\n",
    "\n",
    "# add noise\n",
    "noisy = (signal.T * gain) + missing_noise.T\n",
    "\n",
    "# cast as numpy array\n",
    "noisy = noisy.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy traces\n",
    "traces = torch.normal(0, 3, size=(n_samples, n_sites))  # too large for GPU memory\n",
    "traces = traces.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get config\n",
    "NOISE_PATH = \"/gpfs/bbp.cscs.ch/project/proj85/scratch/laquitai/4_preprint_2023/dataeng/0_silico/neuropixels_lfp_10m_384ch_hex0_40Khz_2023_10_18/be011315-9555-493e-a59c-27f42d1058ed/campaign/preprocessed/missing_noise_\"\n",
    "\n",
    "# if already fitted data exist\n",
    "# return concatenated noise per layer\n",
    "noises = ()\n",
    "if os.path.isfile(NOISE_PATH + \"L1.npy\"):\n",
    "    noises += (np.load(NOISE_PATH + \"L1.npy\", allow_pickle=True).item(),)\n",
    "if os.path.isfile(NOISE_PATH + \"L2_3.npy\"):\n",
    "    noises += (np.load(NOISE_PATH + \"L2_3.npy\", allow_pickle=True).item(),)\n",
    "if os.path.isfile(NOISE_PATH + \"L4.npy\"):\n",
    "    noises += (np.load(NOISE_PATH + \"L4.npy\", allow_pickle=True).item(),)\n",
    "if os.path.isfile(NOISE_PATH + \"L5.npy\"):\n",
    "    noises += (np.load(NOISE_PATH + \"L5.npy\", allow_pickle=True).item(),)\n",
    "if os.path.isfile(NOISE_PATH + \"L6.npy\"):\n",
    "    noises += (np.load(NOISE_PATH + \"L6.npy\", allow_pickle=True).item(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "\n",
    "# gain_prms = dict()\n",
    "# gain_prms[\"gain_adjust\"] = 0.9\n",
    "\n",
    "\n",
    "# # get stored results for the best fit scaling factor and missing noise\n",
    "# # set seed for reproducibility\n",
    "# np.random.seed(noises[0][\"seed\"])\n",
    "\n",
    "# # make writable (40s/h recording)\n",
    "# fitted_traces = copy.copy(traces).T\n",
    "# nsites = traces.shape[1]\n",
    "# ntimepoints = traces.shape[0]\n",
    "\n",
    "# # - scale trace and add missing noise to each site\n",
    "# for ix, _ in enumerate(noises):\n",
    "\n",
    "#     # get sites, scaling factor and missing noise\n",
    "#     sites = noises[ix][\"layer_sites_ix\"]\n",
    "#     gain = noises[ix][\"gain\"] * gain_prms[\"gain_adjust\"]  # adjust gain\n",
    "#     missing_noise = noises[ix][\"missing_noise_rms\"]\n",
    "\n",
    "#     # reconstruct fitted missing noise traces\n",
    "#     missing_noise_traces = np.random.normal(\n",
    "#         0,\n",
    "#         missing_noise,\n",
    "#         [nsites, ntimepoints],\n",
    "#     )\n",
    "\n",
    "#     # scale traces and add missing noise\n",
    "#     fitted_traces[sites, :] = traces[:, sites].T * gain + missing_noise_traces[sites, :]\n",
    "\n",
    "#     # release memory\n",
    "#     del missing_noise_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noise_matrix(noises, n_sites, n_samples):\n",
    "\n",
    "    # set reproducibility\n",
    "    torch.manual_seed(noises[0][\"seed\"])\n",
    "    np.random.seed(noises[0][\"seed\"])\n",
    "\n",
    "    # assign noise rms to each site\n",
    "    # - zeros will be added to sites outside cortex (mean=0, std=0)\n",
    "    # - noise_rms is a column-vector of n sites\n",
    "    noise_rms = torch.tensor(0).repeat(n_sites, 1)\n",
    "    for ix, _ in enumerate(noises):\n",
    "        noise_rms[noises[ix][\"layer_sites_ix\"]] = noises[ix][\"missing_noise_rms\"]\n",
    "\n",
    "    # unit-test\n",
    "    assert all(np.isnan(noise_rms)) == False, \"there should be no nan values\"\n",
    "    return torch.randn(n_sites, n_samples) * noise_rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = torch.from_numpy(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create noise tensor\n",
    "n_sites = traces.shape[1]\n",
    "missing_noise = create_noise_matrix(noises, n_sites, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise and cast as array\n",
    "noisy = (traces.T * gain) + missing_noise\n",
    "noisy = noisy.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0., -0., 0.,  ..., 0., 0., 0.],\n",
       "        [-0., -0., 0.,  ..., -0., -0., 0.],\n",
       "        [0., -0., -0.,  ..., 0., 0., -0.],\n",
       "        ...,\n",
       "        [-0., 0., -0.,  ..., -0., 0., 0.],\n",
       "        [-0., -0., -0.,  ..., -0., -0., -0.],\n",
       "        [-0., 0., -0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikinterf0_100_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
