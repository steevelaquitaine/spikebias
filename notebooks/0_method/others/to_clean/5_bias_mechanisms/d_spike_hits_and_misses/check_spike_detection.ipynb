{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check true spikes detection stata\n",
    "\n",
    "author: steeve.laquitaine@epfl.ch\n",
    "\n",
    "\n",
    "Useful:  \n",
    "* Spikeinterface: \"For all pairs of GT unit and tested unit we first count how many events are matched within a delta_time tolerance (0.4 ms by default).\" (see ref 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtual env is `env_kilosort_silico`\n",
    "\n",
    "You should have extracted the templates from a KS3 run by running `python3.9 -m src.pipes.postpro.univ_temp` in the terminal before. See usage in `univ_temp` module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-25 21:29:55,371 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2023-05-25 21:29:55,394 - root - utils.py - get_config - INFO - Reading experiment config. - done\n"
     ]
    }
   ],
   "source": [
    "# SETUP PACKAGES \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spikeinterface import comparison\n",
    "\n",
    "# SET PROJECT PATH\n",
    "PROJ_PATH = \"/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting\"\n",
    "os.chdir(PROJ_PATH)\n",
    "\n",
    "\n",
    "# SETUP PROJECT PACKAGE\n",
    "from src.nodes.utils import get_config\n",
    "from src.nodes.truth.silico import ground_truth\n",
    "from src.nodes.io.silico import sorting\n",
    "from src.nodes.postpro import spike_detection, metrics\n",
    "\n",
    "\n",
    "# SET PARAMETERS\n",
    "EXPERIMENT = \"silico_neuropixels\"\n",
    "SIMULATION_DATE = \"2023_02_19\"\n",
    "SAMPLING_FREQ = 10000 # sample/sec\n",
    "\n",
    "\n",
    "# EXAMPLE UNIT PAIR MATCHED\n",
    "TRUE_UNIT = 19690\n",
    "SORTED_UNIT = 255\n",
    "\n",
    "# MATCHING PARAMETERS\n",
    "MATCH_WIND_MS = 0.4\n",
    "\n",
    "\n",
    "# SET CONFIG\n",
    "data_conf, param_conf = get_config(EXPERIMENT, SIMULATION_DATE).values()\n",
    "\n",
    "# SET PATHS \n",
    "CELL_MATCHING_PATH = data_conf[\"postprocessing\"][\"cell_matching\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the true/sorted spike hits for an example true unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-25 21:29:59,495 - root - ground_truth.py - load - INFO - loading already processed ground truth SortingExtractor ...\n",
      "2023-05-25 21:29:59,508 - root - ground_truth.py - load - INFO - loading already processed true sorting - done in 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sorted_ttps_hits': {1516374: [],\n",
       "  2553188: [],\n",
       "  2700057: [2700054],\n",
       "  2754658: [2754661],\n",
       "  4813134: []},\n",
       " 'all_sorted_ttps': array([    468,     571,     802, ..., 5499805, 5499815, 5499853]),\n",
       " 'unit_labels_for_sorted_ttps': array([297., 298., 219., ..., 184., 283.,  99.]),\n",
       " 'sorted_unit_hits': {1516374: [],\n",
       "  2553188: [],\n",
       "  2700057: [255],\n",
       "  2754658: [298],\n",
       "  4813134: []}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the MATCH_WIND_MS (0.4 ms in SpikeInterface) matching window in timepoints\n",
    "match_wind = int(MATCH_WIND_MS * SAMPLING_FREQ / 1000)\n",
    "\n",
    "# load precomputed ground truth extractor\n",
    "Truth = ground_truth.load(data_conf)\n",
    "\n",
    "# load precomputed Sorting extractor\n",
    "Sorting = sorting.load(data_conf)\n",
    "\n",
    "# detect hits between a single true unit and all sorted unit timestamps\n",
    "out = spike_detection.match_a_true_unit_spikes_to_all_sorted_spikes(true_unit_id=TRUE_UNIT, Truth=Truth, Sorting=Sorting, match_wind=match_wind)\n",
    "out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check spikes detection stata for example units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-25 21:30:01,315 - root - ground_truth.py - load - INFO - loading already processed ground truth SortingExtractor ...\n",
      "2023-05-25 21:30:01,325 - root - ground_truth.py - load - INFO - loading already processed true sorting - done in 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/src/nodes/postpro/spike_detection.py:149: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  dict([(k, pd.Series(v)) for k, v in hits_dict.items()])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>events</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1516374</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553188</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700057</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754658</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813134</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         detected\n",
       "events           \n",
       "1516374     False\n",
       "2553188     False\n",
       "2700057      True\n",
       "2754658      True\n",
       "4813134     False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the detection status for each spikes of the chosen true unit\n",
    "is_spike_detected = spike_detection.get_true_unit_spikes_detection_status(true_unit_id=TRUE_UNIT, data_conf=data_conf)\n",
    "is_spike_detected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check my agreement score vs. SpikeInterface's for a true/sorted match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/src/nodes/postpro/metrics.py:14: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  dict([(k, pd.Series(v)) for k, v in hits_dict.items()])\n"
     ]
    }
   ],
   "source": [
    "# get hit count\n",
    "hit_count = metrics.get_hit_counts_for_a_true_units(out)\n",
    "\n",
    "# get true unit's event count \n",
    "event_counts_truth = dict()\n",
    "event_counts_truth[TRUE_UNIT] = metrics.get_event_count_truth(unit_id=TRUE_UNIT, Truth=Truth)\n",
    "\n",
    "# get sorted unit's event count \n",
    "event_counts_sorting = dict()\n",
    "event_counts_sorting[SORTED_UNIT] = metrics.get_event_count_sorting(unit_id=SORTED_UNIT, Sorting=Sorting)\n",
    "\n",
    "# calculate agreement score\n",
    "agreement_score = metrics.get_agreement_score(TRUE_UNIT, SORTED_UNIT, hit_count, event_counts_truth, event_counts_sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that spikeinterface produces the same agreement score\n",
    "MatchingObject = comparison.compare_sorter_to_ground_truth(\n",
    "    Truth, Sorting, exhaustive_gt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "si_agreement_score = MatchingObject.agreement_scores.loc[TRUE_UNIT, SORTED_UNIT]\n",
    "assert si_agreement_score == agreement_score, \"Your agreement score differs from  SpikeInterface\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "(1) https://spikeinterface.readthedocs.io/en/0.96.1/module_comparison.html#compare-the-output-of-multiple-spike-sorters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_silico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
