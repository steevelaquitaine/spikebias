{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check spykingcircus2\n",
    "\n",
    "note: Buccino's spikeinterface version is older 0.9.9 while ours is 0.96.1, we updated the code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground-truth comparison and ensemble sorting of a synthetic Neuropixels recording\n",
    "This notebook reproduces figures 2 and 3 from the paper SpikeInterface, a unified framework for spike sorting.\n",
    "\n",
    "The data set for this notebook is available on the Dandi Archive: https://gui.dandiarchive.org/#/dandiset/000034.\n",
    "\n",
    "The entire data archive can be downloaded with the command dandi download https://gui.dandiarchive.org/#/dandiset/000034/draft (about 75GB).\n",
    "\n",
    "The data file required to run the code is:\n",
    "\n",
    "the raw data: sub-MEAREC-250neuron-Neuropixels_ecephys.nwb\n",
    "This file should be in the same directory where the notebook is located (otherwise adjust paths below).\n",
    "\n",
    "Author: Matthias Hennig, University of Edinburgh, 22 Aug 2020\n",
    "\n",
    "Requirements\n",
    "For this need you will need the following Python packages:\n",
    "\n",
    "* numpy\n",
    "* pandas\n",
    "* matplotlib\n",
    "* seaborn\n",
    "* spikeinterface\n",
    "* dandi\n",
    "* matplotlib-venn\n",
    "To run the MATLAB-based sorters, you would also need a MATLAB license. For other sorters, please refer to the documentation on how to [install sorters](https://spikeinterface.readthedocs.io/en/latest/install_sorters.html).\n",
    "\n",
    "1. Activate spack environment:\n",
    "\n",
    "```bash\n",
    "cd /gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/\n",
    "module load spack\n",
    ". /gpfs/bbp.cscs.ch/ssd/apps/bsd/2022-01-10/spack/share/spack/setup-env.sh\n",
    "spack env activate spack_env -p\n",
    "spack load python@3.9.7\n",
    "```\n",
    "\n",
    "2. Create and activate buccino_env:\n",
    "\n",
    "```bash\n",
    "python3.9 -m venv buccino_env\n",
    "source buccino_env/bin/activate\n",
    "pip3.9 install requirements_buccino.txt\n",
    "```\n",
    "\n",
    "3. Download `sub-MEAREC-250neuron-Neuropixels_ecephys.nwb` file (28 GB):\n",
    "\n",
    "```bash\n",
    "dandi download https://api.dandiarchive.org/api/assets/6d94dcf4-0b38-4323-8250-04fdc7039a66/download/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Access non-python sorters (for now only python ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscript_okxa1yg/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscript5t5ahx4s/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscriptaefkjqg6/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscript83hiqw1g/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscriptpj7dkfsw/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscriptylenu126/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscriptbr2h5i9v/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscript3sqhrcon/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscriptueig9mtz/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscript12bf9of7/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscriptj8f9t3nw/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscriptocjwchlu/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscriptqhmnzqdk/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscriptsucakvs3/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscriptnoz1vezt/script.sh\n",
      "RUNNING SHELL SCRIPT: /tmp/tmp_shellscriptxtgz3jhp/script.sh\n",
      "herdingspikes: 0.3.102\n",
      "spykingcircus: 1.1.0\n",
      "spykingcircus2: 2.0\n",
      "tridesclous: 1.6.5\n",
      "tridesclous2: 2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Matlab sorter paths:\n",
    "# change these to match your environment\n",
    "os.environ[\"IRONCLUST_PATH\"] = \"/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/sorters_package/ironclust/\"\n",
    "os.environ[\"KILOSORT2_PATH\"] = \"/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/sorters_package/Kilosort/\"\n",
    "os.environ[\"HDSORT_PATH\"] = \"/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/sorters_package/HDsort/\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from matplotlib_venn import venn3\n",
    "\n",
    "import spikeinterface as si\n",
    "import spikeinterface.full as si_full\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.comparison as sc\n",
    "from spikeinterface.comparison import GroundTruthStudy\n",
    "import spikeinterface.widgets as sw\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def clear_axes(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "# print version information\n",
    "# si.print_spikeinterface_version()\n",
    "si.sorters.installed_sorters()\n",
    "si.sorters.print_sorter_versions()\n",
    "\n",
    "MS_BEFORE = 3\n",
    "MS_AFTER = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up ground truth study an run all sorters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/buccino_env/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.5.1 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/buccino_env/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'core' version 2.2.5 because version 2.5.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/buccino_env/lib/python3.9/site-packages/pynwb/ecephys.py:90: UserWarning: ElectricalSeries 'ElectricalSeries': The second dimension of data does not match the length of electrodes. Your data may be transposed.\n",
      "  warnings.warn(\"%s '%s': The second dimension of data does not match the length of electrodes. \"\n"
     ]
    }
   ],
   "source": [
    "# WARNING !! (takes 50ish min the first time !)\n",
    "study_path = Path('/gpfs/bbp.cscs.ch/project/proj68/scratch/laquitai/raw/')\n",
    "data_path = Path('/gpfs/bbp.cscs.ch/project/proj68/scratch/laquitai/raw/')\n",
    "study_folder = study_path / 'study_mearec_250cells_Neuropixels-384chans_duration600s_noise10uV_2020-02-28/'\n",
    "\n",
    "# the original data\n",
    "# this NWB file contains both the ground truth spikes and the raw data\n",
    "data_filename = data_path / 'sub-MEAREC-250neuron-Neuropixels_ecephys.nwb'\n",
    "SX_gt = se.NwbSortingExtractor(str(data_filename))\n",
    "RX = se.NwbRecordingExtractor(str(data_filename))\n",
    "\n",
    "# bandpass (note: This is an update to the original code to enable waveform extraction)\n",
    "RX = si_full.bandpass_filter(RX, freq_min=300, freq_max=6000)\n",
    "\n",
    "# (slowest piece)\n",
    "if not os.path.isdir(study_folder):\n",
    "    gt_dict = {'rec0' : (RX, SX_gt) }\n",
    "    study = GroundTruthStudy.create(study_folder, gt_dict)\n",
    "else:\n",
    "    study = GroundTruthStudy(study_folder)\n",
    "\n",
    "# get Waveform extractor\n",
    "WaveformExtractor = study.get_waveform_extractor(RX)\n",
    "WaveformExtractor.set_params(ms_before=MS_BEFORE, ms_after=MS_AFTER)\n",
    "WaveformExtractor.run_extract_waveforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! The recording is already filtered, but herdingspikes filter is enabled\n",
      "# Generating new position and neighbor files from data file\n",
      "# Not Masking any Channels\n",
      "# Sampling rate: 32000\n",
      "# Localization On\n",
      "# Number of recorded channels: 384\n",
      "# Analysing frames: 19200000; Seconds: 600.0\n",
      "# Frames before spike in cutout: 10\n",
      "# Frames after spike in cutout: 58\n",
      "# tcuts: 42 90\n",
      "# tInc: 100000\n",
      "# Detection completed, time taken: 0:09:08.050980\n",
      "# Time per frame: 0:00:00.028544\n",
      "# Time per sample: 0:00:00.000074\n",
      "Loaded 661977 spikes.\n",
      "Fitting dimensionality reduction using all spikes...\n",
      "...projecting...\n",
      "...done\n",
      "Clustering...\n",
      "Clustering 661977 spikes...\n",
      "number of seeds: 3882\n",
      "seeds/job: 1942\n",
      "using 2 cpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running herdingspikes\n",
      "Warning! The recording is already filtered, but spykingcircus filter is enabled\n",
      "RUNNING SHELL SCRIPT: /gpfs/bbp.cscs.ch/project/proj68/scratch/laquitai/raw/study_mearec_250cells_Neuropixels-384chans_duration600s_noise10uV_2020-02-28/sorter_folders/rec0/spykingcircus/run_spykingcircus.sh\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/buccino_env/bin/spyking-circus\", line 5, in <module>\n",
      "\n",
      "    from circus.scripts.launch import main\n",
      "\n",
      "  File \"/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/buccino_env/lib/python3.9/site-packages/circus/scripts/launch.py\", line 31, in <module>\n",
      "\n",
      "    from circus.shared.files import data_stats\n",
      "\n",
      "  File \"/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/buccino_env/lib/python3.9/site-packages/circus/shared/files.py\", line 3, in <module>\n",
      "\n",
      "    from circus.shared.utils import get_tqdm_progressbar\n",
      "\n",
      "  File \"/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/buccino_env/lib/python3.9/site-packages/circus/shared/utils.py\", line 20, in <module>\n",
      "\n",
      "    from circus.shared.mpi import gather_array, all_gather_array, comm, SHARED_MEMORY\n",
      "\n",
      "  File \"/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/buccino_env/lib/python3.9/site-packages/circus/shared/mpi.py\", line 4, in <module>\n",
      "\n",
      "    from mpi4py import MPI\n",
      "\n",
      "ImportError: libmpi.so: cannot open shared object file: No such file or directory\n",
      "\n",
      "Error running spykingcircus\n"
     ]
    }
   ],
   "source": [
    "# sorting (10 min)\n",
    "sorter_list = ['herdingspikes', 'spykingcircus']\n",
    "sorter_names = ['HerdingSpikes', 'SpykingCircus']\n",
    "sorter_names_short = ['HS', 'SC']\n",
    "\n",
    "study.run_sorters(sorter_list, mode_if_folder_exists='keep', remove_sorter_folders=False, engine='loop', verbose=True)\n",
    "study.copy_sortings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute or load SNR for the ground truth units\n",
    "snr_file = study_folder / 'snr.npy'\n",
    "if os.path.isfile(snr_file):\n",
    "    snr = np.load(snr_file, allow_pickle=True)\n",
    "else:\n",
    "    print('computing snr')\n",
    "    ## note this is quite slow for a NWB file as the data is arranged as channels:time\n",
    "    ## it is faster to first write out a binary file in time:channels order\n",
    "    # snr = st.validation.compute_snrs(SX_gt, RX, apply_filter=False, verbose=False, \n",
    "    #                                  memmap=True, max_spikes_per_unit_for_snr=500)\n",
    "    snr = si.qualitymetrics.misc_metrics.compute_snrs(WaveformExtractor)\n",
    "    np.save(snr_file, snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WaveformExtractor = study.get_waveform_extractor(RX, sorter_name=[\"HerdingSpikes\"])\n",
    "study.run_comparisons(exhaustive_gt=True, match_score=0.1)\n",
    "for (rec_name, sorter_name), comp in study.comparisons.items():\n",
    "    print('*' * 10)\n",
    "    print(rec_name, sorter_name)\n",
    "    print(comp.count_score)  # raw counting of tp/fp/...\n",
    "    comp.print_summary()\n",
    "    perf_unit = comp.get_performance(method='by_unit')\n",
    "    perf_avg = comp.get_performance(method='pooled_with_average')\n",
    "    m = comp.get_confusion_matrix()\n",
    "    w_comp = sw.plot_agreement_matrix(comp)\n",
    "    w_comp.ax.set_title(rec_name  + ' - ' + sorter_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the ground truth comparison and summarise the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m study\u001b[39m.\u001b[39mrun_comparisons(exhaustive_gt\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, match_score\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[1;32m      2\u001b[0m comparisons \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mcomparisons\n\u001b[0;32m----> 3\u001b[0m dataframes \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39;49maggregate_dataframes()\n",
      "File \u001b[0;32m/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/buccino_env/lib/python3.9/site-packages/spikeinterface/comparison/groundtruthstudy.py:188\u001b[0m, in \u001b[0;36mGroundTruthStudy.aggregate_dataframes\u001b[0;34m(self, copy_into_folder, **karg_thresh)\u001b[0m\n\u001b[1;32m    186\u001b[0m dataframes \u001b[39m=\u001b[39m {}\n\u001b[1;32m    187\u001b[0m dataframes[\u001b[39m'\u001b[39m\u001b[39mrun_times\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregate_run_times()\u001b[39m.\u001b[39mreset_index()\n\u001b[0;32m--> 188\u001b[0m perfs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggregate_performance_by_unit()\n\u001b[1;32m    190\u001b[0m dataframes[\u001b[39m'\u001b[39m\u001b[39mperf_by_unit\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m perfs\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m    191\u001b[0m dataframes[\u001b[39m'\u001b[39m\u001b[39mcount_units\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregate_count_units(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkarg_thresh)\u001b[39m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/buccino_env/lib/python3.9/site-packages/spikeinterface/comparison/groundtruthstudy.py:149\u001b[0m, in \u001b[0;36mGroundTruthStudy.aggregate_performance_by_unit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m     perf \u001b[39m=\u001b[39m perf\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m    147\u001b[0m     perf_by_unit\u001b[39m.\u001b[39mappend(perf)\n\u001b[0;32m--> 149\u001b[0m perf_by_unit \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(perf_by_unit)\n\u001b[1;32m    150\u001b[0m perf_by_unit \u001b[39m=\u001b[39m perf_by_unit\u001b[39m.\u001b[39mset_index([\u001b[39m'\u001b[39m\u001b[39mrec_name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msorter_name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgt_unit_id\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    152\u001b[0m \u001b[39mreturn\u001b[39;00m perf_by_unit\n",
      "File \u001b[0;32m/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/buccino_env/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/buccino_env/lib/python3.9/site-packages/pandas/core/reshape/concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[1;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m    159\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39m    1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m         objs,\n\u001b[1;32m    370\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    371\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    372\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    373\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    374\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    375\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    376\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    377\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    378\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spike-sorting/buccino_env/lib/python3.9/site-packages/pandas/core/reshape/concat.py:425\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    422\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[1;32m    424\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 425\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    427\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "comparisons = study.comparisons\n",
    "dataframes = study.aggregate_dataframes()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "(1) https://spikeinterface.github.io/blog/ground-truth-comparison-and-ensemble-sorting-of-a-synthetic-neuropixels-recording/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buccino_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bf114060db2ff7312142305310b0bf8fc338fe57cf8bdc51d5f0778333d6120"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
