{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Download full recordings\n",
    "\n",
    "author: laquitainesteeve@gmail.com\n",
    "\n",
    "purpose: download all full recordings from Dandi Archive\n",
    "\n",
    "Execution time: \n",
    "- writing speed: maximize chunk_size, set to n_jobs=20. This maximizes speed while avoiding overhead [1].\n",
    "\n",
    "Hardware: CPU\n",
    "\n",
    "Tested on: 32 cores, 2TB storage, 188GB RAM Ubuntu machine\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Setup \n",
    "\n",
    "Activate virtual environment (envs/spikebias.yml)\n",
    "\n",
    "```bash\n",
    "python -m ipykernel install --user --name dandi --display-name \"dandi\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spikeinterface 0.101.2\n",
      "CPU times: user 533 ms, sys: 609 ms, total: 1.14 s\n",
      "Wall time: 477 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steeve/steeve/epfl/code/spikebias/envs/dandi/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# import python packages\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "import spikeinterface.extractors as se\n",
    "print(\"spikeinterface\", spikeinterface.__version__)\n",
    "\n",
    "# set the project path\n",
    "PROJ_PATH = \"/home/steeve/steeve/epfl/code/spikebias\"\n",
    "\n",
    "# set the raw dataset path\n",
    "RAW_DATASET = os.path.join(PROJ_PATH, \"dataset/00_raw/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"Data loader for dandi datasets\n",
    "    \"\"\"\n",
    "    def __init__(self, raw_dataset_path:str, dandiset_id:str, filepath:str, is_recording=True, is_sorting=True):\n",
    "        self.raw_dataset_path = raw_dataset_path\n",
    "        self.dandiset_id = dandiset_id\n",
    "        self.filepath = filepath\n",
    "        self.is_recording = is_recording\n",
    "        self.is_sorting = is_sorting        \n",
    "        self.recording = None\n",
    "        self.sorting = None\n",
    "        self.s3_path = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \n",
    "        # Get the file path on S3\n",
    "        with DandiAPIClient() as client:\n",
    "            asset = client.get_dandiset(self.dandiset_id, 'draft').get_asset_by_path(self.filepath)\n",
    "            self.s3_path = asset.get_content_url(follow_redirects=1, strip_query=True)\n",
    "        print(\"s3_path:\", self.s3_path)\n",
    "\n",
    "        # Get RecordingExtractor and SortingExtractor\n",
    "        if self.is_recording:\n",
    "            self.recording = se.NwbRecordingExtractor(file_path=self.s3_path, stream_mode=\"remfile\")\n",
    "        if self.is_sorting:\n",
    "            self.sorting = se.NwbSortingExtractor(file_path=self.s3_path, stream_mode=\"remfile\")\n",
    "\n",
    "        # Report\n",
    "        print('\\nDownloaded recording:', self.recording)\n",
    "        print('\\nDownloaded sorting:', self.sorting)\n",
    "\n",
    "    def save_data(self, recording_folder:str, sorting_folder:str, n_jobs=30, chunk_size=800000, dtype='float32', duration_secs=None):\n",
    "        if self.is_recording:\n",
    "            if duration_secs: \n",
    "                self.recording = self.recording.frame_slice(start_frame=0, end_frame=self.recording.sampling_frequency*duration_secs)\n",
    "            self.recording.save(folder=recording_folder, n_jobs=n_jobs, verbose=True, progress_bar=True, overwrite=True, dtype=dtype, chunk_size=chunk_size)                \n",
    "\n",
    "        if self.is_sorting:\n",
    "            if duration_secs: \n",
    "                self.sorting = self.sorting.frame_slice(start_frame=0, end_frame=self.recording.sampling_frequency*duration_secs)\n",
    "            self.sorting.save(folder=sorting_folder, progress_bar=True, overwrite=True)\n",
    "        \n",
    "        # Report\n",
    "        print('\\nSaved recording:', self.recording)\n",
    "        print('\\nSaved sorting:', self.sorting)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPX spont biophy\n",
    "\n",
    "- execution time: 50 min for 34:30 min\n",
    "- storage: 117 GB (full 34.30 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_path: https://dandiarchive.s3.amazonaws.com/blobs/0c3/2c4/0c32c475-1251-485b-9934-83667b3ba4ba\n",
      "\n",
      "Downloaded recording: NwbRecordingExtractor: 384 channels - 40.0kHz - 1 segments - 82,319,958 samples \n",
      "                       2,058.00s (34.30 minutes) - float32 dtype - 117.76 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/0c3/2c4/0c32c475-1251-485b-9934-83667b3ba4ba\n",
      "\n",
      "Downloaded sorting: NwbSortingExtractor: 1388 units - 1 segments - 40.0kHz\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/0c3/2c4/0c32c475-1251-485b-9934-83667b3ba4ba\n",
      "write_binary_recording \n",
      "n_jobs=30 - samples_per_chunk=800,000 - chunk_memory=1.14 GiB - total_memory=34.33 GiB - chunk_duration=20.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording: 100%|██████████| 103/103 [50:11<00:00, 29.23s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved recording: NwbRecordingExtractor: 384 channels - 40.0kHz - 1 segments - 82,319,958 samples \n",
      "                       2,058.00s (34.30 minutes) - float32 dtype - 117.76 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/0c3/2c4/0c32c475-1251-485b-9934-83667b3ba4ba\n",
      "\n",
      "Saved sorting: NwbSortingExtractor: 1388 units - 1 segments - 40.0kHz\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/0c3/2c4/0c32c475-1251-485b-9934-83667b3ba4ba\n",
      "CPU times: user 546 ms, sys: 261 ms, total: 807 ms\n",
      "Wall time: 50min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set dataset parameters\n",
    "dandiset_id = '001250'\n",
    "filepath = 'sub-001-fitted/sub-001-fitted_ecephys.nwb'\n",
    "recording_folder = os.path.join(RAW_DATASET, \"recording_npx_spont\")\n",
    "sorting_folder = os.path.join(RAW_DATASET, \"sorting_npx_spont\")\n",
    "#DURATION_SECS = 1800 # 30 min\n",
    "\n",
    "# download and save dataset (full 3h40)\n",
    "data_loader = DataLoader(raw_dataset_path=RAW_DATASET, dandiset_id=dandiset_id, filepath=filepath)\n",
    "data_loader.load_data() # Load the data\n",
    "#data_loader.save_data(recording_folder=recording_folder, sorting_folder=sorting_folder, n_jobs=30, chunk_size=800000, dtype='float32', duration_secs=DURATION_SECS) # save\n",
    "data_loader.save_data(recording_folder=recording_folder, sorting_folder=sorting_folder, n_jobs=30, chunk_size=800000, dtype='float32') # save full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPX evoked biophy\n",
    "\n",
    "- Execution time: 44 min for 60 min recording\n",
    "- storage: 103 GB (full 1 hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_path: https://dandiarchive.s3.amazonaws.com/blobs/9d6/6ed/9d66ed40-af31-43aa-b4ba-246d2206dcad\n",
      "\n",
      "Downloaded recording: NwbRecordingExtractor: 384 channels - 20.0kHz - 1 segments - 72,359,964 samples \n",
      "                       3,618.00s (1.00 hours) - float32 dtype - 103.51 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/9d6/6ed/9d66ed40-af31-43aa-b4ba-246d2206dcad\n",
      "\n",
      "Downloaded sorting: NwbSortingExtractor: 1836 units - 1 segments - 20.0kHz\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/9d6/6ed/9d66ed40-af31-43aa-b4ba-246d2206dcad\n",
      "write_binary_recording \n",
      "n_jobs=30 - samples_per_chunk=800,000 - chunk_memory=1.14 GiB - total_memory=34.33 GiB - chunk_duration=40.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording: 100%|██████████| 91/91 [43:38<00:00, 28.77s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved recording: NwbRecordingExtractor: 384 channels - 20.0kHz - 1 segments - 72,359,964 samples \n",
      "                       3,618.00s (1.00 hours) - float32 dtype - 103.51 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/9d6/6ed/9d66ed40-af31-43aa-b4ba-246d2206dcad\n",
      "\n",
      "Saved sorting: NwbSortingExtractor: 1836 units - 1 segments - 20.0kHz\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/9d6/6ed/9d66ed40-af31-43aa-b4ba-246d2206dcad\n",
      "CPU times: user 1.07 s, sys: 446 ms, total: 1.52 s\n",
      "Wall time: 44min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set dataset parameters\n",
    "dandiset_id = '001250'\n",
    "filepath = 'sub-002-fitted/sub-002-fitted_ecephys.nwb'\n",
    "recording_folder = os.path.join(RAW_DATASET, \"recording_npx_evoked\")\n",
    "sorting_folder = os.path.join(RAW_DATASET, \"sorting_npx_evoked\")\n",
    "#DURATION_SECS = 3600 # 60 min\n",
    "\n",
    "# download and save dataset\n",
    "data_loader = DataLoader(raw_dataset_path=RAW_DATASET, dandiset_id=dandiset_id, filepath=filepath)\n",
    "data_loader.load_data() # Load the data\n",
    "#data_loader.save_data(recording_folder=recording_folder, sorting_folder=sorting_folder, n_jobs=30, chunk_size=800000, dtype='float32', duration_secs=DURATION_SECS) # save\n",
    "data_loader.save_data(recording_folder=recording_folder, sorting_folder=sorting_folder, n_jobs=30, chunk_size=800000, dtype='float32') # save full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense depth 1 biophy\n",
    "\n",
    "Execution time: 62 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_path: https://dandiarchive.s3.amazonaws.com/blobs/dec/e65/dece6568-cee4-4ade-80bf-c1166a03fe2a\n",
      "\n",
      "Downloaded recording: NwbRecordingExtractor: 128 channels - 20.0kHz - 1 segments - 34,299,965 samples \n",
      "                       1,715.00s (28.58 minutes) - float32 dtype - 16.36 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/dec/e65/dece6568-cee4-4ade-80bf-c1166a03fe2a\n",
      "\n",
      "Downloaded sorting: NwbSortingExtractor: 287 units - 1 segments - 20.0kHz\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/dec/e65/dece6568-cee4-4ade-80bf-c1166a03fe2a\n",
      "write_binary_recording \n",
      "n_jobs=30 - samples_per_chunk=800,000 - chunk_memory=390.62 MiB - total_memory=11.44 GiB - chunk_duration=40.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording: 100%|██████████| 43/43 [1:02:08<00:00, 86.72s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved recording: NwbRecordingExtractor: 128 channels - 20.0kHz - 1 segments - 34,299,965 samples \n",
      "                       1,715.00s (28.58 minutes) - float32 dtype - 16.36 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/dec/e65/dece6568-cee4-4ade-80bf-c1166a03fe2a\n",
      "\n",
      "Saved sorting: NwbSortingExtractor: 287 units - 1 segments - 20.0kHz\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/dec/e65/dece6568-cee4-4ade-80bf-c1166a03fe2a\n",
      "CPU times: user 187 ms, sys: 128 ms, total: 315 ms\n",
      "Wall time: 1h 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# set dataset parameters\n",
    "dandiset_id = '001250'\n",
    "filepath = 'sub-003-fitted/sub-003-fitted_ecephys.nwb'\n",
    "recording_folder = os.path.join(RAW_DATASET, \"recording_dense_probe1\")\n",
    "sorting_folder = os.path.join(RAW_DATASET, \"sorting_dense_probe1\")\n",
    "\n",
    "# download and save dataset\n",
    "data_loader = DataLoader(raw_dataset_path=RAW_DATASET, dandiset_id=dandiset_id, filepath=filepath)\n",
    "data_loader.load_data() # Load the data\n",
    "data_loader.save_data(recording_folder=recording_folder, sorting_folder=sorting_folder, n_jobs=30, chunk_size=800000, dtype='float32') # save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense depth 2 biophy\n",
    "\n",
    "Execution time: 12 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_path: https://dandiarchive.s3.amazonaws.com/blobs/eef/9e9/eef9e95c-fb5b-46d2-a24c-878d8170b5e0\n",
      "\n",
      "Downloaded recording: NwbRecordingExtractor: 128 channels - 20.0kHz - 1 segments - 23,519,976 samples \n",
      "                       1,176.00s (19.60 minutes) - float32 dtype - 11.22 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/eef/9e9/eef9e95c-fb5b-46d2-a24c-878d8170b5e0\n",
      "\n",
      "Downloaded sorting: NwbSortingExtractor: 770 units - 1 segments - 20.0kHz\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/eef/9e9/eef9e95c-fb5b-46d2-a24c-878d8170b5e0\n",
      "write_binary_recording \n",
      "n_jobs=30 - samples_per_chunk=800,000 - chunk_memory=390.62 MiB - total_memory=11.44 GiB - chunk_duration=40.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording: 100%|██████████| 30/30 [12:42<00:00, 25.41s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved recording: NwbRecordingExtractor: 128 channels - 20.0kHz - 1 segments - 23,519,976 samples \n",
      "                       1,176.00s (19.60 minutes) - float32 dtype - 11.22 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/eef/9e9/eef9e95c-fb5b-46d2-a24c-878d8170b5e0\n",
      "\n",
      "Saved sorting: NwbSortingExtractor: 770 units - 1 segments - 20.0kHz\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/eef/9e9/eef9e95c-fb5b-46d2-a24c-878d8170b5e0\n",
      "CPU times: user 255 ms, sys: 107 ms, total: 363 ms\n",
      "Wall time: 12min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# set dataset parameters\n",
    "dandiset_id = '001250'\n",
    "filepath = 'sub-004-fitted/sub-004-fitted_ecephys.nwb'\n",
    "recording_folder = os.path.join(RAW_DATASET, \"recording_dense_probe2\")\n",
    "sorting_folder = os.path.join(RAW_DATASET, \"sorting_dense_probe2\")\n",
    "\n",
    "# download and save dataset\n",
    "data_loader = DataLoader(raw_dataset_path=RAW_DATASET, dandiset_id=dandiset_id, filepath=filepath)\n",
    "data_loader.load_data() # Load the data\n",
    "data_loader.save_data(recording_folder=recording_folder, sorting_folder=sorting_folder, n_jobs=30, chunk_size=800000, dtype='float32') # save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense depth 3 biophy\n",
    "\n",
    "Execution time: 26 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_path: https://dandiarchive.s3.amazonaws.com/blobs/ee2/816/ee2816de-d861-4b55-9cde-416a52e54049\n",
      "\n",
      "Downloaded recording: NwbRecordingExtractor: 128 channels - 20.0kHz - 1 segments - 35,279,964 samples \n",
      "                       1,764.00s (29.40 minutes) - float32 dtype - 16.82 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/ee2/816/ee2816de-d861-4b55-9cde-416a52e54049\n",
      "\n",
      "Downloaded sorting: NwbSortingExtractor: 1123 units - 1 segments - 20.0kHz\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/ee2/816/ee2816de-d861-4b55-9cde-416a52e54049\n",
      "write_binary_recording \n",
      "n_jobs=30 - samples_per_chunk=800,000 - chunk_memory=390.62 MiB - total_memory=11.44 GiB - chunk_duration=40.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording: 100%|██████████| 45/45 [26:28<00:00, 35.29s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved recording: NwbRecordingExtractor: 128 channels - 20.0kHz - 1 segments - 35,279,964 samples \n",
      "                       1,764.00s (29.40 minutes) - float32 dtype - 16.82 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/ee2/816/ee2816de-d861-4b55-9cde-416a52e54049\n",
      "\n",
      "Saved sorting: NwbSortingExtractor: 1123 units - 1 segments - 20.0kHz\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/ee2/816/ee2816de-d861-4b55-9cde-416a52e54049\n",
      "CPU times: user 428 ms, sys: 115 ms, total: 543 ms\n",
      "Wall time: 26min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# set dataset parameters\n",
    "dandiset_id = '001250'\n",
    "filepath = 'sub-005-fitted/sub-005-fitted_ecephys.nwb'\n",
    "recording_folder = os.path.join(RAW_DATASET, \"recording_dense_probe3\")\n",
    "sorting_folder = os.path.join(RAW_DATASET, \"sorting_dense_probe3\")\n",
    "\n",
    "# download and save dataset\n",
    "data_loader = DataLoader(raw_dataset_path=RAW_DATASET, dandiset_id=dandiset_id, filepath=filepath)\n",
    "data_loader.load_data() # Load the data\n",
    "data_loader.save_data(recording_folder=recording_folder, sorting_folder=sorting_folder, n_jobs=30, chunk_size=800000, dtype='float32') # save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marques-Smith\n",
    "\n",
    "- Execution time: 10 min (for full 20.25 min)\n",
    "- Storage: 26 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_path: https://dandiarchive.s3.amazonaws.com/blobs/109/db6/109db6a7-500b-4e59-83ca-8422c27137cf\n",
      "\n",
      "Downloaded recording: NwbRecordingExtractor: 384 channels - 30.0kHz - 1 segments - 36,451,538 samples \n",
      "                       1,215.05s (20.25 minutes) - int16 dtype - 26.07 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/109/db6/109db6a7-500b-4e59-83ca-8422c27137cf\n",
      "\n",
      "Downloaded sorting: None\n",
      "write_binary_recording \n",
      "n_jobs=30 - samples_per_chunk=800,000 - chunk_memory=585.94 MiB - total_memory=17.17 GiB - chunk_duration=26.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording: 100%|██████████| 46/46 [09:56<00:00, 12.97s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved recording: NwbRecordingExtractor: 384 channels - 30.0kHz - 1 segments - 36,451,538 samples \n",
      "                       1,215.05s (20.25 minutes) - int16 dtype - 26.07 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/109/db6/109db6a7-500b-4e59-83ca-8422c27137cf\n",
      "\n",
      "Saved sorting: None\n",
      "CPU times: user 120 ms, sys: 154 ms, total: 275 ms\n",
      "Wall time: 10min\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# set dataset parameters\n",
    "dandiset_id = '001250'\n",
    "filepath = 'sub-vivo-marques-smith/sub-vivo-marques-smith_ecephys.nwb'\n",
    "recording_folder = os.path.join(RAW_DATASET, \"recording_marques_smith\")\n",
    "sorting_folder = None\n",
    "\n",
    "# download and save dataset\n",
    "data_loader = DataLoader(raw_dataset_path=RAW_DATASET, dandiset_id=dandiset_id, filepath=filepath, is_sorting=False)\n",
    "data_loader.load_data() # Load the data\n",
    "data_loader.save_data(recording_folder=recording_folder, sorting_folder=sorting_folder, n_jobs=30, chunk_size=800000, dtype='float32') # save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horvath depth 1\n",
    "\n",
    "execution time: 21 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_path: https://dandiarchive.s3.amazonaws.com/blobs/10a/c1a/10ac1a40-6918-4eea-b80c-d887bad92ae9\n",
      "\n",
      "Downloaded recording: NwbRecordingExtractor: 128 channels - 20.0kHz - 1 segments - 72,131,040 samples \n",
      "                       3,606.55s (1.00 hours) - int16 dtype - 17.20 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/10a/c1a/10ac1a40-6918-4eea-b80c-d887bad92ae9\n",
      "\n",
      "Downloaded sorting: None\n",
      "write_binary_recording \n",
      "n_jobs=30 - samples_per_chunk=800,000 - chunk_memory=195.31 MiB - total_memory=5.72 GiB - chunk_duration=40.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording: 100%|██████████| 91/91 [21:29<00:00, 14.17s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved recording: NwbRecordingExtractor: 128 channels - 20.0kHz - 1 segments - 72,131,040 samples \n",
      "                       3,606.55s (1.00 hours) - int16 dtype - 17.20 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/10a/c1a/10ac1a40-6918-4eea-b80c-d887bad92ae9\n",
      "\n",
      "Saved sorting: None\n",
      "CPU times: user 124 ms, sys: 126 ms, total: 251 ms\n",
      "Wall time: 21min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# set dataset parameters\n",
    "dandiset_id = '001250'\n",
    "filepath = 'sub-vivo-horvath-depth-1/sub-vivo-horvath-depth-1_ecephys.nwb'\n",
    "recording_folder = os.path.join(RAW_DATASET, \"recording_horvath_probe1\")\n",
    "sorting_folder = None\n",
    "\n",
    "# download and save dataset\n",
    "data_loader = DataLoader(raw_dataset_path=RAW_DATASET, dandiset_id=dandiset_id, filepath=filepath, is_sorting=False)\n",
    "data_loader.load_data() # Load the data\n",
    "data_loader.save_data(recording_folder=recording_folder, sorting_folder=sorting_folder, n_jobs=30, chunk_size=800000, dtype='float32') # save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horvath depth 2\n",
    "\n",
    "-Execution time: 56 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_path: https://dandiarchive.s3.amazonaws.com/blobs/4d2/875/4d2875ba-d83b-44d5-9036-74f42e19e8a0\n",
      "\n",
      "Downloaded recording: NwbRecordingExtractor: 128 channels - 20.0kHz - 1 segments - 73,773,360 samples \n",
      "                       3,688.67s (1.02 hours) - int16 dtype - 17.59 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/4d2/875/4d2875ba-d83b-44d5-9036-74f42e19e8a0\n",
      "\n",
      "Downloaded sorting: None\n",
      "write_binary_recording \n",
      "n_jobs=30 - samples_per_chunk=800,000 - chunk_memory=195.31 MiB - total_memory=5.72 GiB - chunk_duration=40.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording: 100%|██████████| 93/93 [56:00<00:00, 36.13s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved recording: NwbRecordingExtractor: 128 channels - 20.0kHz - 1 segments - 73,773,360 samples \n",
      "                       3,688.67s (1.02 hours) - int16 dtype - 17.59 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/4d2/875/4d2875ba-d83b-44d5-9036-74f42e19e8a0\n",
      "\n",
      "Saved sorting: None\n",
      "CPU times: user 129 ms, sys: 120 ms, total: 250 ms\n",
      "Wall time: 56min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# set dataset parameters\n",
    "dandiset_id = '001250'\n",
    "filepath = 'sub-vivo-horvath-depth-2/sub-vivo-horvath-depth-2_ecephys.nwb'\n",
    "recording_folder = os.path.join(RAW_DATASET, \"recording_horvath_probe2\")\n",
    "sorting_folder = None\n",
    "\n",
    "# download and save dataset\n",
    "data_loader = DataLoader(raw_dataset_path=RAW_DATASET, dandiset_id=dandiset_id, filepath=filepath, is_sorting=False)\n",
    "data_loader.load_data() # Load the data\n",
    "data_loader.save_data(recording_folder=recording_folder, sorting_folder=sorting_folder, n_jobs=30, chunk_size=800000, dtype='float32') # save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horvath depth 3\n",
    "\n",
    "Execution time: 11 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_path: https://dandiarchive.s3.amazonaws.com/blobs/14a/205/14a205ea-306f-47fd-97e8-284a6f00626b\n",
      "\n",
      "Downloaded recording: NwbRecordingExtractor: 128 channels - 20.0kHz - 1 segments - 72,061,920 samples \n",
      "                       3,603.10s (1.00 hours) - int16 dtype - 17.18 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/14a/205/14a205ea-306f-47fd-97e8-284a6f00626b\n",
      "\n",
      "Downloaded sorting: None\n",
      "write_binary_recording \n",
      "n_jobs=30 - samples_per_chunk=800,000 - chunk_memory=195.31 MiB - total_memory=5.72 GiB - chunk_duration=40.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording: 100%|██████████| 91/91 [11:38<00:00,  7.68s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved recording: NwbRecordingExtractor: 128 channels - 20.0kHz - 1 segments - 72,061,920 samples \n",
      "                       3,603.10s (1.00 hours) - int16 dtype - 17.18 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/14a/205/14a205ea-306f-47fd-97e8-284a6f00626b\n",
      "\n",
      "Saved sorting: None\n",
      "CPU times: user 106 ms, sys: 146 ms, total: 252 ms\n",
      "Wall time: 11min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# set dataset parameters\n",
    "dandiset_id = '001250'\n",
    "filepath = 'sub-vivo-horvath-depth-3/sub-vivo-horvath-depth-3_ecephys.nwb'\n",
    "recording_folder = os.path.join(RAW_DATASET, \"recording_horvath_probe3\")\n",
    "sorting_folder = None\n",
    "\n",
    "# download and save dataset\n",
    "data_loader = DataLoader(raw_dataset_path=RAW_DATASET, dandiset_id=dandiset_id, filepath=filepath, is_sorting=False)\n",
    "data_loader.load_data() # Load the data\n",
    "data_loader.save_data(recording_folder=recording_folder, sorting_folder=sorting_folder, n_jobs=30, chunk_size=800000, dtype='float32') # save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_path: https://dandiarchive.s3.amazonaws.com/blobs/465/9c0/4659c033-b336-4b8b-b947-77434cebf494\n",
      "\n",
      " NwbRecordingExtractor: 384 channels - 32.0kHz - 1 segments - 19,200,000 samples \n",
      "                       600.00s (10.00 minutes) - float32 dtype - 27.47 GiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/465/9c0/4659c033-b336-4b8b-b947-77434cebf494\n",
      "\n",
      " NwbSortingExtractor: 250 units - 1 segments - 32.0kHz\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/465/9c0/4659c033-b336-4b8b-b947-77434cebf494\n",
      "write_binary_recording \n",
      "n_jobs=30 - samples_per_chunk=800,000 - chunk_memory=1.14 GiB - total_memory=34.33 GiB - chunk_duration=25.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording: 100%|██████████| 24/24 [10:01:15<00:00, 1503.14s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.52 s, sys: 448 ms, total: 1.96 s\n",
      "Wall time: 10h 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# set dataset parameters\n",
    "dandiset_id = '000034'\n",
    "filepath = 'sub-MEAREC-250neuron-Neuropixels/sub-MEAREC-250neuron-Neuropixels_ecephys.nwb'\n",
    "recording_folder = os.path.join(RAW_DATASET, \"recording_buccino\")\n",
    "sorting_folder = os.path.join(RAW_DATASET, \"sorting_buccino\")\n",
    "\n",
    "# download and save dataset\n",
    "data_loader = DataLoader(raw_dataset_path=RAW_DATASET, dandiset_id=dandiset_id, filepath=filepath)\n",
    "data_loader.load_data() # Load the data\n",
    "data_loader.save_data(recording_folder=recording_folder, sorting_folder=sorting_folder, n_jobs=30, chunk_size=800000, dtype='float32') # save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-cell isolated traces with Reyes probe \n",
    "\n",
    "- 40 second recording\n",
    "- Execution time: 4 min\n",
    "- size: 390.62 MB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_path: https://dandiarchive.s3.amazonaws.com/blobs/2f3/edc/2f3edc58-b09e-4571-bb1c-1ffb2f768b57\n",
      "\n",
      "Downloaded recording: NwbRecordingExtractor: 128 channels - 20.0kHz - 1 segments - 799,900 samples - 39.99s \n",
      "                       float32 dtype - 390.58 MiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/2f3/edc/2f3edc58-b09e-4571-bb1c-1ffb2f768b57\n",
      "\n",
      "Downloaded sorting: NwbSortingExtractor: 1 units - 1 segments - 20.0kHz\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/2f3/edc/2f3edc58-b09e-4571-bb1c-1ffb2f768b57\n",
      "write_binary_recording \n",
      "n_jobs=30 - samples_per_chunk=800,000 - chunk_memory=390.62 MiB - total_memory=11.44 GiB - chunk_duration=40.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording: 100%|██████████| 1/1 [04:27<00:00, 267.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved recording: NwbRecordingExtractor: 128 channels - 20.0kHz - 1 segments - 799,900 samples - 39.99s \n",
      "                       float32 dtype - 390.58 MiB\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/2f3/edc/2f3edc58-b09e-4571-bb1c-1ffb2f768b57\n",
      "\n",
      "Saved sorting: NwbSortingExtractor: 1 units - 1 segments - 20.0kHz\n",
      "  file_path: https://dandiarchive.s3.amazonaws.com/blobs/2f3/edc/2f3edc58-b09e-4571-bb1c-1ffb2f768b57\n",
      "CPU times: user 129 ms, sys: 33.8 ms, total: 163 ms\n",
      "Wall time: 4min 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set dataset parameters\n",
    "dandiset_id = '001250'\n",
    "filepath = 'sub-biophy-isolated-traces-reyes/sub-biophy-isolated-traces-reyes_ses-006_ecephys.nwb'\n",
    "recording_folder = os.path.join(RAW_DATASET, \"recording_reyes_isolated_traces\")\n",
    "sorting_folder = os.path.join(RAW_DATASET, \"sorting_reyes_isolated_traces\")\n",
    "\n",
    "# download and save dataset\n",
    "data_loader = DataLoader(raw_dataset_path=RAW_DATASET, dandiset_id=dandiset_id, filepath=filepath)\n",
    "data_loader.load_data() # Load the data\n",
    "data_loader.save_data(recording_folder=recording_folder, sorting_folder=sorting_folder, n_jobs=30, chunk_size=800000, dtype='float32') # save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] https://github.com/SpikeInterface/spikeinterface/issues/3252\n",
    "* effect of n_jobs and chunk_size on writing speed:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
