{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amplitude-to-noise ratio\n",
    "\n",
    "author: laquitainesteeve@gmail.com\n",
    "\n",
    "Purpose: describe trace amplitude-to-noise ratio\n",
    "\n",
    "Execution time: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Create, activate and select virtual environment kernel `demo` from (envs/demo.yml):\n",
    "\n",
    "```bash\n",
    "python -m ipykernel install --user --name demo --display-name \"demo\" # create kernel\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "spikeinterface version: 0.101.2\n",
      "2025-04-06 08:34:33,207 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2025-04-06 08:34:33,255 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2025-04-06 08:34:33,259 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2025-04-06 08:34:33,288 - root - utils.py - get_config - INFO - Reading experiment config. - done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# import packages\n",
    "import os\n",
    "import numpy as np\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface as si\n",
    "from matplotlib import pyplot as plt;\n",
    "import multiprocessing\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "print(\"spikeinterface version:\", si.__version__)\n",
    "\n",
    "# dandiset parameters\n",
    "dandiset_id = '001250'\n",
    "filepath_evoked = 'sub-demo-npx-bio-evoked/sub-demo-npx-bio-evoked_ecephys.nwb'\n",
    "filepath_spont = 'sub-demo-npx-bio-spont/sub-demo-npx-bio-spont_ecephys.nwb'\n",
    "\n",
    "# project path\n",
    "#proj_path = \"/Users/steeve_laquitaine/Desktop/EPFL/2022_2024_bbp/spikebias/\"\n",
    "proj_path = \"/home/jovyan/steevelaquitaine/spikebias/\"\n",
    "os.chdir(proj_path)\n",
    "\n",
    "from src.nodes.utils import get_config\n",
    "from src.nodes.validation import snr\n",
    "from src.nodes.validation import amplitude\n",
    "\n",
    "# evoked demo\n",
    "cfg_e, param_cfg_e = get_config(\"silico_neuropixels\", \"npx_evoked\").values() # config\n",
    "FREQ_MIN_E = param_cfg_e[\"run\"][\"preprocessing\"][\"min_filter_freq\"] # preprocessing parameters\n",
    "FREQ_MAX_E = param_cfg_e[\"run\"][\"preprocessing\"][\"max_filter_freq\"]\n",
    "\n",
    "# spontaneous demo\n",
    "cfg_s, param_cfg_s = get_config(\"silico_neuropixels\", \"npx_spont\").values() # config\n",
    "FREQ_MIN_S = param_cfg_s[\"run\"][\"preprocessing\"][\"min_filter_freq\"] # preprocessing parameters\n",
    "FREQ_MAX_S = param_cfg_s[\"run\"][\"preprocessing\"][\"max_filter_freq\"]\n",
    "\n",
    "# layer parameter\n",
    "lyrs = [\"L5\"]\n",
    "\n",
    "# plot parameters\n",
    "FIG_SIZE = (1.8, 1.6)\n",
    "COLOR_NS = [0.9, 0.14, 0.15]\n",
    "COLOR_NE = [1, 0.49, 0]\n",
    "N_BINS = 100 # bins for snr histogram\n",
    "pm = {\n",
    "    \"linestyle\": \"-\",\n",
    "    \"linewidth\": 1,\n",
    "    \"marker\": \"None\",\n",
    "}\n",
    "\n",
    "# axes\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 6  # 5-7 with Nature neuroscience as reference\n",
    "plt.rcParams[\"lines.linewidth\"] = 0.5 # typically between 0.5 and 1\n",
    "plt.rcParams[\"axes.linewidth\"] = 0.5 #1\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"xtick.major.width\"] = 0.5 #0.8 #* 1.3\n",
    "plt.rcParams[\"xtick.minor.width\"] = 0.5 #0.8 #* 1.3\n",
    "plt.rcParams[\"ytick.major.width\"] = 0.5 #0.8 #* 1.3\n",
    "plt.rcParams[\"ytick.minor.width\"] = 0.5 #0.8 #* 1.3\n",
    "plt.rcParams[\"xtick.major.size\"] = 3.5 * 1.1\n",
    "plt.rcParams[\"xtick.minor.size\"] = 2 * 1.1\n",
    "plt.rcParams[\"ytick.major.size\"] = 3.5 * 1.1\n",
    "plt.rcParams[\"ytick.minor.size\"] = 2 * 1.1\n",
    "# legend\n",
    "savefig_cfg = {\"transparent\":True, \"dpi\": 300}\n",
    "legend_cfg = {\"frameon\": False, \"handletextpad\": 0.5}\n",
    "tight_layout_cfg = {\"pad\": 0.5}\n",
    "LG_FRAMEON = False              # no legend frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.9 s, sys: 6.1 s, total: 43 s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# EVOKED DEMO\n",
    "\n",
    "with DandiAPIClient() as client: # download the extractors from Dandi archive\n",
    "    asset = client.get_dandiset(dandiset_id, 'draft').get_asset_by_path(filepath_evoked)\n",
    "    s3_path = asset.get_content_url(follow_redirects=1, strip_query=True)\n",
    "RecordingE = se.NwbRecordingExtractor(file_path=s3_path, stream_mode=\"remfile\") # get extractor\n",
    "RecordingE = spre.astype(RecordingE, \"int16\") # compress to int16 (like kilosorts)\n",
    "RecordingE = spre.bandpass_filter(RecordingE, freq_min=FREQ_MIN_E, freq_max=FREQ_MAX_E)  # band-pass filter\n",
    "RecordingE = spre.common_reference(RecordingE, reference=\"global\", operator=\"median\") # common reference\n",
    "traces_ne = RecordingE.get_traces() # get trace array\n",
    "\n",
    "# SPONTANEOUS DEMO\n",
    "\n",
    "with DandiAPIClient() as client:\n",
    "    asset = client.get_dandiset(dandiset_id, 'draft').get_asset_by_path(filepath_spont)\n",
    "    s3_path = asset.get_content_url(follow_redirects=1, strip_query=True)\n",
    "RecordingS = se.NwbRecordingExtractor(file_path=s3_path, stream_mode=\"remfile\")\n",
    "RecordingS = spre.astype(RecordingS, \"int16\")\n",
    "RecordingS = spre.bandpass_filter(RecordingS, freq_min=FREQ_MIN_S, freq_max=FREQ_MAX_S)\n",
    "RecordingS = spre.common_reference(RecordingS, reference=\"global\", operator=\"median\")\n",
    "traces_ns = RecordingS.get_traces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'mad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/jovyan/steevelaquitaine/spikebias/envs/demo/lib/python3.10/concurrent/futures/process.py\", line 246, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/home/jovyan/steevelaquitaine/spikebias/envs/demo/lib/python3.10/concurrent/futures/process.py\", line 205, in _process_chunk\n    return [fn(*args) for args in chunk]\n  File \"/home/jovyan/steevelaquitaine/spikebias/envs/demo/lib/python3.10/concurrent/futures/process.py\", line 205, in <listcomp>\n    return [fn(*args) for args in chunk]\n  File \"/home/jovyan/steevelaquitaine/spikebias/src/nodes/validation/snr.py\", line 507, in get_site_snr\n    mad = pd.DataFrame(trace).mad().values\n  File \"/home/jovyan/steevelaquitaine/spikebias/envs/demo/lib/python3.10/site-packages/pandas/core/generic.py\", line 6299, in __getattr__\n    return object.__getattribute__(self, name)\nAttributeError: 'DataFrame' object has no attribute 'mad'. Did you mean: 'map'?\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:12\u001b[0m\n",
      "File \u001b[0;32m~/steevelaquitaine/spikebias/src/nodes/validation/snr.py:532\u001b[0m, in \u001b[0;36mget_snrs_parallel\u001b[0;34m(traces)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    527\u001b[0m     site_snrs \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    528\u001b[0m         get_site_snr,\n\u001b[1;32m    529\u001b[0m         traces\u001b[38;5;241m.\u001b[39mT,\n\u001b[1;32m    530\u001b[0m         np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, nsites, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    531\u001b[0m     )\n\u001b[0;32m--> 532\u001b[0m snr_by_site \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msite_snrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(snr_by_site)\n",
      "File \u001b[0;32m~/steevelaquitaine/spikebias/envs/demo/lib/python3.10/concurrent/futures/process.py:570\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    565\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    571\u001b[0m         element\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m~/steevelaquitaine/spikebias/envs/demo/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/steevelaquitaine/spikebias/envs/demo/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/steevelaquitaine/spikebias/envs/demo/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/steevelaquitaine/spikebias/envs/demo/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'mad'"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# evoked\n",
    "traces_ne = RecordingE.get_traces() # get trace array\n",
    "site_ly_ne = RecordingE.get_property(\"layers\") # get layers\n",
    "sites_ne = np.where(np.isin(site_ly_ne, lyrs))[0]\n",
    "\n",
    "# spontaneous\n",
    "traces_ns = RecordingS.get_traces() # get trace array\n",
    "site_ly_ns = RecordingS.get_property(\"layers\") # get layers\n",
    "sites_ns = np.where(np.isin(site_ly_ns, lyrs))[0]\n",
    "\n",
    "# compute snrs\n",
    "snr_ne = snr.get_snrs_parallel(traces_ne[:, sites_ne]).astype(np.float32)\n",
    "max_anr_e = np.max(snr_ne)\n",
    "min_anr_e = np.min(snr_ne)\n",
    "snr_ns = snr.get_snrs_parallel(traces_ns[:, sites_ns]).astype(np.float32)\n",
    "max_anr_s = np.max(snr_ns)\n",
    "min_anr_s = np.min(snr_ns)\n",
    "\n",
    "# get the common bins across all experiments\n",
    "# gather the mins and maxs computed from all nodes and \n",
    "# compute the common bins on node 0\n",
    "anr_max = np.max([max_anr_e, max_anr_s])\n",
    "anr_min = np.min([min_anr_e, min_anr_s])\n",
    "step = (anr_max - anr_min) / N_BINS\n",
    "bins = np.arange(anr_min, anr_max + step / 2, step)\n",
    "\n",
    "# compute summary statistics\n",
    "mean_ne, ci_ne, _ = amplitude.get_snr_pdfs(snr_ne, bins)\n",
    "mean_ne, ci_ne, _ = amplitude.get_snr_pdfs(snr_ns, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anr_min)\n",
    "print(anr_max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=FIG_SIZE)\n",
    "\n",
    "# plot\n",
    "ax = amplitude.plot_anr_pdf_l5(\n",
    "    ax,\n",
    "    mean_ns,\n",
    "    mean_ne,\n",
    "    ci_ns,\n",
    "    ci_ne,\n",
    "    bins,\n",
    "    COLOR_NS,\n",
    "    COLOR_NE,\n",
    "    pm,\n",
    ")\n",
    "\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.set_xticks([np.floor(xmin).astype(int), 0, np.ceil(xmax).astype(int)], [np.floor(xmin).astype(int), 0, np.ceil(xmax).astype(int)])\n",
    "ax.set_xlim([np.floor(xmin), np.ceil(xmax)])\n",
    "\n",
    "# tighten\n",
    "fig.tight_layout(**tight_layout_cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
