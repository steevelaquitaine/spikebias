{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias types (Herdingspikes)\n",
    "\n",
    "author: steeve.laquitaine@epfl.ch  \n",
    "last modified: 13-02-2024\n",
    "status: OK  \n",
    "regression: None  \n",
    "\n",
    "Purpose: Characterize and quantify ground truth sorting quality and biases from matching with best matching sorted units"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Create or activate env `npx_10m_384ch_unit_classes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 15:11:19,264 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-02-15 15:11:19,279 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2024-02-15 15:11:19,280 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-02-15 15:11:19,303 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2024-02-15 15:11:19,305 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-02-15 15:11:19,324 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2024-02-15 15:11:19,325 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-02-15 15:11:19,351 - root - utils.py - get_config - INFO - Reading experiment config. - done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import spikeinterface as si\n",
    "import copy\n",
    "proj_path = \"/gpfs/bbp.cscs.ch/project/proj85/home/laquitai/spikebias/\"\n",
    "os.chdir(proj_path)\n",
    "\n",
    "from src.nodes.postpro.cell_matching import get_SpikeInterface_matching_object\n",
    "from src.nodes.utils import get_config\n",
    "\n",
    "# set classification parameters\n",
    "LOW_RATE_CEILING = 0.2  # max firing rate where negative proba change is observed in \"bias plot\" (sparse units)\n",
    "DET_THRESH = 0.8\n",
    "CHANCE_THRESH = 0.1\n",
    "\n",
    "# buccino\n",
    "data_conf, param_conf = get_config(\"buccino_2020\", \"2020\").values()\n",
    "SORTING_PATH_b = data_conf[\"sorting\"][\"sorters\"][\"herdingspikes\"][\"output\"]\n",
    "GT_SORTING_PATH_b = data_conf[\"sorting\"][\"simulation\"][\"ground_truth\"][\"output\"]\n",
    "RECORDING_PATH_b = data_conf[\"recording\"][\"output\"]\n",
    "SORTING_PATH_b = data_conf[\"sorting\"][\"sorters\"][\"herdingspikes\"][\"output\"]\n",
    "\n",
    "# silico marques\n",
    "data_conf, param_conf = get_config(\"silico_neuropixels\", \"2023_10_18\").values()\n",
    "SORTING_PATH_m = data_conf[\"sorting\"][\"sorters\"][\"herdingspikes\"][\"output\"]\n",
    "GT_SORTING_PATH_m = data_conf[\"sorting\"][\"simulation\"][\"ground_truth\"][\"output\"]\n",
    "RECORDING_PATH_m = data_conf[\"recording\"][\"output\"]\n",
    "SORTING_PATH_m = data_conf[\"sorting\"][\"sorters\"][\"herdingspikes\"][\"output\"]\n",
    "\n",
    "# silico horvath\n",
    "data_conf, param_conf = get_config(\"silico_horvath\", \"concatenated/probe_1\").values()\n",
    "SORTING_PATH_h = data_conf[\"sorting\"][\"sorters\"][\"herdingspikes\"][\"output\"]\n",
    "GT_SORTING_PATH_h = data_conf[\"sorting\"][\"simulation\"][\"ground_truth\"][\"output\"]\n",
    "RECORDING_PATH_h = data_conf[\"recording\"][\"output\"]\n",
    "SORTING_PATH_h = data_conf[\"sorting\"][\"sorters\"][\"herdingspikes\"][\"output\"]\n",
    "\n",
    "# silico stimulus\n",
    "data_conf, param_conf = get_config(\"silico_neuropixels\", \"stimulus\").values()\n",
    "SORTING_PATH_e = data_conf[\"sorting\"][\"sorters\"][\"herdingspikes\"][\"output\"]\n",
    "GT_SORTING_PATH_e = data_conf[\"sorting\"][\"simulation\"][\"ground_truth\"][\"output\"]\n",
    "RECORDING_PATH_e = data_conf[\"recording\"][\"output\"]\n",
    "SORTING_PATH_e = data_conf[\"sorting\"][\"sorters\"][\"herdingspikes\"][\"output\"]\n",
    "\n",
    "\n",
    "# FIGURE SETTINGS\n",
    "COLOR_VIVO = (0.7, 0.7, 0.7)\n",
    "COLOR_SILI = (0.84, 0.27, 0.2)\n",
    "COLOR_STIM = (0.6, 0.75, 0.1)\n",
    "BOX_ASPECT = 1                  # square fig\n",
    "FIG_SIZE = (1,1)\n",
    "plt.rcParams['figure.figsize'] = (2,1)\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 6\n",
    "plt.rcParams['lines.linewidth'] = 0.2\n",
    "plt.rcParams['axes.linewidth'] = 0.5\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['xtick.major.width'] = 0.3\n",
    "plt.rcParams['xtick.minor.size'] = 0.1\n",
    "plt.rcParams['xtick.major.size'] = 1.5\n",
    "plt.rcParams['ytick.major.size'] = 1.5\n",
    "plt.rcParams['ytick.major.width'] = 0.3\n",
    "legend_cfg = {\"frameon\": False, \"handletextpad\": 0.1}\n",
    "savefig_cfg = {\"transparent\":True}\n",
    "# print(plt.rcParams.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_agreement_matrix(MatchingObject):\n",
    "\n",
    "    # get sorted x true units' agreement scores\n",
    "    overmerging_matx = MatchingObject.agreement_scores.T\n",
    "\n",
    "    # sort each row such that the row with the highest score be first, while column order stays unchanged\n",
    "    argmax = overmerging_matx.T.idxmax().to_frame()\n",
    "    max = overmerging_matx.T.max()\n",
    "    descending_ix = np.argsort(max)[::-1]\n",
    "    overmerging_matx_2 = overmerging_matx.iloc[descending_ix]\n",
    "\n",
    "    # repeat for columns, row order stays auntouched\n",
    "    argmax = overmerging_matx_2.idxmax().to_frame()\n",
    "    max = overmerging_matx_2.max()\n",
    "    descending_ix = np.argsort(max)[::-1]\n",
    "    return overmerging_matx_2.iloc[:, descending_ix]\n",
    "\n",
    "\n",
    "def classify_true_unit_biases(overmerging_matx_2, det_thresh, chance):\n",
    "\n",
    "    # create masks\n",
    "    mask_above_det = overmerging_matx_2 >= det_thresh\n",
    "    mask_below_chance = overmerging_matx_2 <= chance\n",
    "    mask_in_between = np.logical_and(\n",
    "        overmerging_matx_2 < det_thresh, overmerging_matx_2 > chance\n",
    "    )\n",
    "    mask_entirely_missed = overmerging_matx_2 == 0\n",
    "\n",
    "    # implement tree to classify ground truths\n",
    "    # find ground truth (cols) with one mask_above_det=True and other mask_below_chance = True\n",
    "\n",
    "    gt_classes = []\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # loop over ground truth units\n",
    "    for gt_i in range(overmerging_matx_2.shape[1]):\n",
    "\n",
    "        # check if that ground truth has a single sorted unit\n",
    "        # with an agreement score above detection threshold\n",
    "        if any(mask_above_det.iloc[:, gt_i]):\n",
    "\n",
    "            # get this ground truth detection stata\n",
    "            is_detected = mask_above_det.iloc[:, gt_i]\n",
    "            detected_loc = np.where(is_detected)[0]\n",
    "            detected_ix = is_detected.index[detected_loc]\n",
    "\n",
    "            # get other cells\n",
    "            other_cells_ix = is_detected.drop(index=detected_ix).index\n",
    "\n",
    "            # get this ground truth below chance stata\n",
    "            is_below_chance = mask_below_chance.iloc[:, gt_i]\n",
    "\n",
    "            # check if all other sorted units are below chance\n",
    "            if all(is_below_chance.loc[other_cells_ix]):\n",
    "                gt_classes.append(\"well detected\")\n",
    "\n",
    "            # if another unit has an agreement score\n",
    "            # above chance level, it is: well detected + correlated unit\n",
    "            else:\n",
    "                gt_classes.append(\"well detected, correlated\")\n",
    "\n",
    "        # case where ground truth matches only one sorted unit\n",
    "        # with a score b/w detection and chance and\n",
    "        # other units below chance\n",
    "        # no score are above detection\n",
    "        elif (sum(mask_in_between.iloc[:, gt_i]) == 1) and (\n",
    "            any(mask_above_det.iloc[:, gt_i]) == False\n",
    "        ):\n",
    "            gt_classes.append(\"poorly detected\")\n",
    "\n",
    "        # case a true unit is associated is a sorted unit with score\n",
    "        # between detection and chance that is associated with other\n",
    "        # true units with scores between detection and chances\n",
    "        elif sum(mask_in_between.iloc[:, gt_i]) > 1:\n",
    "            gt_classes.append(\"oversplit\")\n",
    "\n",
    "        # check that all sorted units have scores below\n",
    "        # chance\n",
    "        elif all(mask_below_chance.iloc[:, gt_i]):\n",
    "            if all(mask_entirely_missed.iloc[:, gt_i]):\n",
    "                gt_classes.append(\"missed\")\n",
    "            else:\n",
    "                gt_classes.append(\"below chance\")\n",
    "\n",
    "    # Detect overmerged units and combinations -------------\n",
    "\n",
    "    # if one of its sorted units with score between\n",
    "    # detection and chance has also a score between\n",
    "    # detection and chance with another true unit\n",
    "    # the true unit is overmerged (with another true unit)\n",
    "    true_units_loc = np.where(mask_in_between.sum(axis=0) >= 1)[0]\n",
    "    true_units = mask_in_between.columns[true_units_loc]\n",
    "    gt_overmerged = dict()\n",
    "\n",
    "    for gt_i in range(len(true_units_loc)):\n",
    "        target_true_units_mx = mask_in_between.iloc[:, true_units_loc]\n",
    "        sorted_u = np.where(target_true_units_mx.iloc[:, gt_i])[0]\n",
    "\n",
    "        # check overmerged (that sorted unit merges other true units)\n",
    "        if any(mask_in_between.iloc[sorted_u, :].sum(axis=1) > 1):\n",
    "            overmerged_bool = mask_in_between.iloc[sorted_u, :].sum(axis=1) > 1\n",
    "            overmerging_sorted = overmerged_bool.index[\n",
    "                np.where(overmerged_bool)[0]\n",
    "            ].to_list()\n",
    "            gt_overmerged[true_units[gt_i]] = overmerging_sorted\n",
    "\n",
    "    # what other biases do overmerged units have?\n",
    "    all_true_units = overmerging_matx_2.columns\n",
    "    gt_classes_df = pd.DataFrame(data=gt_classes, index=all_true_units.to_list())\n",
    "    print(\n",
    "        \"combination of biases:\", np.unique(gt_classes_df.loc[gt_overmerged.keys(), :])\n",
    "    )\n",
    "\n",
    "    # label combination of biases\n",
    "    gt_classes_df.loc[gt_overmerged.keys(), :] = gt_classes_df.loc[\n",
    "        gt_overmerged.keys(), :\n",
    "    ].apply(lambda x: x + \", overmerged\")\n",
    "\n",
    "    # poorly detected + overmerged units are poorly detected because overmerged so simply overmerged\n",
    "    gt_classes_df[gt_classes_df == \"poorly detected, overmerged\"] = \"overmerged\"\n",
    "    return gt_classes_df\n",
    "\n",
    "\n",
    "def create_true_biases_df(true_biases_series):\n",
    "\n",
    "    # format dataframe to plot\n",
    "    bias_types = [\n",
    "        \"well detected\",\n",
    "        \"well detected, correlated\",\n",
    "        \"well detected, correlated, overmerged\",\n",
    "        \"poorly detected\",\n",
    "        \"overmerged\",\n",
    "        \"oversplit\",\n",
    "        \"oversplit, overmerged\",\n",
    "        \"below chance\",\n",
    "        \"missed\",\n",
    "    ]\n",
    "\n",
    "    # count each bias\n",
    "    count_by_class = dict(Counter(true_biases_series.values.squeeze().tolist()))\n",
    "\n",
    "    # fill up count per bias\n",
    "    for key_k in bias_types:\n",
    "        try:\n",
    "            count_by_class[key_k]\n",
    "        except:\n",
    "            count_by_class[key_k] = 0\n",
    "\n",
    "    # order by \"bias_types\"\n",
    "    reordered = {k: count_by_class[k] for k in bias_types}\n",
    "\n",
    "    # create table\n",
    "    biases_ratio_df = pd.DataFrame(\n",
    "        {\"cell_count\": list(reordered.values())}, index=list(reordered.keys())\n",
    "    )\n",
    "    return biases_ratio_df\n",
    "\n",
    "\n",
    "def plot_biases(axis, biases_count: pd.DataFrame):\n",
    "\n",
    "    # set colors for combination of biases\n",
    "    oversplit_plus_overmerged = np.array([[0.6, 0.9, 0.6], [0, 0.7, 1]]).mean(axis=0)\n",
    "    well_detected_plus_correlated_units_plus_overmerged = np.array(\n",
    "        [[1, 0, 0], [0, 0.7, 1]]\n",
    "    ).mean(axis=0)\n",
    "\n",
    "    # set all colors\n",
    "    colors = [\n",
    "        [0.7, 0.1, 0.1],  # \"well_detected\" (strong red)\n",
    "        [1, 0, 0],  # \"well_detected_plus_correlated_units\" (red)\n",
    "        well_detected_plus_correlated_units_plus_overmerged,\n",
    "        [1, 0.85, 0.85],  # \"poorly_detected\" (pink)\n",
    "        [0, 0.7, 1],  # \"overmerged\" (green)\n",
    "        [0.6, 0.9, 0.6],  # \"oversplit\" (blue)\n",
    "        oversplit_plus_overmerged,\n",
    "        [0.95, 0.95, 0.95],  # \"below chance\"\n",
    "        \"k\",  # \"missed\"\n",
    "    ]\n",
    "\n",
    "    biases_ratio = biases_count / biases_count.sum()\n",
    "\n",
    "    # plot\n",
    "    ax = (biases_ratio).T.plot.bar(\n",
    "        ax=axis,\n",
    "        stacked=True,\n",
    "        color=colors,\n",
    "        width=0.9,\n",
    "        edgecolor=[0.5, 0.5, 0.5],\n",
    "        linewidth=0.2,\n",
    "    )\n",
    "\n",
    "    # set axis legend\n",
    "    ax.spines[[\"left\", \"right\", \"top\", \"bottom\"]].set_visible(False)\n",
    "    y_axis = ax.axes.get_yaxis()\n",
    "    y_axis.set_visible(False)\n",
    "    ax.set_xticklabels(biases_ratio.columns, rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel(\"Sorting biases (ratio)\", fontsize=9)\n",
    "\n",
    "    ax.legend(\n",
    "        biases_count.index,\n",
    "        ncol=1,\n",
    "        loc=\"lower left\",\n",
    "        bbox_to_anchor=(1, 0),\n",
    "        frameon=False,\n",
    "        handletextpad=0.6,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return axis\n",
    "\n",
    "\n",
    "def plot_heatmap(overmerging_matx_2):\n",
    "\n",
    "    # plot\n",
    "    # fig, axis = plt.subplots(1, 1, figsize=(2, 10))\n",
    "\n",
    "    # plot agreement matrix\n",
    "    mx_to_plot = overmerging_matx_2.iloc[:500, :500].values\n",
    "    fig, axis = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        mx_to_plot,\n",
    "        cmap=\"jet\",\n",
    "        cbar_kws={\"shrink\": 0.5},\n",
    "        yticklabels=False,\n",
    "        xticklabels=False,\n",
    "    )\n",
    "    plt.xlabel(\"true units\")\n",
    "    plt.ylabel(\"sorted units\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "\n",
    "def classify_sorted_unit_biases(agreem_mx):\n",
    "\n",
    "    # note: with this approach (BEST matching approach), the same sorted unit can be paired with more than one true unit\n",
    "    # we only keep the pairings with highest agreement scores\n",
    "    # true-sorted unit pairing\n",
    "    pairing = agreem_mx.T.idxmax(axis=1)\n",
    "    pairing = pairing.to_frame()\n",
    "    pairing.columns = [\"sorted\"]\n",
    "\n",
    "    # add agreement score\n",
    "    accuracy = agreem_mx.T.max(axis=1)\n",
    "    pairing[\"accuracy\"] = accuracy\n",
    "\n",
    "    # check if the only sorted unit paired with this true unit\n",
    "    sorted_ids = agreem_mx.index\n",
    "\n",
    "    df = copy.copy(pairing.iloc[0, :].to_frame().T)\n",
    "    false_positives = []\n",
    "\n",
    "    # else keep the pairing with highest agreement score\n",
    "    # loop over all sorted single unit units\n",
    "    for ix in range(len(sorted_ids)):\n",
    "        # case the sorted unit was paired with a ground truth unit\n",
    "        if any(pairing[\"sorted\"] == sorted_ids[ix]):\n",
    "            sorted_pairings = pairing[pairing[\"sorted\"] == sorted_ids[ix]].sort_values(\n",
    "                by=\"accuracy\", ascending=False\n",
    "            )\n",
    "            # take max pairing (first row)\n",
    "            df = pd.concat([df, sorted_pairings.iloc[0, :].to_frame().T])\n",
    "        else:\n",
    "            # case the sorted unit was paired with none of the ground truth units\n",
    "            false_positives.append(sorted_ids[ix])\n",
    "\n",
    "    df = df[1:]\n",
    "    df[\"sorted\"] = df[\"sorted\"].astype(int)\n",
    "\n",
    "    # count biases\n",
    "    n_good = sum(df[\"accuracy\"] >= DET_THRESH)\n",
    "    n_poor = sum((df[\"accuracy\"] >= CHANCE_THRESH) & (df[\"accuracy\"] < DET_THRESH))\n",
    "    n_below_chance = sum((df[\"accuracy\"] > 0) & (df[\"accuracy\"] < CHANCE_THRESH))\n",
    "    n_false_pos = len(false_positives)\n",
    "\n",
    "    # sanity check\n",
    "    assert n_good + n_poor + n_below_chance + n_false_pos == len(\n",
    "        sorted_ids\n",
    "    ), \"They must match\"\n",
    "    return {\n",
    "        \"n_good\": n_good,\n",
    "        \"n_poor\": n_poor,\n",
    "        \"n_below_chance\": n_below_chance,\n",
    "        \"n_false_pos\": n_false_pos,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sorted x true agreement matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 2 min\n",
    "\n",
    "# get true/sorted matching object\n",
    "MatchingObject_b = get_SpikeInterface_matching_object(GT_SORTING_PATH_b, SORTING_PATH_b)\n",
    "MatchingObject_m = get_SpikeInterface_matching_object(GT_SORTING_PATH_m, SORTING_PATH_m)\n",
    "MatchingObject_h = get_SpikeInterface_matching_object(GT_SORTING_PATH_h, SORTING_PATH_h)\n",
    "MatchingObject_e = get_SpikeInterface_matching_object(GT_SORTING_PATH_e, SORTING_PATH_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sort each row in descending order. The columns are not labelled as the raw ground truth anymore but become labelled as best match ground truth to the worst match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreem_mx_b = format_agreement_matrix(MatchingObject_b)\n",
    "agreem_mx_m = format_agreement_matrix(MatchingObject_m)\n",
    "agreem_mx_h = format_agreement_matrix(MatchingObject_h)\n",
    "agreem_mx_e = format_agreement_matrix(MatchingObject_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot biases (matching only the best matching sorted single units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the sorted single units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter the sorted single units\n",
    "# NOTE: herdingspikes does not have a metadata label for single units\n",
    "\n",
    "# # buccino\n",
    "# Sorting = si.load_extractor(SORTING_PATH_b)\n",
    "# agreem_mx_b = agreem_mx_b.loc[\n",
    "#     Sorting.unit_ids[Sorting.get_property(\"KSLabel\") == \"good\"], :\n",
    "# ]\n",
    "\n",
    "# # marques\n",
    "# Sorting = si.load_extractor(SORTING_PATH_m)\n",
    "# agreem_mx_m = agreem_mx_m.loc[\n",
    "#     Sorting.unit_ids[Sorting.get_property(\"KSLabel\") == \"good\"], :\n",
    "# ]\n",
    "\n",
    "# # horvath\n",
    "# Sorting = si.load_extractor(SORTING_PATH_h)\n",
    "# agreem_mx_h = agreem_mx_h.loc[\n",
    "#     Sorting.unit_ids[Sorting.get_property(\"KSLabel\") == \"good\"], :\n",
    "# ]\n",
    "\n",
    "# # evoked\n",
    "# Sorting = si.load_extractor(SORTING_PATH_e)\n",
    "# agreem_mx_e = agreem_mx_e.loc[\n",
    "#     Sorting.unit_ids[Sorting.get_property(\"KSLabel\") == \"good\"], :\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>142759</th>\n",
       "      <th>3463535</th>\n",
       "      <th>3558393</th>\n",
       "      <th>3443482</th>\n",
       "      <th>281388</th>\n",
       "      <th>3887809</th>\n",
       "      <th>4094711</th>\n",
       "      <th>2304097</th>\n",
       "      <th>739303</th>\n",
       "      <th>796411</th>\n",
       "      <th>...</th>\n",
       "      <th>1033335</th>\n",
       "      <th>2298129</th>\n",
       "      <th>1485577</th>\n",
       "      <th>1492568</th>\n",
       "      <th>1493374</th>\n",
       "      <th>1504069</th>\n",
       "      <th>3234861</th>\n",
       "      <th>3316630</th>\n",
       "      <th>1102883</th>\n",
       "      <th>2283084</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997010</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows Ã— 1310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     142759    3463535   3558393   3443482   281388    3887809   4094711  \\\n",
       "204      1.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "32       0.0  0.998771  0.000000  0.001494  0.000000  0.000000  0.001199   \n",
       "50       0.0  0.000000  0.997010  0.001074  0.000000  0.000000  0.000000   \n",
       "14       0.0  0.000999  0.000000  0.991660  0.000000  0.001812  0.000489   \n",
       "145      0.0  0.000000  0.000000  0.000000  0.991379  0.000000  0.000000   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "181      0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "107      0.0  0.000978  0.001140  0.000000  0.000000  0.000000  0.000000   \n",
       "165      0.0  0.000000  0.001318  0.000000  0.000000  0.000000  0.000000   \n",
       "193      0.0  0.000000  0.000000  0.000000  0.000000  0.000935  0.000000   \n",
       "55       0.0  0.001373  0.000000  0.001630  0.000000  0.001202  0.000000   \n",
       "\n",
       "      2304097  739303   796411   ...  1033335  2298129  1485577  1492568  \\\n",
       "204  0.000000      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "32   0.000753      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "50   0.000000      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "14   0.000000      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "145  0.001585      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "..        ...      ...      ...  ...      ...      ...      ...      ...   \n",
       "181  0.000000      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "107  0.001381      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "165  0.000000      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "193  0.000000      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "55   0.000862      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "\n",
       "     1493374  1504069  3234861  3316630  1102883  2283084  \n",
       "204      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "32       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "50       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "14       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "145      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "..       ...      ...      ...      ...      ...      ...  \n",
       "181      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "107      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "165      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "193      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "55       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[212 rows x 1310 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreem_mx_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination of biases: ['poorly detected']\n",
      "combination of biases: ['oversplit' 'poorly detected' 'well detected, correlated']\n",
      "combination of biases: ['oversplit' 'poorly detected' 'well detected, correlated']\n",
      "combination of biases: ['oversplit' 'poorly detected']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_289945/1308606798.py:208: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 50x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# takes 2 secs\n",
    "\n",
    "# record agreement matrices for each dataset\n",
    "agreem_mxs = [agreem_mx_b, agreem_mx_m, agreem_mx_h, agreem_mx_e]\n",
    "agreem_names = [\"Buccino\", \"Marques\", \"Horvath\", \"Evoked\"]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for ix, mx_i in enumerate(agreem_mxs):\n",
    "\n",
    "    # classify sorting biases for this dataset\n",
    "    bias_labels = classify_true_unit_biases(mx_i, DET_THRESH, CHANCE_THRESH)\n",
    "\n",
    "    # calculate proportions of biases for this dataset\n",
    "    biases_ratio_df = create_true_biases_df(bias_labels)\n",
    "    df[agreem_names[ix]] = biases_ratio_df[\"cell_count\"].values\n",
    "\n",
    "df.index = biases_ratio_df.index\n",
    "\n",
    "# plot\n",
    "fig, axis = plt.subplots(1, 1, figsize=(0.5, 1))\n",
    "axis = plot_biases(axis, df)\n",
    "axis.set_xlabel(\"Simulated recordings\")\n",
    "\n",
    "# save figures\n",
    "plt.savefig(\n",
    "    \"/gpfs/bbp.cscs.ch/project/proj85/home/laquitai/spikebias/figures/3_bias/svg/sorting_accuracy_and_biases_herdingspikes.svg\",\n",
    "    **savefig_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Buccino</th>\n",
       "      <th>Marques</th>\n",
       "      <th>Horvath</th>\n",
       "      <th>Evoked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>well detected</th>\n",
       "      <td>116</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well detected, correlated</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well detected, correlated, overmerged</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poorly detected</th>\n",
       "      <td>55</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overmerged</th>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversplit</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversplit, overmerged</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>below chance</th>\n",
       "      <td>63</td>\n",
       "      <td>900</td>\n",
       "      <td>127</td>\n",
       "      <td>1627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed</th>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "      <td>91</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Buccino  Marques  Horvath  Evoked\n",
       "well detected                              116       35        2      31\n",
       "well detected, correlated                    6        6        1       1\n",
       "well detected, correlated, overmerged        0        3        2       0\n",
       "poorly detected                             55       70        6      87\n",
       "overmerged                                   8       47       44      35\n",
       "oversplit                                    2        7        0       9\n",
       "oversplit, overmerged                        0        8       14       7\n",
       "below chance                                63      900      127    1627\n",
       "missed                                       0      234       91      39"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple description of sorted units as \"good\", \"poor\", \"below chance\" or \"false positive\"\n",
    "\n",
    "This description is only based on the unit sorting accuracy with its best matching ground truth unit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_289945/464774481.py:52: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 50x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set all colors\n",
    "colors = [\n",
    "    [0.7, 0.1, 0.1],  # \"good\" (strong red)\n",
    "    [1, 0.85, 0.85],  # \"poor\" (pink)\n",
    "    [0.95, 0.95, 0.95],  # \"below chance\"\n",
    "    \"w\",  # \"false positive\"\n",
    "]\n",
    "\n",
    "# count sorted unit biases for each dataset\n",
    "agreem_names = [\"Buccino\", \"Marques\", \"Horvath\", \"Evoked\"]\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for ix in range(len(agreem_names)):\n",
    "    out = classify_sorted_unit_biases(agreem_mxs[ix])\n",
    "    df2[agreem_names[ix]] = [\n",
    "        out[\"n_good\"],\n",
    "        out[\"n_poor\"],\n",
    "        out[\"n_below_chance\"],\n",
    "        out[\"n_false_pos\"],\n",
    "    ]\n",
    "df2.index = [\"good\", \"poor\", \"below chance\", \"false positive\"]\n",
    "df2_ratio = df2 / df2.sum()\n",
    "\n",
    "fig, axis = plt.subplots(1, 1, figsize=(0.5, 1))\n",
    "ax = (df2_ratio).T.plot.bar(\n",
    "    ax=axis,\n",
    "    stacked=True,\n",
    "    color=colors,\n",
    "    width=0.9,\n",
    "    edgecolor=[0, 0, 0],\n",
    "    linewidth=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "# set axis legend\n",
    "ax.spines[[\"left\", \"right\", \"top\", \"bottom\"]].set_visible(False)\n",
    "y_axis = ax.axes.get_yaxis()\n",
    "y_axis.set_visible(False)\n",
    "ax.set_xticklabels(df2_ratio.columns, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Sorting biases (ratio)\", fontsize=9)\n",
    "\n",
    "ax.legend(\n",
    "    df2.index,\n",
    "    ncol=1,\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(1, 0),\n",
    "    frameon=False,\n",
    "    handletextpad=0.6,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# save figures\n",
    "plt.savefig(\n",
    "    \"/gpfs/bbp.cscs.ch/project/proj85/home/laquitai/spikebias/figures/3_bias/svg/sorted_unit_biases_herdingspikes.svg\",\n",
    "    **savefig_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPLREMENTARY: For a comprehensive descriptions of biases for ground truth and sorted units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination of biases: ['oversplit' 'poorly detected']\n"
     ]
    }
   ],
   "source": [
    "overmerging_matx_2 = agreem_mx_m\n",
    "det_thresh = 0.8\n",
    "chance = 0.1\n",
    "\n",
    "# create masks\n",
    "mask_above_det = overmerging_matx_2 >= det_thresh\n",
    "mask_below_chance = overmerging_matx_2 <= chance\n",
    "mask_in_between = np.logical_and(\n",
    "    overmerging_matx_2 < det_thresh, overmerging_matx_2 > chance\n",
    ")\n",
    "mask_entirely_missed = overmerging_matx_2 == 0\n",
    "\n",
    "# implement tree to classify ground truths\n",
    "# find ground truth (cols) with one mask_above_det=True and other mask_below_chance = True\n",
    "\n",
    "gt_classes = []\n",
    "df = pd.DataFrame(\n",
    "    data=np.array([[0], [0], [0], [0]]).T,\n",
    "    columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    ")\n",
    "\n",
    "# loop over ground truth units\n",
    "for gt_i in range(overmerging_matx_2.shape[1]):\n",
    "\n",
    "    # check if that ground truth has a single sorted unit\n",
    "    # with an agreement score above detection threshold\n",
    "    if any(mask_above_det.iloc[:, gt_i]):\n",
    "\n",
    "        # get this ground truth detection stata\n",
    "        is_detected = mask_above_det.iloc[:, gt_i]\n",
    "        detected_loc = np.where(is_detected)[0]\n",
    "        detected_id = is_detected.index[detected_loc]\n",
    "\n",
    "        # get other correlated unit ids\n",
    "        other_sorted_unit_ids = is_detected.drop(index=detected_id).index\n",
    "\n",
    "        # get this ground truth below chance stata\n",
    "        is_below_chance = mask_below_chance.iloc[:, gt_i]\n",
    "\n",
    "        # check if all other sorted units are below chance\n",
    "        if all(is_below_chance.loc[other_sorted_unit_ids]):\n",
    "            gt_classes.append(\"well detected\")\n",
    "\n",
    "            # pair true and sorted units\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        [overmerging_matx_2.columns[gt_i]],\n",
    "                        [detected_id[0]],\n",
    "                        [\"well detected\"],\n",
    "                        [\"good\"],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "\n",
    "        # if another unit has an agreement score\n",
    "        # above chance level, it is: well detected + correlated unit\n",
    "        else:\n",
    "            gt_classes.append(\"well detected, correlated\")\n",
    "\n",
    "            # pair true and the well detected sorted unit\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        [overmerging_matx_2.columns[gt_i]],\n",
    "                        [detected_id[0]],\n",
    "                        [\"well detected, correlated\"],\n",
    "                        [\"good\"],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "\n",
    "            # pair true and the other redundant sorted unit\n",
    "            n_redundants = len(other_sorted_unit_ids.tolist())\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        n_redundants * [overmerging_matx_2.columns[gt_i]],\n",
    "                        other_sorted_unit_ids.tolist(),\n",
    "                        n_redundants * [\"poorly detected\"],\n",
    "                        n_redundants * [\"redundant\"],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "\n",
    "    # case where ground truth matches only one sorted unit\n",
    "    # with a score b/w detection and chance and\n",
    "    # other units below chance\n",
    "    # no scores are above detection\n",
    "    elif (sum(mask_in_between.iloc[:, gt_i]) == 1) and (\n",
    "        any(mask_above_det.iloc[:, gt_i]) == False\n",
    "    ):\n",
    "        gt_classes.append(\"poorly detected\")\n",
    "\n",
    "        # pair units\n",
    "        unit_id = overmerging_matx_2.index[\n",
    "            np.where(mask_in_between.iloc[:, gt_i] == 1)[0][0]\n",
    "        ]\n",
    "        df2 = pd.DataFrame(\n",
    "            data=np.array(\n",
    "                [\n",
    "                    [overmerging_matx_2.columns[gt_i]],\n",
    "                    [unit_id],\n",
    "                    [\"poorly detected\"],\n",
    "                    [\"poor unit\"],\n",
    "                ]\n",
    "            ).T,\n",
    "            columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "        )\n",
    "        df = pd.concat([df, df2])\n",
    "\n",
    "    # case a true unit is associated is a sorted unit with score\n",
    "    # between detection and chance that is associated with other\n",
    "    # true units with scores between detection and chances\n",
    "    elif sum(mask_in_between.iloc[:, gt_i]) > 1:\n",
    "        gt_classes.append(\"oversplit\")\n",
    "\n",
    "        # pair units\n",
    "        unit_ids = overmerging_matx_2.index[\n",
    "            np.where(mask_in_between.iloc[:, gt_i])[0].tolist()\n",
    "        ].tolist()\n",
    "        n_oversplitters = len(unit_ids)\n",
    "\n",
    "        df2 = pd.DataFrame(\n",
    "            data=np.array(\n",
    "                [\n",
    "                    n_oversplitters * [overmerging_matx_2.columns[gt_i]],\n",
    "                    unit_ids,\n",
    "                    n_oversplitters * [\"oversplit\"],\n",
    "                    n_oversplitters * [\"oversplitters\"],\n",
    "                ]\n",
    "            ).T,\n",
    "            columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "        )\n",
    "        df = pd.concat([df, df2])\n",
    "\n",
    "    # check that all sorted units have scores below\n",
    "    # chance\n",
    "    elif all(mask_below_chance.iloc[:, gt_i]):\n",
    "        if all(mask_entirely_missed.iloc[:, gt_i]):\n",
    "            gt_classes.append(\"missed\")\n",
    "\n",
    "            # pair units\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        [overmerging_matx_2.columns[gt_i]],\n",
    "                        [np.nan],\n",
    "                        [\"missed\"],\n",
    "                        [np.nan],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "        else:\n",
    "            gt_classes.append(\"below chance\")\n",
    "            unit_ids = overmerging_matx_2.index[\n",
    "                np.where(\n",
    "                    (overmerging_matx_2.iloc[:, gt_i] <= chance)\n",
    "                    * (overmerging_matx_2.iloc[:, gt_i] > 0)\n",
    "                )[0]\n",
    "            ].tolist()\n",
    "            n_below_chance = len(unit_ids)\n",
    "\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        n_below_chance * [overmerging_matx_2.columns[gt_i]],\n",
    "                        unit_ids,\n",
    "                        n_below_chance * [\"below chance\"],\n",
    "                        n_below_chance * [\"below chance\"],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "\n",
    "\n",
    "# Detect overmerged units and combinations -------------\n",
    "\n",
    "# if one of its sorted units with score between\n",
    "# detection and chance has also a score between\n",
    "# detection and chance with another true unit\n",
    "# the true unit is overmerged (with another true unit)\n",
    "true_units_loc = np.where(mask_in_between.sum(axis=0) >= 1)[0]\n",
    "true_units = mask_in_between.columns[true_units_loc]\n",
    "gt_overmerged = dict()\n",
    "\n",
    "for gt_i in range(len(true_units_loc)):\n",
    "    target_true_units_mx = mask_in_between.iloc[:, true_units_loc]\n",
    "    sorted_u = np.where(target_true_units_mx.iloc[:, gt_i])[0]\n",
    "\n",
    "    # check overmerged (that sorted unit merges other true units)\n",
    "    if any(mask_in_between.iloc[sorted_u, :].sum(axis=1) > 1):\n",
    "        overmerged_bool = mask_in_between.iloc[sorted_u, :].sum(axis=1) > 1\n",
    "        overmerging_sorted = overmerged_bool.index[\n",
    "            np.where(overmerged_bool)[0]\n",
    "        ].to_list()\n",
    "        gt_overmerged[true_units[gt_i]] = overmerging_sorted\n",
    "\n",
    "# what other biases do overmerged units have?\n",
    "all_true_units = overmerging_matx_2.columns\n",
    "gt_classes_df = pd.DataFrame(data=gt_classes, index=all_true_units.to_list())\n",
    "print(\"combination of biases:\", np.unique(gt_classes_df.loc[gt_overmerged.keys(), :]))\n",
    "\n",
    "# label combination of biases\n",
    "gt_classes_df.loc[gt_overmerged.keys(), :] = gt_classes_df.loc[\n",
    "    gt_overmerged.keys(), :\n",
    "].apply(lambda x: x + \", overmerged\")\n",
    "\n",
    "# poorly detected + overmerged units are poorly detected because overmerged so simply overmerged\n",
    "gt_classes_df[gt_classes_df == \"poorly detected, overmerged\"] = \"overmerged\"\n",
    "df = df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground truth</th>\n",
       "      <th>sorted</th>\n",
       "      <th>ground truth bias</th>\n",
       "      <th>sorted bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1527208</td>\n",
       "      <td>99</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1527208</td>\n",
       "      <td>117</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1527208</td>\n",
       "      <td>124</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1527208</td>\n",
       "      <td>164</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1527208</td>\n",
       "      <td>198</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3547327</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1509317</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514245</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2696195</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1725884</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24696 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ground truth sorted ground truth bias   sorted bias\n",
       "0       1527208     99      below chance  below chance\n",
       "1       1527208    117      below chance  below chance\n",
       "2       1527208    124      below chance  below chance\n",
       "3       1527208    164      below chance  below chance\n",
       "4       1527208    198      below chance  below chance\n",
       "..          ...    ...               ...           ...\n",
       "0       3547327    nan            missed           nan\n",
       "0       1509317    nan            missed           nan\n",
       "0       1514245    nan            missed           nan\n",
       "0       2696195    nan            missed           nan\n",
       "0       1725884    nan            missed           nan\n",
       "\n",
       "[24696 rows x 4 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A sorted unit can show several biases (with different ground truth units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['below chance', 'redundant', 'poor unit'], dtype=object)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 20\n",
    "\n",
    "sorted_ids = df[\"sorted\"].unique()\n",
    "df[df[\"sorted\"] == sorted_ids[ix]][\"sorted bias\"].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_kilosort_silico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
