{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# False positives\n",
    "\n",
    "author: steeve.laquitaine@epfl.ch  \n",
    "last modified: 13-02-2024\n",
    "\n",
    "**Method**:\n",
    "\n",
    "* **delta_time (Œîùë°)** = 1.3 ms: the time windows before and after the spike timestamp of a ground truth. When a the timestamp of a sorted unit falls within this time window, they coincide and the sorted timestamp is a hit.\n",
    "* **chance level score**: see paper\n",
    "* **dark (missed) units**: ground truth units with sorting accuracy below the chance agreement score (their best match with a sorted unit produce an agreement score below chance).\n",
    "* **false positive units**: units which timestamps never hit the timestamps of the ground truth units wihin 50 microns of the probe: they never fall withing the delta_time window.\n",
    "\n",
    "**New!**\n",
    "* delta_time: 1.3 ms instead of 0.4 ms\n",
    "* chance score: theoretically derived instead of 0.1\n",
    "* false positive: units with all scores below chance \n",
    "\n",
    "**TODO**:\n",
    "* do the same for the dense spontaneous recording: ensure that for each layer, we fully cover each layer only once, same as for neuropixels to enable a fair comparison.\n",
    "Because of the multiple probe insertions we might cover a layer twice, which would oversample it and change the overall ratio of sorted unit qualities.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Create or activate env `spikeinterf...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spikeinterface as si\n",
    "\n",
    "# set project path\n",
    "proj_path = \"/gpfs/bbp.cscs.ch/project/proj85/home/laquitai/preprint_2023/\"\n",
    "os.chdir(proj_path)\n",
    "\n",
    "from src.nodes.utils import get_config\n",
    "from src.nodes.analysis.failures import accuracy as acc\n",
    "from src.nodes.metrics import quality\n",
    "from src.nodes.metrics.quality import get_scores_for_dense_probe as gscdp\n",
    "from src.nodes.metrics.quality import get_chance_for_dense_probe as gchdp\n",
    "from src.nodes.metrics.quality import combine_quality_across_dense_probe as cqadb\n",
    "\n",
    "# PARAMETERS\n",
    "DUR = 600 # 10 minutes recording\n",
    "DT = 1.3 #¬†ms (optimized)\n",
    "THR_GOOD = 0.8\n",
    "\n",
    "#¬†DATASETS\n",
    "\n",
    "# NPX PROBE\n",
    "# Synthetic (10m)\n",
    "cfg_nb, _ = get_config(\"buccino_2020\", \"2020\").values()\n",
    "GT_nb_10m = cfg_nb[\"sorting\"][\"simulation\"][\"ground_truth\"][\"10m\"][\"output\"]\n",
    "KS4_nb_10m = cfg_nb[\"sorting\"][\"sorters\"][\"kilosort4\"][\"10m\"][\"output\"]\n",
    "KS3_nb_10m = cfg_nb[\"sorting\"][\"sorters\"][\"kilosort3\"][\"10m\"][\"output\"]\n",
    "KS2_5_nb_10m = cfg_nb[\"sorting\"][\"sorters\"][\"kilosort2_5\"][\"10m\"][\"output\"]\n",
    "KS2_nb_10m = cfg_nb[\"sorting\"][\"sorters\"][\"kilosort2\"][\"10m\"][\"output\"]\n",
    "KS_nb_10m = cfg_nb[\"sorting\"][\"sorters\"][\"kilosort\"][\"10m\"][\"output\"]\n",
    "HS_nb_10m = cfg_nb[\"sorting\"][\"sorters\"][\"herdingspikes\"][\"10m\"][\"output\"]\n",
    "REC_nb = cfg_nb[\"probe_wiring\"][\"full\"][\"output\"]\n",
    "\n",
    "# biophy spont (10m)\n",
    "cfg_ns, _ = get_config(\"silico_neuropixels\", \"concatenated\").values()\n",
    "KS4_ns_10m = cfg_ns[\"sorting\"][\"sorters\"][\"kilosort4\"][\"10m\"][\"output\"]\n",
    "KS3_ns_10m = cfg_ns[\"sorting\"][\"sorters\"][\"kilosort3\"][\"10m\"][\"output\"]\n",
    "KS2_5_ns_10m = cfg_ns[\"sorting\"][\"sorters\"][\"kilosort2_5\"][\"10m\"][\"output\"]\n",
    "KS_ns_10m = cfg_ns[\"sorting\"][\"sorters\"][\"kilosort\"][\"10m\"][\"output\"]\n",
    "HS_ns_10m = cfg_ns[\"sorting\"][\"sorters\"][\"herdingspikes\"][\"10m\"][\"output\"]\n",
    "GT_ns_10m = cfg_ns[\"sorting\"][\"simulation\"][\"ground_truth\"][\"10m\"][\"output\"]\n",
    "REC_ns = cfg_ns[\"probe_wiring\"][\"full\"][\"output\"]\n",
    "\n",
    "# biophy evoked\n",
    "cfg_ne, _ = get_config(\"silico_neuropixels\", \"stimulus\").values()\n",
    "KS4_ne_10m = cfg_ne[\"sorting\"][\"sorters\"][\"kilosort3\"][\"10m\"][\"output\"]\n",
    "KS3_ne_10m = cfg_ne[\"sorting\"][\"sorters\"][\"kilosort3\"][\"10m\"][\"output\"]\n",
    "KS2_ne_10m = cfg_ne[\"sorting\"][\"sorters\"][\"kilosort2\"][\"10m\"][\"output\"]\n",
    "KS_ne_10m = cfg_ne[\"sorting\"][\"sorters\"][\"kilosort\"][\"10m\"][\"output\"]\n",
    "HS_ne_10m = cfg_ne[\"sorting\"][\"sorters\"][\"herdingspikes\"][\"10m\"][\"output\"]\n",
    "GT_ne_10m = cfg_ne[\"sorting\"][\"simulation\"][\"ground_truth\"][\"10m\"][\"output\"]\n",
    "REC_ne = cfg_ne[\"probe_wiring\"][\"full\"][\"output\"]\n",
    "\n",
    "# DENSE PROBE \n",
    "# depth 1\n",
    "cfg_ds1, _ = get_config(\"silico_horvath\", \"concatenated/probe_1\").values()\n",
    "K4_d1 = cfg_ds1[\"sorting\"][\"sorters\"][\"kilosort4\"][\"10m\"][\"output\"]\n",
    "K3_d1 = cfg_ds1[\"sorting\"][\"sorters\"][\"kilosort3\"][\"10m\"][\"output\"]\n",
    "K25_d1 = cfg_ds1[\"sorting\"][\"sorters\"][\"kilosort2_5\"][\"10m\"][\"output\"]\n",
    "K2_d1 = cfg_ds1[\"sorting\"][\"sorters\"][\"kilosort2\"][\"10m\"][\"output\"]\n",
    "K_d1 = cfg_ds1[\"sorting\"][\"sorters\"][\"kilosort\"][\"10m\"][\"output\"]\n",
    "H_d1 = cfg_ds1[\"sorting\"][\"sorters\"][\"herdingspikes\"][\"10m\"][\"output\"]\n",
    "R_d1 = cfg_ds1[\"probe_wiring\"][\"full\"][\"output\"]\n",
    "T_d1 = cfg_ds1[\"sorting\"][\"simulation\"][\"ground_truth\"][\"10m\"][\"output\"]\n",
    "\n",
    "# depth 2\n",
    "cfg_ds2, _ = get_config(\"silico_horvath\", \"concatenated/probe_2\").values()\n",
    "K4_d2 = cfg_ds2[\"sorting\"][\"sorters\"][\"kilosort4\"][\"10m\"][\"output\"]\n",
    "K3_d2 = cfg_ds2[\"sorting\"][\"sorters\"][\"kilosort3\"][\"10m\"][\"output\"]\n",
    "K25_d2 = cfg_ds2[\"sorting\"][\"sorters\"][\"kilosort2_5\"][\"10m\"][\"output\"]\n",
    "K2_d2 = cfg_ds2[\"sorting\"][\"sorters\"][\"kilosort2\"][\"10m\"][\"output\"]\n",
    "K_d2 = cfg_ds2[\"sorting\"][\"sorters\"][\"kilosort\"][\"10m\"][\"output\"]\n",
    "H_d2 = cfg_ds2[\"sorting\"][\"sorters\"][\"herdingspikes\"][\"10m\"][\"output\"]\n",
    "R_d2 = cfg_ds2[\"probe_wiring\"][\"full\"][\"output\"]\n",
    "T_d2 = cfg_ds2[\"sorting\"][\"simulation\"][\"ground_truth\"][\"10m\"][\"output\"]\n",
    "\n",
    "# depth 3\n",
    "cfg_ds3, _ = get_config(\"silico_horvath\", \"concatenated/probe_3\").values()\n",
    "K4_d3 = cfg_ds3[\"sorting\"][\"sorters\"][\"kilosort4\"][\"10m\"][\"output\"]\n",
    "K3_d3 = cfg_ds3[\"sorting\"][\"sorters\"][\"kilosort3\"][\"10m\"][\"output\"]\n",
    "K25_d3 = cfg_ds3[\"sorting\"][\"sorters\"][\"kilosort2_5\"][\"10m\"][\"output\"]\n",
    "K2_d3 = cfg_ds3[\"sorting\"][\"sorters\"][\"kilosort2\"][\"10m\"][\"output\"]\n",
    "K_d3 = cfg_ds3[\"sorting\"][\"sorters\"][\"kilosort\"][\"10m\"][\"output\"]\n",
    "H_d3 = cfg_ds3[\"sorting\"][\"sorters\"][\"herdingspikes\"][\"10m\"][\"output\"]\n",
    "R_d3 = cfg_ds3[\"probe_wiring\"][\"full\"][\"output\"]\n",
    "T_d3 = cfg_ds3[\"sorting\"][\"simulation\"][\"ground_truth\"][\"10m\"][\"output\"]\n",
    "\n",
    "\n",
    "# pre-computed qualities\n",
    "quality_path = \"/gpfs/bbp.cscs.ch/project/proj85/scratch/laquitai/4_preprint_2023/analysis/sorting_quality/sorting_quality.csv\"\n",
    "\n",
    "# FIGURE SETTINGS\n",
    "# ticks\n",
    "N_MJ_TCKS = 5\n",
    "N_MN_TCKS = 11\n",
    "\n",
    "# colors\n",
    "# quality colors\n",
    "cl = {\"good\": [0.7, 0.1, 0.1], #¬†strong red\n",
    "      \"oversplitter\": [0.6, 0.9, 0.6], # blue\n",
    "      \"overmerger\": [0, 0.7, 1], # green\n",
    "      \"mixed: good + overmerger\": np.array([[0.7, 0.1, 0.1], [0, 0.7, 1]]).mean(axis=0),\n",
    "      \"mixed: good + oversplitter\": np.array([[0.7, 0.1, 0.1], [0.6, 0.9, 0.6]]).mean(axis=0),\n",
    "      \"mixed: overmerger + oversplitter\": np.array([[0.6, 0.9, 0.6], [0, 0.7, 1]]).mean(axis=0),\n",
    "      \"mixed: good + overmerger + oversplitter\": np.array([[0.7, 0.1, 0.1], [0, 0.7, 1],[0.6, 0.9, 0.6]]).mean(axis=0),\n",
    "      \"false positive\": [0, 0, 0] #¬†black\n",
    "}\n",
    "\n",
    "# axes\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 6  # 5-7 with Nature neuroscience as reference\n",
    "plt.rcParams[\"lines.linewidth\"] = 0.5 # typically between 0.5 and 1\n",
    "plt.rcParams[\"axes.linewidth\"] = 0.5 #1\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"xtick.major.width\"] = 0.5 #0.8 #* 1.3\n",
    "plt.rcParams[\"xtick.minor.width\"] = 0.5 #0.8 #* 1.3\n",
    "plt.rcParams[\"ytick.major.width\"] = 0.5 #0.8 #* 1.3\n",
    "plt.rcParams[\"ytick.minor.width\"] = 0.5 #0.8 #* 1.3\n",
    "plt.rcParams[\"xtick.major.size\"] = 3.5 * 1.1\n",
    "plt.rcParams[\"xtick.minor.size\"] = 2 * 1.1\n",
    "plt.rcParams[\"ytick.major.size\"] = 3.5 * 1.1\n",
    "plt.rcParams[\"ytick.minor.size\"] = 2 * 1.1\n",
    "# legend\n",
    "legend_cfg = {\"frameon\": False, \"handletextpad\": 0.5}\n",
    "tight_layout_cfg = {\"pad\": 0.001}\n",
    "LG_FRAMEON = False              # no legend frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (30s)Scores\n",
    "\n",
    "* sorted single-units only\n",
    "* 10 minutes recordings\n",
    "* for the dense probe, sorted units filtered such that there is no overepresentation of a layer: from L1, L2/3 from depth 1, L4,5 (depth 2), L6 (depth 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # KS4\n",
    "# # npx-synthetic\n",
    "# scores_nb_ks4, Sorting_nb_ks4, SortingTrue_nb = quality.get_score_single_unit(\n",
    "#     KS4_nb_10m, GT_nb_10m, DT\n",
    "# )\n",
    "## npx-biophy.spont\n",
    "scores_ns_ks4, Sorting_ns_ks4, SortingTrue_ns = quality.get_score_single_unit(\n",
    "    KS4_ns_10m, GT_ns_10m, DT\n",
    ")\n",
    "## npx-biophy.evoked\n",
    "# scores_ne_ks4, Sorting_ne_ks4, SortingTrue_ne = quality.get_score_single_unit(\n",
    "#     KS4_ne_10m, GT_ne_10m, DT\n",
    "# )\n",
    "## dense-biophy.spont\n",
    "(k4_sc, k4_so, k4_t) = gscdp(K4_d1, K4_d2, K4_d3, T_d1, T_d2, T_d3, DT)\n",
    "\n",
    "# # KS3\n",
    "# scores_nb_ks3, Sorting_nb_ks3, SortingTrue_nb = quality.get_score_single_unit(\n",
    "#     KS3_nb_10m, GT_nb_10m, DT\n",
    "# )\n",
    "scores_ns_ks3, Sorting_ns_ks3, SortingTrue_ns = quality.get_score_single_unit(\n",
    "    KS3_ns_10m, GT_ns_10m, DT\n",
    ")\n",
    "# scores_ne_ks3, Sorting_ne_ks3, SortingTrue_ne = quality.get_score_single_unit(\n",
    "#     KS3_ne_10m, GT_ne_10m, DT\n",
    "# )\n",
    "(k3_sc, k3_so, k3_t) = gscdp(K3_d1, K3_d2, K3_d3, T_d1, T_d2, T_d3, DT)\n",
    "\n",
    "# # KS2.5\n",
    "# scores_nb_ks2_5, Sorting_nb_ks2_5, SortingTrue_nb = quality.get_score_single_unit(\n",
    "#     KS3_nb_10m, GT_nb_10m, DT\n",
    "# )\n",
    "scores_ns_ks2_5, Sorting_ns_ks2_5, SortingTrue_ns = quality.get_score_single_unit(\n",
    "    KS3_ns_10m, GT_ns_10m, DT\n",
    ")\n",
    "# scores_ne_ks2_5, Sorting_ne_ks2_5, SortingTrue_ne = quality.get_score_single_unit(\n",
    "#     KS3_ne_10m, GT_ne_10m, DT\n",
    "# )\n",
    "(k25_sc, k25_so, k25_t) = gscdp(K25_d1, K25_d2, K25_d3, T_d1, T_d2, T_d3, DT)\n",
    "\n",
    "# # KS2\n",
    "# scores_nb_ks2, Sorting_nb_ks2, SortingTrue_nb = quality.get_score_single_unit(\n",
    "#     KS3_nb_10m, GT_nb_10m, DT\n",
    "# )\n",
    "scores_ns_ks2, Sorting_ns_ks2, SortingTrue_ns = quality.get_score_single_unit(\n",
    "    KS3_ns_10m, GT_ns_10m, DT\n",
    ")\n",
    "# scores_ne_ks2, Sorting_ne_ks2, SortingTrue_ne = quality.get_score_single_unit(\n",
    "#     KS3_ne_10m, GT_ne_10m, DT\n",
    "# )\n",
    "(k2_sc, k2_so, k2_t) = gscdp(K2_d1, K2_d2, K2_d3, T_d1, T_d2, T_d3, DT)\n",
    "\n",
    "# # KS\n",
    "# scores_nb_ks, Sorting_nb_ks, SortingTrue_nb = quality.get_score_single_unit(\n",
    "#     KS3_nb_10m, GT_nb_10m, DT\n",
    "# )\n",
    "scores_ns_ks, Sorting_ns_ks, SortingTrue_ns = quality.get_score_single_unit(\n",
    "    KS3_ns_10m, GT_ns_10m, DT\n",
    ")\n",
    "# scores_ne_ks, Sorting_ne_ks, SortingTrue_ne = quality.get_score_single_unit(\n",
    "#     KS3_ne_10m, GT_ne_10m, DT\n",
    "# )\n",
    "(K_sc, K_so, K_t) = gscdp(K_d1, K_d2, K_d3, T_d1, T_d2, T_d3, DT)\n",
    "\n",
    "# # HS\n",
    "# scores_nb_hs, Sorting_nb_hs, SortingTrue_nb = quality.get_score_single_unit(\n",
    "#     KS3_nb_10m, GT_nb_10m, DT\n",
    "# )\n",
    "scores_ns_hs, Sorting_ns_hs, SortingTrue_ns = quality.get_score_single_unit(\n",
    "    KS3_ns_10m, GT_ns_10m, DT\n",
    ")\n",
    "# scores_ne_hs, Sorting_ne_hs, SortingTrue_ne = quality.get_score_single_unit(\n",
    "#     KS3_ne_10m, GT_ne_10m, DT\n",
    "# )\n",
    "(H_sc, H_so, H_t) = gscdp(H_d1, H_d2, H_d3, T_d1, T_d2, T_d3, DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (9m)Chance scores\n",
    "\n",
    "* sorted single-units only\n",
    "* chance scores are theoretically derived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-compute chance scores (parallelized)\n",
    "# # KS4\n",
    "# chance_nb_ks4 = quality.precompute_chance_score(\n",
    "#     REC_nb, scores_nb_ks4, Sorting_nb_ks4, SortingTrue_nb, DUR, DT\n",
    "# )\n",
    "chance_ns_ks4 = quality.precompute_chance_score(\n",
    "    REC_ns, scores_ns_ks4, Sorting_ns_ks4, SortingTrue_ns, DUR, DT\n",
    ")\n",
    "# chance_ne_ks4 = quality.precompute_chance_score(\n",
    "#     REC_ne, scores_ne_ks4, Sorting_ne_ks4, SortingTrue_ne, DUR, DT\n",
    "# )\n",
    "## dense-biophy.spont\n",
    "k4_ch = gchdp(DUR, DT, R_d1, R_d2, R_d3, **k4_sc, **k4_so, **k4_t)\n",
    "\n",
    "# # KS3\n",
    "# chance_nb_ks3 = quality.precompute_chance_score(\n",
    "#     REC_nb, scores_nb_ks3, Sorting_nb_ks3, SortingTrue_nb, DUR, DT\n",
    "# )\n",
    "chance_ns_ks3 = quality.precompute_chance_score(\n",
    "    REC_ns, scores_ns_ks3, Sorting_ns_ks3, SortingTrue_ns, DUR, DT\n",
    ")\n",
    "# chance_ne_ks3 = quality.precompute_chance_score(\n",
    "#     REC_ne, scores_ne_ks3, Sorting_ne_ks3, SortingTrue_ne, DUR, DT\n",
    "# )\n",
    "k3_ch = gchdp(DUR, DT, R_d1, R_d2, R_d3, **k3_sc, **k3_so, **k3_t)\n",
    "\n",
    "# # KS2_5\n",
    "# chance_nb_ks2_5 = quality.precompute_chance_score(\n",
    "#     REC_nb, scores_nb_ks2_5, Sorting_nb_ks2_5, SortingTrue_nb, DUR, DT\n",
    "# )\n",
    "chance_ns_ks2_5 = quality.precompute_chance_score(\n",
    "    REC_ns, scores_ns_ks2_5, Sorting_ns_ks2_5, SortingTrue_ns, DUR, DT\n",
    ")\n",
    "# chance_ne_ks2_5 = quality.precompute_chance_score(\n",
    "#     REC_ne, scores_ne_ks2_5, Sorting_ne_ks2_5, SortingTrue_ne, DUR, DT\n",
    "# )\n",
    "k25_ch = gchdp(DUR, DT, R_d1, R_d2, R_d3, **k25_sc, **k25_so, **k25_t)\n",
    "\n",
    "# # KS2\n",
    "# chance_nb_ks2 = quality.precompute_chance_score(\n",
    "#     REC_nb, scores_nb_ks2, Sorting_nb_ks2, SortingTrue_nb, DUR, DT\n",
    "# )\n",
    "chance_ns_ks2 = quality.precompute_chance_score(\n",
    "    REC_ns, scores_ns_ks2, Sorting_ns_ks2, SortingTrue_ns, DUR, DT\n",
    ")\n",
    "# chance_ne_ks2 = quality.precompute_chance_score(\n",
    "#     REC_ne, scores_ne_ks2, Sorting_ne_ks2, SortingTrue_ne, DUR, DT\n",
    "# )\n",
    "k2_ch = gchdp(DUR, DT, R_d1, R_d2, R_d3, **k2_sc, **k2_so, **k2_t)\n",
    "\n",
    "# # KS\n",
    "# chance_nb_ks = quality.precompute_chance_score(\n",
    "#     REC_nb, scores_nb_ks, Sorting_nb_ks, SortingTrue_nb, DUR, DT\n",
    "# )\n",
    "chance_ns_ks = quality.precompute_chance_score(\n",
    "    REC_ns, scores_ns_ks, Sorting_ns_ks, SortingTrue_ns, DUR, DT\n",
    ")\n",
    "# chance_ne_ks = quality.precompute_chance_score(\n",
    "#     REC_ne, scores_ne_ks, Sorting_ne_ks, SortingTrue_ne, DUR, DT\n",
    "# )\n",
    "K_ch = gchdp(DUR, DT, R_d1, R_d2, R_d3, **K_sc, **K_so, **K_t)\n",
    "\n",
    "# # HS\n",
    "# chance_nb_hs = quality.precompute_chance_score(\n",
    "#     REC_nb, scores_nb_hs, Sorting_nb_hs, SortingTrue_nb, DUR, DT\n",
    "# )\n",
    "chance_ns_hs = quality.precompute_chance_score(\n",
    "    REC_ns, scores_ns_hs, Sorting_ns_hs, SortingTrue_ns, DUR, DT\n",
    ")\n",
    "# chance_ne_hs = quality.precompute_chance_score(\n",
    "#     REC_ne, scores_ne_hs, Sorting_ne_hs, SortingTrue_ne, DUR, DT\n",
    "# )\n",
    "H_ch = gchdp(DUR, DT, R_d1, R_d2, R_d3, **H_sc, **H_so, **H_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (36m)Sorted unit quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6m) qualify all sorted single-units\n",
    "# (18m) KS4\n",
    "df_ns_ks4 = quality.qualify_sorted_units(scores_ns_ks4, chance_ns_ks4, THR_GOOD)\n",
    "# df_nb_ks4 = quality.qualify_sorted_units(scores_nb_ks4, chance_nb_ks4, THR_GOOD)\n",
    "# df_ne_ks4 = quality.qualify_sorted_units(scores_ne_ks4, chance_ne_ks4, THR_GOOD)\n",
    "df_ds_ks4 = cqadb(THR_GOOD, K4_d1, K4_d2, K4_d3, **k4_sc, **k4_ch)\n",
    "# # KS3\n",
    "df_ns_ks3 = quality.qualify_sorted_units(scores_ns_ks3, chance_ns_ks3, THR_GOOD)\n",
    "# df_nb_ks3 = quality.qualify_sorted_units(scores_nb_ks3, chance_nb_ks3, THR_GOOD)\n",
    "# df_ne_ks3 = quality.qualify_sorted_units(scores_ne_ks3, chance_ne_ks3, THR_GOOD)\n",
    "df_ds_ks3 = cqadb(THR_GOOD, K3_d1, K3_d2, K3_d3, **k3_sc, **k3_ch)\n",
    "# # KS2.5\n",
    "df_ns_ks2_5 = quality.qualify_sorted_units(scores_ns_ks2_5, chance_ns_ks2_5, THR_GOOD)\n",
    "# df_nb_ks2_5 = quality.qualify_sorted_units(scores_nb_ks2_5, chance_nb_ks2_5, THR_GOOD)\n",
    "# df_ne_ks2_5 = quality.qualify_sorted_units(scores_ne_ks2_5, chance_ne_ks2_5, THR_GOOD)\n",
    "df_ds_ks25 = cqadb(THR_GOOD, K25_d1, K25_d2, K25_d3, **k25_sc, **k25_ch)\n",
    "# # KS2\n",
    "df_ns_ks2 = quality.qualify_sorted_units(scores_ns_ks2, chance_ns_ks2, THR_GOOD)\n",
    "# df_nb_ks2 = quality.qualify_sorted_units(scores_nb_ks2, chance_nb_ks2, THR_GOOD)\n",
    "# df_ne_ks2 = quality.qualify_sorted_units(scores_ne_ks2, chance_ne_ks2, THR_GOOD)\n",
    "df_ds_ks2 = cqadb(THR_GOOD, K2_d1, K2_d2, K2_d3, **k2_sc, **k2_ch)\n",
    "# # KS\n",
    "df_ns_ks = quality.qualify_sorted_units(scores_ns_ks, chance_ns_ks, THR_GOOD)\n",
    "# df_nb_ks = quality.qualify_sorted_units(scores_nb_ks, chance_nb_ks, THR_GOOD)\n",
    "# df_ne_ks = quality.qualify_sorted_units(scores_ne_ks, chance_ne_ks, THR_GOOD)\n",
    "df_ds_ks = cqadb(THR_GOOD, K_d1, K_d2, K_d3, **K_sc, **K_ch)\n",
    "# # HS\n",
    "df_ns_hs = quality.qualify_sorted_units(scores_ns_hs, chance_ns_hs, THR_GOOD)\n",
    "# df_nb_hs = quality.qualify_sorted_units(scores_nb_hs, chance_nb_hs, THR_GOOD)\n",
    "# df_ne_hs = quality.qualify_sorted_units(scores_ne_hs, chance_ne_hs, THR_GOOD)\n",
    "df_ds_h = cqadb(THR_GOOD, H_d1, H_d2, H_d3, **H_sc, **H_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiments\n",
    "# KS4\n",
    "df_ns_ks4[\"sorter\"] = \"KS4\"\n",
    "df_ns_ks4[\"experiment\"] = \"NS\"\n",
    "# df_nb_ks4[\"sorter\"] = \"KS4\"\n",
    "# df_nb_ks4[\"experiment\"] = \"S\"\n",
    "# df_ne_ks4[\"sorter\"] = \"KS4\"\n",
    "# df_ne_ks4[\"experiment\"] = \"E\"\n",
    "df_ds_ks4[\"sorter\"] = \"KS4\"\n",
    "df_ds_ks4[\"experiment\"] = \"DS\"\n",
    "\n",
    "# # KS3\n",
    "df_ns_ks3[\"sorter\"] = \"KS3\"\n",
    "df_ns_ks3[\"experiment\"] = \"NS\"\n",
    "# df_nb_ks3[\"sorter\"] = \"KS3\"\n",
    "# df_nb_ks3[\"experiment\"] = \"S\"\n",
    "# df_ne_ks3[\"sorter\"] = \"KS3\"\n",
    "# df_ne_ks3[\"experiment\"] = \"E\"\n",
    "df_ds_ks3[\"sorter\"] = \"KS3\"\n",
    "df_ds_ks3[\"experiment\"] = \"DS\"\n",
    "\n",
    "# # KS2.5\n",
    "df_ns_ks2_5[\"sorter\"] = \"KS2.5\"\n",
    "df_ns_ks2_5[\"experiment\"] = \"NS\"\n",
    "# df_nb_ks2_5[\"sorter\"] = \"KS2.5\"\n",
    "# df_nb_ks2_5[\"experiment\"] = \"S\"\n",
    "# df_ne_ks2_5[\"sorter\"] = \"KS2.5\"\n",
    "# df_ne_ks2_5[\"experiment\"] = \"E\"\n",
    "df_ds_ks25[\"sorter\"] = \"KS2.5\"\n",
    "df_ds_ks25[\"experiment\"] = \"DS\"\n",
    "\n",
    "# # KS2\n",
    "df_ns_ks2[\"sorter\"] = \"KS2\"\n",
    "df_ns_ks2[\"experiment\"] = \"NS\"\n",
    "# df_nb_ks2[\"sorter\"] = \"KS2\"\n",
    "# df_nb_ks2[\"experiment\"] = \"S\"\n",
    "# df_ne_ks2[\"sorter\"] = \"KS2\"\n",
    "# df_ne_ks2[\"experiment\"] = \"E\"\n",
    "df_ds_ks2[\"sorter\"] = \"KS2\"\n",
    "df_ds_ks2[\"experiment\"] = \"DS\"\n",
    "\n",
    "# # KS\n",
    "df_ns_ks[\"sorter\"] = \"KS\"\n",
    "df_ns_ks[\"experiment\"] = \"NS\"\n",
    "# df_nb_ks[\"sorter\"] = \"KS\"\n",
    "# df_nb_ks[\"experiment\"] = \"S\"\n",
    "# df_ne_ks[\"sorter\"] = \"KS\"\n",
    "# df_ne_ks[\"experiment\"] = \"E\"\n",
    "df_ds_ks[\"sorter\"] = \"KS\"\n",
    "df_ds_ks[\"experiment\"] = \"DS\"\n",
    "\n",
    "# # HS\n",
    "df_ns_hs[\"sorter\"] = \"HS\"\n",
    "df_ns_hs[\"experiment\"] = \"NS\"\n",
    "# df_nb_hs[\"sorter\"] = \"HS\"\n",
    "# df_nb_hs[\"experiment\"] = \"S\"\n",
    "# df_ne_hs[\"sorter\"] = \"HS\"\n",
    "# df_ne_hs[\"experiment\"] = \"E\"\n",
    "df_ds_h[\"sorter\"] = \"HS\"\n",
    "df_ds_h[\"experiment\"] = \"DS\"\n",
    "\n",
    "# concatenate\n",
    "df = pd.concat(\n",
    "    [\n",
    "        df_ns_ks4,\n",
    "        # df_nb_ks4,\n",
    "        # df_ne_ks4,\n",
    "        df_ns_ks3,\n",
    "        # df_nb_ks3,\n",
    "        # df_ne_ks3,\n",
    "        df_ns_ks2_5,\n",
    "        # df_nb_ks2_5,\n",
    "        # df_ne_ks2_5,\n",
    "        df_ns_ks2,\n",
    "        # df_nb_ks2,\n",
    "        # df_ne_ks2,\n",
    "        df_ns_ks,\n",
    "        # df_nb_ks,\n",
    "        # df_ne_ks,\n",
    "        df_ns_hs,\n",
    "        # df_nb_hs,\n",
    "        # df_ne_hs,\n",
    "    ]\n",
    ")\n",
    "df = df.sort_values(\"quality\")\n",
    "\n",
    "# temp save\n",
    "# df.to_csv(\"sorting_quality.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pre-computed data\n",
    "# df = pd.read_csv(quality_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot by experiment x sorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# plot - kilosort 4\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ax \u001b[38;5;241m=\u001b[39m quality\u001b[38;5;241m.\u001b[39mplot_ratio_by_exp(\u001b[43mdf\u001b[49m[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msorter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKS4\u001b[39m\u001b[38;5;124m\"\u001b[39m], cl, legend_cfg)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# plot - kilosort 3\u001b[39;00m\n\u001b[1;32m      5\u001b[0m ax \u001b[38;5;241m=\u001b[39m quality\u001b[38;5;241m.\u001b[39mplot_ratio_by_exp(df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msorter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKS3\u001b[39m\u001b[38;5;124m\"\u001b[39m], cl, legend_cfg)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# plot - kilosort 4\n",
    "ax = quality.plot_ratio_by_exp(df[df[\"sorter\"] == \"KS4\"], cl, legend_cfg)\n",
    "\n",
    "# plot - kilosort 3\n",
    "ax = quality.plot_ratio_by_exp(df[df[\"sorter\"] == \"KS3\"], cl, legend_cfg)\n",
    "\n",
    "# plot - kilosort 2.5\n",
    "ax = quality.plot_ratio_by_exp(df[df[\"sorter\"] == \"KS2.5\"], cl, legend_cfg)\n",
    "\n",
    "# plot - kilosort 2\n",
    "ax = quality.plot_ratio_by_exp(df[df[\"sorter\"] == \"KS2\"], cl, legend_cfg)\n",
    "\n",
    "# plot - kilosort\n",
    "ax = quality.plot_ratio_by_exp(df[df[\"sorter\"] == \"KS\"], cl, legend_cfg)\n",
    "\n",
    "# plot - herdingspikes\n",
    "ax = quality.plot_ratio_by_exp(df[df[\"sorter\"] == \"HS\"], cl, legend_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "(1) https://neuronaldynamics.epfl.ch/online/Ch7.S2.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_kilosort_silico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
