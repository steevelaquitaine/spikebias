{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias types (Kilosort 2.5)\n",
    "\n",
    "author: steeve.laquitaine@epfl.ch  \n",
    "last modified: 13-02-2024\n",
    "status: OK  \n",
    "regression: None  \n",
    "\n",
    "Purpose: Characterize and quantify ground truth sorting quality and biases from matching with best matching sorted units\n",
    "\n",
    "Notes:\n",
    "* pros of Kilosort 3.0:\n",
    "    * fully automated to produce single units (isolated from multi-units via additional postprocessing label \"KSlabel\")\n",
    "    * very efficient algorithm\n",
    "    * very recent and well maintained, was very easy to setup and run from SpikeInterface\n",
    "    * the most used and cited by recent studies, in high-impact papers\n",
    "\n",
    "\n",
    "We define biases types to characterize what happens to the true units (not with respect to sorted unit). This allows the proportion of all biases to sum to 100% over true units.\n",
    "\n",
    "Based on our definitions:\n",
    "\n",
    "* Possible biases types are:  \n",
    "    * well detected\n",
    "    * well detected + correlated unit\n",
    "    * poorly detected    \n",
    "    * oversplit\n",
    "    * overmerged (include overmerged + poorly detected because this combination is always due to overmerging)   \n",
    "    * overmerged + oversplit\n",
    "    * overmerged + well detected + correlated unit\n",
    "    * below chance    \n",
    "    * missed\n",
    "* Impossible biases types are:\n",
    "    * poorly detected + oversplit (impossible because poorly detected requires matching at max a single sorted unit above chance, while oversplit requires matching at least two units)\n",
    "\n",
    "\n",
    "To detect overmerged units and combinations\n",
    "\n",
    "* need to look from perspective of sorted units\n",
    "* A true unit is overmerged (with other true units) if it has at least one sorted units with a score between detection and chance that also has a score between detection and chance with another true unit.\n",
    "* a poorly sorted units (accuracy between 0.1 and 0.8) can thus be overmerged (it fuse together half the spike trains of two true units). In that case it is classified as overmerged.\n",
    "\n",
    "**Sorted unit biases**\n",
    "\n",
    "* Method: \n",
    "    * sorted units were matched with ground truth unit producing N ground truth pairs (each ground truth was paired with its highest accuracy sorted unit). \n",
    "    * this can produce situations where a single sorted unit can be paired with different ground truths.\n",
    "    * among these pairing, we select the pairing with the highest agreement score accuracy yielding a single ground truth for each sorted unit and N sorted units pairs.\n",
    "    * When the number of resulting sorted units pairs is below the number of isolated sorted single units, the missing sorted units are false positive sorted units\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Create or activate env `npx_10m_384ch_unit_classes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 13:49:48,680 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-02-15 13:49:48,694 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2024-02-15 13:49:48,695 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-02-15 13:49:48,720 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2024-02-15 13:49:48,721 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-02-15 13:49:48,741 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2024-02-15 13:49:48,742 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-02-15 13:49:48,772 - root - utils.py - get_config - INFO - Reading experiment config. - done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import spikeinterface as si\n",
    "import copy\n",
    "proj_path = \"/gpfs/bbp.cscs.ch/project/proj85/home/laquitai/preprint_2023/\"\n",
    "os.chdir(proj_path)\n",
    "\n",
    "from src.nodes.postpro.cell_matching import get_SpikeInterface_matching_object, match_sorted_to_true_neuropixels_2023_02_19\n",
    "from src.nodes.utils import get_config\n",
    "from src.nodes.postpro.feateng import (add_firing_rates)\n",
    "from src.nodes.postpro import spikestats\n",
    "\n",
    "# set classification parameters\n",
    "LOW_RATE_CEILING = 0.2  # max firing rate where negative proba change is observed in \"bias plot\" (sparse units)\n",
    "DET_THRESH = 0.8\n",
    "CHANCE_THRESH = 0.1\n",
    "\n",
    "# buccino\n",
    "data_conf, param_conf = get_config(\"buccino_2020\", \"2020\").values()\n",
    "SORTING_PATH_b = data_conf[\"sorting\"][\"sorters\"][\"kilosort2_5\"][\"output\"]\n",
    "GT_SORTING_PATH_b = data_conf[\"sorting\"][\"simulation\"][\"ground_truth\"][\"output\"]\n",
    "RECORDING_PATH_b = data_conf[\"recording\"][\"output\"]\n",
    "SORTING_PATH_b = data_conf[\"sorting\"][\"sorters\"][\"kilosort2_5\"][\"output\"]\n",
    "\n",
    "# silico marques\n",
    "data_conf, param_conf = get_config(\"silico_neuropixels\", \"2023_10_18\").values()\n",
    "SORTING_PATH_m = data_conf[\"sorting\"][\"sorters\"][\"kilosort2_5\"][\"output\"]\n",
    "GT_SORTING_PATH_m = data_conf[\"sorting\"][\"simulation\"][\"ground_truth\"][\"output\"]\n",
    "RECORDING_PATH_m = data_conf[\"recording\"][\"output\"]\n",
    "SORTING_PATH_m = data_conf[\"sorting\"][\"sorters\"][\"kilosort2_5\"][\"output\"]\n",
    "\n",
    "# silico horvath\n",
    "data_conf, param_conf = get_config(\"silico_horvath\", \"concatenated/probe_1\").values()\n",
    "SORTING_PATH_h = data_conf[\"sorting\"][\"sorters\"][\"kilosort2_5\"][\"output\"]\n",
    "GT_SORTING_PATH_h = data_conf[\"sorting\"][\"simulation\"][\"ground_truth\"][\"output\"]\n",
    "RECORDING_PATH_h = data_conf[\"recording\"][\"output\"]\n",
    "SORTING_PATH_h = data_conf[\"sorting\"][\"sorters\"][\"kilosort2_5\"][\"output\"]\n",
    "\n",
    "# silico stimulus\n",
    "data_conf, param_conf = get_config(\"silico_neuropixels\", \"stimulus\").values()\n",
    "SORTING_PATH_e = data_conf[\"sorting\"][\"sorters\"][\"kilosort2_5\"][\"output\"]\n",
    "GT_SORTING_PATH_e = data_conf[\"sorting\"][\"simulation\"][\"ground_truth\"][\"output\"]\n",
    "RECORDING_PATH_e = data_conf[\"recording\"][\"output\"]\n",
    "SORTING_PATH_e = data_conf[\"sorting\"][\"sorters\"][\"kilosort2_5\"][\"output\"]\n",
    "\n",
    "\n",
    "# FIGURE SETTINGS\n",
    "COLOR_VIVO = (0.7, 0.7, 0.7)\n",
    "COLOR_SILI = (0.84, 0.27, 0.2)\n",
    "COLOR_STIM = (0.6, 0.75, 0.1)\n",
    "BOX_ASPECT = 1                  # square fig\n",
    "FIG_SIZE = (1,1)\n",
    "plt.rcParams['figure.figsize'] = (2,1)\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 6\n",
    "plt.rcParams['lines.linewidth'] = 0.2\n",
    "plt.rcParams['axes.linewidth'] = 0.5\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['xtick.major.width'] = 0.3\n",
    "plt.rcParams['xtick.minor.size'] = 0.1\n",
    "plt.rcParams['xtick.major.size'] = 1.5\n",
    "plt.rcParams['ytick.major.size'] = 1.5\n",
    "plt.rcParams['ytick.major.width'] = 0.3\n",
    "legend_cfg = {\"frameon\": False, \"handletextpad\": 0.1}\n",
    "savefig_cfg = {\"transparent\":True}\n",
    "# print(plt.rcParams.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_agreement_matrix(MatchingObject):\n",
    "\n",
    "    # get sorted x true units' agreement scores\n",
    "    overmerging_matx = MatchingObject.agreement_scores.T\n",
    "\n",
    "    # sort each row such that the row with the highest score be first, while column order stays unchanged\n",
    "    argmax = overmerging_matx.T.idxmax().to_frame()\n",
    "    max = overmerging_matx.T.max()\n",
    "    descending_ix = np.argsort(max)[::-1]\n",
    "    overmerging_matx_2 = overmerging_matx.iloc[descending_ix]\n",
    "\n",
    "    # repeat for columns, row order stays auntouched\n",
    "    argmax = overmerging_matx_2.idxmax().to_frame()\n",
    "    max = overmerging_matx_2.max()\n",
    "    descending_ix = np.argsort(max)[::-1]\n",
    "    return overmerging_matx_2.iloc[:, descending_ix]\n",
    "\n",
    "\n",
    "def classify_true_unit_biases(overmerging_matx_2, det_thresh, chance):\n",
    "\n",
    "    # create masks\n",
    "    mask_above_det = overmerging_matx_2 >= det_thresh\n",
    "    mask_below_chance = overmerging_matx_2 <= chance\n",
    "    mask_in_between = np.logical_and(\n",
    "        overmerging_matx_2 < det_thresh, overmerging_matx_2 > chance\n",
    "    )\n",
    "    mask_entirely_missed = overmerging_matx_2 == 0\n",
    "\n",
    "    # implement tree to classify ground truths\n",
    "    # find ground truth (cols) with one mask_above_det=True and other mask_below_chance = True\n",
    "\n",
    "    gt_classes = []\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # loop over ground truth units\n",
    "    for gt_i in range(overmerging_matx_2.shape[1]):\n",
    "\n",
    "        # check if that ground truth has a single sorted unit\n",
    "        # with an agreement score above detection threshold\n",
    "        if any(mask_above_det.iloc[:, gt_i]):\n",
    "\n",
    "            # get this ground truth detection stata\n",
    "            is_detected = mask_above_det.iloc[:, gt_i]\n",
    "            detected_loc = np.where(is_detected)[0]\n",
    "            detected_ix = is_detected.index[detected_loc]\n",
    "\n",
    "            # get other cells\n",
    "            other_cells_ix = is_detected.drop(index=detected_ix).index\n",
    "\n",
    "            # get this ground truth below chance stata\n",
    "            is_below_chance = mask_below_chance.iloc[:, gt_i]\n",
    "\n",
    "            # check if all other sorted units are below chance\n",
    "            if all(is_below_chance.loc[other_cells_ix]):\n",
    "                gt_classes.append(\"well detected\")\n",
    "\n",
    "            # if another unit has an agreement score\n",
    "            # above chance level, it is: well detected + correlated unit\n",
    "            else:\n",
    "                gt_classes.append(\"well detected, correlated\")\n",
    "\n",
    "        # case where ground truth matches only one sorted unit\n",
    "        # with a score b/w detection and chance and\n",
    "        # other units below chance\n",
    "        # no score are above detection\n",
    "        elif (sum(mask_in_between.iloc[:, gt_i]) == 1) and (\n",
    "            any(mask_above_det.iloc[:, gt_i]) == False\n",
    "        ):\n",
    "            gt_classes.append(\"poorly detected\")\n",
    "\n",
    "        # case a true unit is associated is a sorted unit with score\n",
    "        # between detection and chance that is associated with other\n",
    "        # true units with scores between detection and chances\n",
    "        elif sum(mask_in_between.iloc[:, gt_i]) > 1:\n",
    "            gt_classes.append(\"oversplit\")\n",
    "\n",
    "        # check that all sorted units have scores below\n",
    "        # chance\n",
    "        elif all(mask_below_chance.iloc[:, gt_i]):\n",
    "            if all(mask_entirely_missed.iloc[:, gt_i]):\n",
    "                gt_classes.append(\"missed\")\n",
    "            else:\n",
    "                gt_classes.append(\"below chance\")\n",
    "\n",
    "    # Detect overmerged units and combinations -------------\n",
    "\n",
    "    # if one of its sorted units with score between\n",
    "    # detection and chance has also a score between\n",
    "    # detection and chance with another true unit\n",
    "    # the true unit is overmerged (with another true unit)\n",
    "    true_units_loc = np.where(mask_in_between.sum(axis=0) >= 1)[0]\n",
    "    true_units = mask_in_between.columns[true_units_loc]\n",
    "    gt_overmerged = dict()\n",
    "\n",
    "    for gt_i in range(len(true_units_loc)):\n",
    "        target_true_units_mx = mask_in_between.iloc[:, true_units_loc]\n",
    "        sorted_u = np.where(target_true_units_mx.iloc[:, gt_i])[0]\n",
    "\n",
    "        # check overmerged (that sorted unit merges other true units)\n",
    "        if any(mask_in_between.iloc[sorted_u, :].sum(axis=1) > 1):\n",
    "            overmerged_bool = mask_in_between.iloc[sorted_u, :].sum(axis=1) > 1\n",
    "            overmerging_sorted = overmerged_bool.index[\n",
    "                np.where(overmerged_bool)[0]\n",
    "            ].to_list()\n",
    "            gt_overmerged[true_units[gt_i]] = overmerging_sorted\n",
    "\n",
    "    # what other biases do overmerged units have?\n",
    "    all_true_units = overmerging_matx_2.columns\n",
    "    gt_classes_df = pd.DataFrame(data=gt_classes, index=all_true_units.to_list())\n",
    "    print(\n",
    "        \"combination of biases:\", np.unique(gt_classes_df.loc[gt_overmerged.keys(), :])\n",
    "    )\n",
    "\n",
    "    # label combination of biases\n",
    "    gt_classes_df.loc[gt_overmerged.keys(), :] = gt_classes_df.loc[\n",
    "        gt_overmerged.keys(), :\n",
    "    ].apply(lambda x: x + \", overmerged\")\n",
    "\n",
    "    # poorly detected + overmerged units are poorly detected because overmerged so simply overmerged\n",
    "    gt_classes_df[gt_classes_df == \"poorly detected, overmerged\"] = \"overmerged\"\n",
    "    return gt_classes_df\n",
    "\n",
    "\n",
    "def create_true_biases_df(true_biases_series):\n",
    "\n",
    "    # format dataframe to plot\n",
    "    bias_types = [\n",
    "        \"well detected\",\n",
    "        \"well detected, correlated\",\n",
    "        \"well detected, correlated, overmerged\",\n",
    "        \"poorly detected\",\n",
    "        \"overmerged\",\n",
    "        \"oversplit\",\n",
    "        \"oversplit, overmerged\",\n",
    "        \"below chance\",\n",
    "        \"missed\",\n",
    "    ]\n",
    "\n",
    "    # count each bias\n",
    "    count_by_class = dict(Counter(true_biases_series.values.squeeze().tolist()))\n",
    "\n",
    "    # fill up count per bias\n",
    "    for key_k in bias_types:\n",
    "        try:\n",
    "            count_by_class[key_k]\n",
    "        except:\n",
    "            count_by_class[key_k] = 0\n",
    "\n",
    "    # order by \"bias_types\"\n",
    "    reordered = {k: count_by_class[k] for k in bias_types}\n",
    "\n",
    "    # create table\n",
    "    biases_ratio_df = pd.DataFrame(\n",
    "        {\"cell_count\": list(reordered.values())}, index=list(reordered.keys())\n",
    "    )\n",
    "    return biases_ratio_df\n",
    "\n",
    "\n",
    "def plot_biases(axis, biases_count: pd.DataFrame):\n",
    "\n",
    "    # set colors for combination of biases\n",
    "    oversplit_plus_overmerged = np.array([[0.6, 0.9, 0.6], [0, 0.7, 1]]).mean(axis=0)\n",
    "    well_detected_plus_correlated_units_plus_overmerged = np.array(\n",
    "        [[1, 0, 0], [0, 0.7, 1]]\n",
    "    ).mean(axis=0)\n",
    "\n",
    "    # set all colors\n",
    "    colors = [\n",
    "        [0.7, 0.1, 0.1],  # \"well_detected\" (strong red)\n",
    "        [1, 0, 0],  # \"well_detected_plus_correlated_units\" (red)\n",
    "        well_detected_plus_correlated_units_plus_overmerged,\n",
    "        [1, 0.85, 0.85],  # \"poorly_detected\" (pink)\n",
    "        [0, 0.7, 1],  # \"overmerged\" (green)\n",
    "        [0.6, 0.9, 0.6],  # \"oversplit\" (blue)\n",
    "        oversplit_plus_overmerged,\n",
    "        [0.95, 0.95, 0.95],  # \"below chance\"\n",
    "        \"k\",  # \"missed\"\n",
    "    ]\n",
    "\n",
    "    biases_ratio = biases_count / biases_count.sum()\n",
    "\n",
    "    # plot\n",
    "    ax = (biases_ratio).T.plot.bar(\n",
    "        ax=axis,\n",
    "        stacked=True,\n",
    "        color=colors,\n",
    "        width=0.9,\n",
    "        edgecolor=[0.5, 0.5, 0.5],\n",
    "        linewidth=0.2,\n",
    "    )\n",
    "\n",
    "    # set axis legend\n",
    "    ax.spines[[\"left\", \"right\", \"top\", \"bottom\"]].set_visible(False)\n",
    "    y_axis = ax.axes.get_yaxis()\n",
    "    y_axis.set_visible(False)\n",
    "    ax.set_xticklabels(biases_ratio.columns, rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel(\"Sorting biases (ratio)\", fontsize=9)\n",
    "\n",
    "    ax.legend(\n",
    "        biases_count.index,\n",
    "        ncol=1,\n",
    "        loc=\"lower left\",\n",
    "        bbox_to_anchor=(1, 0),\n",
    "        frameon=False,\n",
    "        handletextpad=0.6,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return axis\n",
    "\n",
    "\n",
    "def plot_heatmap(overmerging_matx_2):\n",
    "\n",
    "    # plot\n",
    "    # fig, axis = plt.subplots(1, 1, figsize=(2, 10))\n",
    "\n",
    "    # plot agreement matrix\n",
    "    mx_to_plot = overmerging_matx_2.iloc[:500, :500].values\n",
    "    fig, axis = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        mx_to_plot,\n",
    "        cmap=\"jet\",\n",
    "        cbar_kws={\"shrink\": 0.5},\n",
    "        yticklabels=False,\n",
    "        xticklabels=False,\n",
    "    )\n",
    "    plt.xlabel(\"true units\")\n",
    "    plt.ylabel(\"sorted units\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "\n",
    "def classify_sorted_unit_biases(agreem_mx):\n",
    "\n",
    "    # note: with this approach (BEST matching approach), the same sorted unit can be paired with more than one true unit\n",
    "    # we only keep the pairings with highest agreement scores\n",
    "    # true-sorted unit pairing\n",
    "    pairing = agreem_mx.T.idxmax(axis=1)\n",
    "    pairing = pairing.to_frame()\n",
    "    pairing.columns = [\"sorted\"]\n",
    "\n",
    "    # add agreement score\n",
    "    accuracy = agreem_mx.T.max(axis=1)\n",
    "    pairing[\"accuracy\"] = accuracy\n",
    "\n",
    "    # check if the only sorted unit paired with this true unit\n",
    "    sorted_ids = agreem_mx.index\n",
    "\n",
    "    df = copy.copy(pairing.iloc[0, :].to_frame().T)\n",
    "    false_positives = []\n",
    "\n",
    "    # else keep the pairing with highest agreement score\n",
    "    # loop over all sorted single unit units\n",
    "    for ix in range(len(sorted_ids)):\n",
    "        # case the sorted unit was paired with a ground truth unit\n",
    "        if any(pairing[\"sorted\"] == sorted_ids[ix]):\n",
    "            sorted_pairings = pairing[pairing[\"sorted\"] == sorted_ids[ix]].sort_values(\n",
    "                by=\"accuracy\", ascending=False\n",
    "            )\n",
    "            # take max pairing (first row)\n",
    "            df = pd.concat([df, sorted_pairings.iloc[0, :].to_frame().T])\n",
    "        else:\n",
    "            # case the sorted unit was paired with none of the ground truth units\n",
    "            false_positives.append(sorted_ids[ix])\n",
    "\n",
    "    df = df[1:]\n",
    "    df[\"sorted\"] = df[\"sorted\"].astype(int)\n",
    "\n",
    "    # count biases\n",
    "    n_good = sum(df[\"accuracy\"] >= DET_THRESH)\n",
    "    n_poor = sum((df[\"accuracy\"] >= CHANCE_THRESH) & (df[\"accuracy\"] < DET_THRESH))\n",
    "    n_below_chance = sum((df[\"accuracy\"] > 0) & (df[\"accuracy\"] < CHANCE_THRESH))\n",
    "    n_false_pos = len(false_positives)\n",
    "\n",
    "    # sanity check\n",
    "    assert n_good + n_poor + n_below_chance + n_false_pos == len(\n",
    "        sorted_ids\n",
    "    ), \"They must match\"\n",
    "    return {\n",
    "        \"n_good\": n_good,\n",
    "        \"n_poor\": n_poor,\n",
    "        \"n_below_chance\": n_below_chance,\n",
    "        \"n_false_pos\": n_false_pos,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sorted x true agreement matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 2 min\n",
    "\n",
    "# get true/sorted matching object\n",
    "MatchingObject_b = get_SpikeInterface_matching_object(GT_SORTING_PATH_b, SORTING_PATH_b)\n",
    "MatchingObject_m = get_SpikeInterface_matching_object(GT_SORTING_PATH_m, SORTING_PATH_m)\n",
    "MatchingObject_h = get_SpikeInterface_matching_object(GT_SORTING_PATH_h, SORTING_PATH_h)\n",
    "MatchingObject_e = get_SpikeInterface_matching_object(GT_SORTING_PATH_e, SORTING_PATH_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sort each row in descending order. The columns are not labelled as the raw ground truth anymore but become labelled as best match ground truth to the worst match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreem_mx_b = format_agreement_matrix(MatchingObject_b)\n",
    "agreem_mx_m = format_agreement_matrix(MatchingObject_m)\n",
    "agreem_mx_h = format_agreement_matrix(MatchingObject_h)\n",
    "agreem_mx_e = format_agreement_matrix(MatchingObject_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot biases (matching only the best matching sorted single units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the sorted single units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the sorted single units\n",
    "\n",
    "# buccino\n",
    "Sorting = si.load_extractor(SORTING_PATH_b)\n",
    "agreem_mx_b = agreem_mx_b.loc[\n",
    "    Sorting.unit_ids[Sorting.get_property(\"KSLabel\") == \"good\"], :\n",
    "]\n",
    "\n",
    "# marques\n",
    "Sorting = si.load_extractor(SORTING_PATH_m)\n",
    "agreem_mx_m = agreem_mx_m.loc[\n",
    "    Sorting.unit_ids[Sorting.get_property(\"KSLabel\") == \"good\"], :\n",
    "]\n",
    "\n",
    "# horvath\n",
    "Sorting = si.load_extractor(SORTING_PATH_h)\n",
    "agreem_mx_h = agreem_mx_h.loc[\n",
    "    Sorting.unit_ids[Sorting.get_property(\"KSLabel\") == \"good\"], :\n",
    "]\n",
    "\n",
    "# evoked\n",
    "Sorting = si.load_extractor(SORTING_PATH_e)\n",
    "agreem_mx_e = agreem_mx_e.loc[\n",
    "    Sorting.unit_ids[Sorting.get_property(\"KSLabel\") == \"good\"], :\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3342648</th>\n",
       "      <th>1805689</th>\n",
       "      <th>3697894</th>\n",
       "      <th>367098</th>\n",
       "      <th>1527208</th>\n",
       "      <th>1817280</th>\n",
       "      <th>582918</th>\n",
       "      <th>1653016</th>\n",
       "      <th>680496</th>\n",
       "      <th>3443482</th>\n",
       "      <th>...</th>\n",
       "      <th>2900466</th>\n",
       "      <th>2906855</th>\n",
       "      <th>3438985</th>\n",
       "      <th>1586210</th>\n",
       "      <th>2153673</th>\n",
       "      <th>2169777</th>\n",
       "      <th>2171014</th>\n",
       "      <th>2177069</th>\n",
       "      <th>3471826</th>\n",
       "      <th>833045</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows Ã— 1310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     3342648  1805689  3697894  367098   1527208   1817280   582918   \\\n",
       "10   0.00000      0.0      0.0  0.00000      0.0  0.000000  0.000000   \n",
       "12   0.00000      0.0      0.0  0.00000      0.0  0.000000  0.000000   \n",
       "13   0.00000      0.0      0.0  0.00000      0.0  0.000000  0.000000   \n",
       "17   0.00000      0.0      0.0  0.00000      0.0  0.000852  0.000000   \n",
       "19   0.00035      0.0      0.0  0.00000      0.0  0.000000  0.000325   \n",
       "..       ...      ...      ...      ...      ...       ...       ...   \n",
       "557  0.00000      0.0      0.0  0.00000      0.0  0.000000  0.000000   \n",
       "562  0.00000      0.0      0.0  0.00000      0.0  0.000000  0.000000   \n",
       "564  0.00000      0.0      0.0  0.00000      0.0  0.000000  0.000000   \n",
       "565  0.00000      0.0      0.0  0.00062      0.0  0.000000  0.000000   \n",
       "566  0.00000      0.0      0.0  0.00000      0.0  0.000000  0.000000   \n",
       "\n",
       "      1653016   680496    3443482  ...  2900466  2906855  3438985  1586210  \\\n",
       "10   0.000000  0.001079  0.000504  ...      0.0      0.0      0.0      0.0   \n",
       "12   0.000000  0.000808  0.000000  ...      0.0      0.0      0.0      0.0   \n",
       "13   0.000000  0.000652  0.001880  ...      0.0      0.0      0.0      0.0   \n",
       "17   0.000000  0.000911  0.000860  ...      0.0      0.0      0.0      0.0   \n",
       "19   0.000000  0.000768  0.000743  ...      0.0      0.0      0.0      0.0   \n",
       "..        ...       ...       ...  ...      ...      ...      ...      ...   \n",
       "557  0.000000  0.000000  0.000489  ...      0.0      0.0      0.0      0.0   \n",
       "562  0.000000  0.000000  0.000000  ...      0.0      0.0      0.0      0.0   \n",
       "564  0.000000  0.001517  0.000949  ...      0.0      0.0      0.0      0.0   \n",
       "565  0.000586  0.000000  0.002157  ...      0.0      0.0      0.0      0.0   \n",
       "566  0.001381  0.000000  0.001109  ...      0.0      0.0      0.0      0.0   \n",
       "\n",
       "     2153673  2169777  2171014  2177069  3471826  833045   \n",
       "10       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "12       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "13       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "17       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "19       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "..       ...      ...      ...      ...      ...      ...  \n",
       "557      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "562      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "564      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "565      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "566      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[148 rows x 1310 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreem_mx_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias_labels = classify_true_unit_biases(agreem_mx_m, DET_THRESH, CHANCE_THRESH)\n",
    "# sum(bias_labels.values == \"poorly detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination of biases: ['well detected, correlated']\n",
      "combination of biases: ['oversplit' 'poorly detected' 'well detected, correlated']\n",
      "combination of biases: []\n",
      "combination of biases: ['oversplit' 'poorly detected']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_278889/1308606798.py:208: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 50x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# takes 2 secs\n",
    "\n",
    "# record agreement matrices for each dataset\n",
    "agreem_mxs = [agreem_mx_b, agreem_mx_m, agreem_mx_h, agreem_mx_e]\n",
    "agreem_names = [\"Buccino\", \"Marques\", \"Horvath\", \"Evoked\"]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for ix, mx_i in enumerate(agreem_mxs):\n",
    "\n",
    "    # classify sorting biases for this dataset\n",
    "    bias_labels = classify_true_unit_biases(mx_i, DET_THRESH, CHANCE_THRESH)\n",
    "\n",
    "    # calculate proportions of biases for this dataset\n",
    "    biases_ratio_df = create_true_biases_df(bias_labels)\n",
    "    df[agreem_names[ix]] = biases_ratio_df[\"cell_count\"].values\n",
    "\n",
    "df.index = biases_ratio_df.index\n",
    "\n",
    "# plot\n",
    "fig, axis = plt.subplots(1, 1, figsize=(0.5, 1))\n",
    "axis = plot_biases(axis, df)\n",
    "axis.set_xlabel(\"Simulated recordings\")\n",
    "\n",
    "# save figures\n",
    "plt.savefig(\n",
    "    \"/gpfs/bbp.cscs.ch/project/proj85/home/laquitai/preprint_2023/figures/3_bias/svg/truth_sorting_accuracy_and_biases_ks2_5.svg\",\n",
    "    **savefig_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Buccino</th>\n",
       "      <th>Marques</th>\n",
       "      <th>Horvath</th>\n",
       "      <th>Evoked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>well detected</th>\n",
       "      <td>240</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well detected, correlated</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well detected, correlated, overmerged</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poorly detected</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overmerged</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversplit</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversplit, overmerged</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>below chance</th>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>61</td>\n",
       "      <td>1705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed</th>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "      <td>226</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Buccino  Marques  Horvath  Evoked\n",
       "well detected                              240       49        0      34\n",
       "well detected, correlated                    1        0        0       2\n",
       "well detected, correlated, overmerged        4        1        0       0\n",
       "poorly detected                              0       40        0      36\n",
       "overmerged                                   0       12        0      10\n",
       "oversplit                                    0        1        0       1\n",
       "oversplit, overmerged                        0        1        0       1\n",
       "below chance                                 5     1000       61    1705\n",
       "missed                                       0      206      226      47"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple description of sorted units as \"good\", \"poor\", \"below chance\" or \"false positive\"\n",
    "\n",
    "This description is only based on the unit sorting accuracy with its best matching ground truth unit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_278889/1825854769.py:52: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 50x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set all colors\n",
    "colors = [\n",
    "    [0.7, 0.1, 0.1],  # \"good\" (strong red)\n",
    "    [1, 0.85, 0.85],  # \"poor\" (pink)\n",
    "    [0.95, 0.95, 0.95],  # \"below chance\"\n",
    "    \"w\",  # \"false positive\"\n",
    "]\n",
    "\n",
    "# count sorted unit biases for each dataset\n",
    "agreem_names = [\"Buccino\", \"Marques\", \"Horvath\", \"Evoked\"]\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for ix in range(len(agreem_names)):\n",
    "    out = classify_sorted_unit_biases(agreem_mxs[ix])\n",
    "    df2[agreem_names[ix]] = [\n",
    "        out[\"n_good\"],\n",
    "        out[\"n_poor\"],\n",
    "        out[\"n_below_chance\"],\n",
    "        out[\"n_false_pos\"],\n",
    "    ]\n",
    "df2.index = [\"good\", \"poor\", \"below chance\", \"false positive\"]\n",
    "df2_ratio = df2 / df2.sum()\n",
    "\n",
    "fig, axis = plt.subplots(1, 1, figsize=(0.5, 1))\n",
    "ax = (df2_ratio).T.plot.bar(\n",
    "    ax=axis,\n",
    "    stacked=True,\n",
    "    color=colors,\n",
    "    width=0.9,\n",
    "    edgecolor=[0, 0, 0],\n",
    "    linewidth=0.2,\n",
    ")\n",
    "\n",
    "# set axis legend\n",
    "ax.spines[[\"left\", \"right\", \"top\", \"bottom\"]].set_visible(False)\n",
    "y_axis = ax.axes.get_yaxis()\n",
    "y_axis.set_visible(False)\n",
    "ax.set_xticklabels(df2_ratio.columns, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Sorting biases (ratio)\", fontsize=9)\n",
    "\n",
    "ax.legend(\n",
    "    df2.index,\n",
    "    ncol=1,\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(1, 0),\n",
    "    frameon=False,\n",
    "    handletextpad=0.6,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# save figures\n",
    "plt.savefig(\n",
    "    \"/gpfs/bbp.cscs.ch/project/proj85/home/laquitai/preprint_2023/figures/3_bias/svg/sorted_unit_biases_ks2_5.svg\",\n",
    "    **savefig_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPLREMENTARY: For a comprehensive descriptions of biases for ground truth and sorted units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination of biases: ['oversplit' 'poorly detected']\n"
     ]
    }
   ],
   "source": [
    "overmerging_matx_2 = agreem_mx_m\n",
    "det_thresh = 0.8\n",
    "chance = 0.1\n",
    "\n",
    "# create masks\n",
    "mask_above_det = overmerging_matx_2 >= det_thresh\n",
    "mask_below_chance = overmerging_matx_2 <= chance\n",
    "mask_in_between = np.logical_and(\n",
    "    overmerging_matx_2 < det_thresh, overmerging_matx_2 > chance\n",
    ")\n",
    "mask_entirely_missed = overmerging_matx_2 == 0\n",
    "\n",
    "# implement tree to classify ground truths\n",
    "# find ground truth (cols) with one mask_above_det=True and other mask_below_chance = True\n",
    "\n",
    "gt_classes = []\n",
    "df = pd.DataFrame(\n",
    "    data=np.array([[0], [0], [0], [0]]).T,\n",
    "    columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    ")\n",
    "\n",
    "# loop over ground truth units\n",
    "for gt_i in range(overmerging_matx_2.shape[1]):\n",
    "\n",
    "    # check if that ground truth has a single sorted unit\n",
    "    # with an agreement score above detection threshold\n",
    "    if any(mask_above_det.iloc[:, gt_i]):\n",
    "\n",
    "        # get this ground truth detection stata\n",
    "        is_detected = mask_above_det.iloc[:, gt_i]\n",
    "        detected_loc = np.where(is_detected)[0]\n",
    "        detected_id = is_detected.index[detected_loc]\n",
    "\n",
    "        # get other correlated unit ids\n",
    "        other_sorted_unit_ids = is_detected.drop(index=detected_id).index\n",
    "\n",
    "        # get this ground truth below chance stata\n",
    "        is_below_chance = mask_below_chance.iloc[:, gt_i]\n",
    "\n",
    "        # check if all other sorted units are below chance\n",
    "        if all(is_below_chance.loc[other_sorted_unit_ids]):\n",
    "            gt_classes.append(\"well detected\")\n",
    "\n",
    "            # pair true and sorted units\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        [overmerging_matx_2.columns[gt_i]],\n",
    "                        [detected_id[0]],\n",
    "                        [\"well detected\"],\n",
    "                        [\"good\"],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "\n",
    "        # if another unit has an agreement score\n",
    "        # above chance level, it is: well detected + correlated unit\n",
    "        else:\n",
    "            gt_classes.append(\"well detected, correlated\")\n",
    "\n",
    "            # pair true and the well detected sorted unit\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        [overmerging_matx_2.columns[gt_i]],\n",
    "                        [detected_id[0]],\n",
    "                        [\"well detected, correlated\"],\n",
    "                        [\"good\"],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "\n",
    "            # pair true and the other redundant sorted unit\n",
    "            n_redundants = len(other_sorted_unit_ids.tolist())\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        n_redundants * [overmerging_matx_2.columns[gt_i]],\n",
    "                        other_sorted_unit_ids.tolist(),\n",
    "                        n_redundants * [\"poorly detected\"],\n",
    "                        n_redundants * [\"redundant\"],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "\n",
    "    # case where ground truth matches only one sorted unit\n",
    "    # with a score b/w detection and chance and\n",
    "    # other units below chance\n",
    "    # no scores are above detection\n",
    "    elif (sum(mask_in_between.iloc[:, gt_i]) == 1) and (\n",
    "        any(mask_above_det.iloc[:, gt_i]) == False\n",
    "    ):\n",
    "        gt_classes.append(\"poorly detected\")\n",
    "\n",
    "        # pair units\n",
    "        unit_id = overmerging_matx_2.index[\n",
    "            np.where(mask_in_between.iloc[:, gt_i] == 1)[0][0]\n",
    "        ]\n",
    "        df2 = pd.DataFrame(\n",
    "            data=np.array(\n",
    "                [\n",
    "                    [overmerging_matx_2.columns[gt_i]],\n",
    "                    [unit_id],\n",
    "                    [\"poorly detected\"],\n",
    "                    [\"poor unit\"],\n",
    "                ]\n",
    "            ).T,\n",
    "            columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "        )\n",
    "        df = pd.concat([df, df2])\n",
    "\n",
    "    # case a true unit is associated is a sorted unit with score\n",
    "    # between detection and chance that is associated with other\n",
    "    # true units with scores between detection and chances\n",
    "    elif sum(mask_in_between.iloc[:, gt_i]) > 1:\n",
    "        gt_classes.append(\"oversplit\")\n",
    "\n",
    "        # pair units\n",
    "        unit_ids = overmerging_matx_2.index[\n",
    "            np.where(mask_in_between.iloc[:, gt_i])[0].tolist()\n",
    "        ].tolist()\n",
    "        n_oversplitters = len(unit_ids)\n",
    "\n",
    "        df2 = pd.DataFrame(\n",
    "            data=np.array(\n",
    "                [\n",
    "                    n_oversplitters * [overmerging_matx_2.columns[gt_i]],\n",
    "                    unit_ids,\n",
    "                    n_oversplitters * [\"oversplit\"],\n",
    "                    n_oversplitters * [\"oversplitters\"],\n",
    "                ]\n",
    "            ).T,\n",
    "            columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "        )\n",
    "        df = pd.concat([df, df2])\n",
    "\n",
    "    # check that all sorted units have scores below\n",
    "    # chance\n",
    "    elif all(mask_below_chance.iloc[:, gt_i]):\n",
    "        if all(mask_entirely_missed.iloc[:, gt_i]):\n",
    "            gt_classes.append(\"missed\")\n",
    "\n",
    "            # pair units\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        [overmerging_matx_2.columns[gt_i]],\n",
    "                        [np.nan],\n",
    "                        [\"missed\"],\n",
    "                        [np.nan],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "        else:\n",
    "            gt_classes.append(\"below chance\")\n",
    "            unit_ids = overmerging_matx_2.index[\n",
    "                np.where(\n",
    "                    (overmerging_matx_2.iloc[:, gt_i] <= chance)\n",
    "                    * (overmerging_matx_2.iloc[:, gt_i] > 0)\n",
    "                )[0]\n",
    "            ].tolist()\n",
    "            n_below_chance = len(unit_ids)\n",
    "\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        n_below_chance * [overmerging_matx_2.columns[gt_i]],\n",
    "                        unit_ids,\n",
    "                        n_below_chance * [\"below chance\"],\n",
    "                        n_below_chance * [\"below chance\"],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "\n",
    "\n",
    "# Detect overmerged units and combinations -------------\n",
    "\n",
    "# if one of its sorted units with score between\n",
    "# detection and chance has also a score between\n",
    "# detection and chance with another true unit\n",
    "# the true unit is overmerged (with another true unit)\n",
    "true_units_loc = np.where(mask_in_between.sum(axis=0) >= 1)[0]\n",
    "true_units = mask_in_between.columns[true_units_loc]\n",
    "gt_overmerged = dict()\n",
    "\n",
    "for gt_i in range(len(true_units_loc)):\n",
    "    target_true_units_mx = mask_in_between.iloc[:, true_units_loc]\n",
    "    sorted_u = np.where(target_true_units_mx.iloc[:, gt_i])[0]\n",
    "\n",
    "    # check overmerged (that sorted unit merges other true units)\n",
    "    if any(mask_in_between.iloc[sorted_u, :].sum(axis=1) > 1):\n",
    "        overmerged_bool = mask_in_between.iloc[sorted_u, :].sum(axis=1) > 1\n",
    "        overmerging_sorted = overmerged_bool.index[\n",
    "            np.where(overmerged_bool)[0]\n",
    "        ].to_list()\n",
    "        gt_overmerged[true_units[gt_i]] = overmerging_sorted\n",
    "\n",
    "# what other biases do overmerged units have?\n",
    "all_true_units = overmerging_matx_2.columns\n",
    "gt_classes_df = pd.DataFrame(data=gt_classes, index=all_true_units.to_list())\n",
    "print(\"combination of biases:\", np.unique(gt_classes_df.loc[gt_overmerged.keys(), :]))\n",
    "\n",
    "# label combination of biases\n",
    "gt_classes_df.loc[gt_overmerged.keys(), :] = gt_classes_df.loc[\n",
    "    gt_overmerged.keys(), :\n",
    "].apply(lambda x: x + \", overmerged\")\n",
    "\n",
    "# poorly detected + overmerged units are poorly detected because overmerged so simply overmerged\n",
    "gt_classes_df[gt_classes_df == \"poorly detected, overmerged\"] = \"overmerged\"\n",
    "df = df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground truth</th>\n",
       "      <th>sorted</th>\n",
       "      <th>ground truth bias</th>\n",
       "      <th>sorted bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1527208</td>\n",
       "      <td>99</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1527208</td>\n",
       "      <td>117</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1527208</td>\n",
       "      <td>124</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1527208</td>\n",
       "      <td>164</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1527208</td>\n",
       "      <td>198</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3547327</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1509317</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514245</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2696195</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1725884</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24696 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ground truth sorted ground truth bias   sorted bias\n",
       "0       1527208     99      below chance  below chance\n",
       "1       1527208    117      below chance  below chance\n",
       "2       1527208    124      below chance  below chance\n",
       "3       1527208    164      below chance  below chance\n",
       "4       1527208    198      below chance  below chance\n",
       "..          ...    ...               ...           ...\n",
       "0       3547327    nan            missed           nan\n",
       "0       1509317    nan            missed           nan\n",
       "0       1514245    nan            missed           nan\n",
       "0       2696195    nan            missed           nan\n",
       "0       1725884    nan            missed           nan\n",
       "\n",
       "[24696 rows x 4 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A sorted unit can show several biases (with different ground truth units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['below chance', 'redundant', 'poor unit'], dtype=object)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 20\n",
    "\n",
    "sorted_ids = df[\"sorted\"].unique()\n",
    "df[df[\"sorted\"] == sorted_ids[ix]][\"sorted bias\"].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_kilosort_silico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
