{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias types (Kilosort 3.0)\n",
    "\n",
    "author: steeve.laquitaine@epfl.ch  \n",
    "last modified: 13-02-2024\n",
    "status: OK  \n",
    "regression: None  \n",
    "\n",
    "Purpose: Characterize and quantify ground truth sorting quality and biases from matching with best matching sorted units\n",
    "\n",
    "Notes:\n",
    "* pros of Kilosort 3.0:\n",
    "    * fully automated to produce single units (isolated from multi-units via additional postprocessing label \"KSlabel\")\n",
    "    * very efficient algorithm\n",
    "    * very recent and well maintained, was very easy to setup and run from SpikeInterface\n",
    "    * the most used and cited by recent studies, in high-impact papers\n",
    "\n",
    "\n",
    "We define biases types to characterize what happens to the true units (not with respect to sorted unit). This allows the proportion of all biases to sum to 100% over true units.\n",
    "\n",
    "Based on our definitions:\n",
    "\n",
    "* Possible biases types are:  \n",
    "    * well detected\n",
    "    * well detected + correlated unit\n",
    "    * poorly detected    \n",
    "    * oversplit\n",
    "    * overmerged (include overmerged + poorly detected because this combination is always due to overmerging)   \n",
    "    * overmerged + oversplit\n",
    "    * overmerged + well detected + correlated unit\n",
    "    * below chance    \n",
    "    * missed\n",
    "* Impossible biases types are:\n",
    "    * poorly detected + oversplit (impossible because poorly detected requires matching at max a single sorted unit above chance, while oversplit requires matching at least two units)\n",
    "\n",
    "\n",
    "To detect overmerged units and combinations\n",
    "\n",
    "* need to look from perspective of sorted units\n",
    "* A true unit is overmerged (with other true units) if it has at least one sorted units with a score between detection and chance that also has a score between detection and chance with another true unit.\n",
    "* a poorly sorted units (accuracy between 0.1 and 0.8) can thus be overmerged (it fuse together half the spike trains of two true units). In that case it is classified as overmerged.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Create or activate env `npx_10m_384ch_unit_classes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 09:58:38,574 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-02-15 09:58:38,603 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2024-02-15 09:58:38,605 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-02-15 09:58:38,678 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2024-02-15 09:58:38,680 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-02-15 09:58:38,717 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2024-02-15 09:58:38,719 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-02-15 09:58:38,770 - root - utils.py - get_config - INFO - Reading experiment config. - done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import spikeinterface as si\n",
    "\n",
    "proj_path = \"/gpfs/bbp.cscs.ch/project/proj85/home/laquitai/spikebias/\"\n",
    "os.chdir(proj_path)\n",
    "\n",
    "from src.nodes.postpro.cell_matching import get_SpikeInterface_matching_object, match_sorted_to_true_neuropixels_2023_02_19\n",
    "from src.nodes.utils import get_config\n",
    "from src.nodes.postpro.feateng import (add_firing_rates)\n",
    "from src.nodes.postpro import spikestats\n",
    "\n",
    "# set classification parameters\n",
    "LOW_RATE_CEILING = 0.2  # max firing rate where negative proba change is observed in \"bias plot\" (sparse units)\n",
    "DET_THRESH = 0.8\n",
    "CHANCE_THRESH = 0.1\n",
    "\n",
    "# buccino\n",
    "data_conf, param_conf = get_config(\"buccino_2020\", \"2020\").values()\n",
    "KS3_SORTING_PATH_b = data_conf[\"sorting\"][\"sorters\"][\"kilosort3\"][\"output\"]\n",
    "GT_SORTING_PATH_b = data_conf[\"sorting\"][\"simulation\"][\"ground_truth\"][\"output\"]\n",
    "RECORDING_PATH_b = data_conf[\"recording\"][\"output\"]\n",
    "KS3_SORTING_PATH_b = data_conf[\"sorting\"][\"sorters\"][\"kilosort3\"][\"output\"]\n",
    "\n",
    "# silico marques\n",
    "data_conf, param_conf = get_config(\"silico_neuropixels\", \"2023_10_18\").values()\n",
    "KS3_SORTING_PATH_m = data_conf[\"sorting\"][\"sorters\"][\"kilosort3\"][\"output\"]\n",
    "GT_SORTING_PATH_m = data_conf[\"sorting\"][\"simulation\"][\"ground_truth\"][\"output\"]\n",
    "RECORDING_PATH_m = data_conf[\"recording\"][\"output\"]\n",
    "KS3_SORTING_PATH_m = data_conf[\"sorting\"][\"sorters\"][\"kilosort3\"][\"output\"]\n",
    "\n",
    "# silico horvath\n",
    "data_conf, param_conf = get_config(\"silico_horvath\", \"concatenated/probe_1\").values()\n",
    "KS3_SORTING_PATH_h = data_conf[\"sorting\"][\"sorters\"][\"kilosort3\"][\"output\"]\n",
    "GT_SORTING_PATH_h = data_conf[\"sorting\"][\"simulation\"][\"ground_truth\"][\"output\"]\n",
    "RECORDING_PATH_h = data_conf[\"recording\"][\"output\"]\n",
    "KS3_SORTING_PATH_h = data_conf[\"sorting\"][\"sorters\"][\"kilosort3\"][\"output\"]\n",
    "\n",
    "# silico stimulus\n",
    "data_conf, param_conf = get_config(\"silico_neuropixels\", \"stimulus\").values()\n",
    "KS3_SORTING_PATH_e = data_conf[\"sorting\"][\"sorters\"][\"kilosort3\"][\"output\"]\n",
    "GT_SORTING_PATH_e = data_conf[\"sorting\"][\"simulation\"][\"ground_truth\"][\"output\"]\n",
    "RECORDING_PATH_e = data_conf[\"recording\"][\"output\"]\n",
    "KS3_SORTING_PATH_e = data_conf[\"sorting\"][\"sorters\"][\"kilosort3\"][\"output\"]\n",
    "\n",
    "\n",
    "# FIGURE SETTINGS\n",
    "COLOR_VIVO = (0.7, 0.7, 0.7)\n",
    "COLOR_SILI = (0.84, 0.27, 0.2)\n",
    "COLOR_STIM = (0.6, 0.75, 0.1)\n",
    "BOX_ASPECT = 1                  # square fig\n",
    "FIG_SIZE = (1,1)\n",
    "plt.rcParams['figure.figsize'] = (2,1)\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 6\n",
    "plt.rcParams['lines.linewidth'] = 0.2\n",
    "plt.rcParams['axes.linewidth'] = 0.5\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['xtick.major.width'] = 0.3\n",
    "plt.rcParams['xtick.minor.size'] = 0.1\n",
    "plt.rcParams['xtick.major.size'] = 1.5\n",
    "plt.rcParams['ytick.major.size'] = 1.5\n",
    "plt.rcParams['ytick.major.width'] = 0.3\n",
    "legend_cfg = {\"frameon\": False, \"handletextpad\": 0.1}\n",
    "savefig_cfg = {\"transparent\":True}\n",
    "# print(plt.rcParams.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_agreement_matrix(MatchingObject):\n",
    "\n",
    "    # get sorted x true units' agreement scores\n",
    "    overmerging_matx = MatchingObject.agreement_scores.T\n",
    "\n",
    "    # sort each row such that the row with the highest score be first, while column order stays unchanged\n",
    "    argmax = overmerging_matx.T.idxmax().to_frame()\n",
    "    max = overmerging_matx.T.max()\n",
    "    descending_ix = np.argsort(max)[::-1]\n",
    "    overmerging_matx_2 = overmerging_matx.iloc[descending_ix]\n",
    "\n",
    "    # repeat for columns, row order stays auntouched\n",
    "    argmax = overmerging_matx_2.idxmax().to_frame()\n",
    "    max = overmerging_matx_2.max()\n",
    "    descending_ix = np.argsort(max)[::-1]\n",
    "    return overmerging_matx_2.iloc[:, descending_ix]\n",
    "\n",
    "\n",
    "def classify_true_unit_biases(overmerging_matx_2, det_thresh, chance):\n",
    "\n",
    "    # create masks\n",
    "    mask_above_det = overmerging_matx_2 >= det_thresh\n",
    "    mask_below_chance = overmerging_matx_2 <= chance\n",
    "    mask_in_between = np.logical_and(\n",
    "        overmerging_matx_2 < det_thresh, overmerging_matx_2 > chance\n",
    "    )\n",
    "    mask_entirely_missed = overmerging_matx_2 == 0\n",
    "\n",
    "    # implement tree to classify ground truths\n",
    "    # find ground truth (cols) with one mask_above_det=True and other mask_below_chance = True\n",
    "\n",
    "    gt_classes = []\n",
    "\n",
    "    # loop over ground truth units\n",
    "    for gt_i in range(overmerging_matx_2.shape[1]):\n",
    "\n",
    "        # check if that ground truth has a single sorted unit\n",
    "        # with an agreement score above detection threshold\n",
    "        if any(mask_above_det.iloc[:, gt_i]):\n",
    "\n",
    "            # get this ground truth detection stata\n",
    "            is_detected = mask_above_det.iloc[:, gt_i]\n",
    "            detected_loc = np.where(is_detected)[0]\n",
    "            detected_ix = is_detected.index[detected_loc]\n",
    "\n",
    "            # get other cells\n",
    "            other_cells_ix = is_detected.drop(index=detected_ix).index\n",
    "\n",
    "            # get this ground truth below chance stata\n",
    "            is_below_chance = mask_below_chance.iloc[:, gt_i]\n",
    "\n",
    "            # check if all other sorted units are below chance\n",
    "            if all(is_below_chance.loc[other_cells_ix]):\n",
    "                gt_classes.append(\"well detected\")\n",
    "            # if another unit has an agreement score\n",
    "            # above chance level, it is: well detected + correlated unit\n",
    "            else:\n",
    "                gt_classes.append(\"well detected, correlated\")\n",
    "\n",
    "        # case where ground truth matches only one sorted unit\n",
    "        # with a score b/w detection and chance and\n",
    "        # other units below chance\n",
    "        # no score are above detection\n",
    "        elif (sum(mask_in_between.iloc[:, gt_i]) == 1) and (\n",
    "            any(mask_above_det.iloc[:, gt_i]) == False\n",
    "        ):\n",
    "            gt_classes.append(\"poorly detected\")\n",
    "\n",
    "        # case a true unit is associated is a sorted unit with score\n",
    "        # between detection and chance that is associated with other\n",
    "        # true units with scores between detection and chances\n",
    "        elif sum(mask_in_between.iloc[:, gt_i]) > 1:\n",
    "            gt_classes.append(\"oversplit\")\n",
    "\n",
    "        # check that all sorted units have scores below\n",
    "        # chance\n",
    "        elif all(mask_below_chance.iloc[:, gt_i]):\n",
    "            if all(mask_entirely_missed.iloc[:, gt_i]):\n",
    "                gt_classes.append(\"missed\")\n",
    "            else:\n",
    "                gt_classes.append(\"below chance\")\n",
    "\n",
    "    # Detect overmerged units and combinations -------------\n",
    "\n",
    "    # if one of its sorted units with score between\n",
    "    # detection and chance has also a score between\n",
    "    # detection and chance with another true unit\n",
    "    # the true unit is overmerged (with another true unit)\n",
    "    true_units_loc = np.where(mask_in_between.sum(axis=0) >= 1)[0]\n",
    "    true_units = mask_in_between.columns[true_units_loc]\n",
    "    gt_overmerged = dict()\n",
    "\n",
    "    for gt_i in range(len(true_units_loc)):\n",
    "        target_true_units_mx = mask_in_between.iloc[:, true_units_loc]\n",
    "        sorted_u = np.where(target_true_units_mx.iloc[:, gt_i])[0]\n",
    "\n",
    "        # check overmerged (that sorted unit merges other true units)\n",
    "        if any(mask_in_between.iloc[sorted_u, :].sum(axis=1) > 1):\n",
    "            overmerged_bool = mask_in_between.iloc[sorted_u, :].sum(axis=1) > 1\n",
    "            overmerging_sorted = overmerged_bool.index[\n",
    "                np.where(overmerged_bool)[0]\n",
    "            ].to_list()\n",
    "            gt_overmerged[true_units[gt_i]] = overmerging_sorted\n",
    "\n",
    "    # what other biases do overmerged units have?\n",
    "    all_true_units = overmerging_matx_2.columns\n",
    "    gt_classes_df = pd.DataFrame(data=gt_classes, index=all_true_units.to_list())\n",
    "    print(\n",
    "        \"combination of biases:\", np.unique(gt_classes_df.loc[gt_overmerged.keys(), :])\n",
    "    )\n",
    "\n",
    "    # label combination of biases\n",
    "    gt_classes_df.loc[gt_overmerged.keys(), :] = gt_classes_df.loc[\n",
    "        gt_overmerged.keys(), :\n",
    "    ].apply(lambda x: x + \", overmerged\")\n",
    "\n",
    "    # poorly detected + overmerged units are poorly detected because overmerged so simply overmerged\n",
    "    gt_classes_df[gt_classes_df == \"poorly detected, overmerged\"] = \"overmerged\"\n",
    "    return gt_classes_df\n",
    "\n",
    "\n",
    "def create_true_biases_df(true_biases_series):\n",
    "\n",
    "    # format dataframe to plot\n",
    "    bias_types = [\n",
    "        \"well detected\",\n",
    "        \"well detected, correlated\",\n",
    "        \"well detected, correlated, overmerged\",\n",
    "        \"poorly detected\",\n",
    "        \"overmerged\",\n",
    "        \"oversplit\",\n",
    "        \"oversplit, overmerged\",\n",
    "        \"below chance\",\n",
    "        \"missed\",\n",
    "    ]\n",
    "\n",
    "    # count each bias\n",
    "    count_by_class = dict(Counter(true_biases_series.values.squeeze().tolist()))\n",
    "\n",
    "    # fill up count per bias\n",
    "    for key_k in bias_types:\n",
    "        try:\n",
    "            count_by_class[key_k]\n",
    "        except:\n",
    "            count_by_class[key_k] = 0\n",
    "\n",
    "    # order by \"bias_types\"\n",
    "    reordered = {k: count_by_class[k] for k in bias_types}\n",
    "\n",
    "    # create table\n",
    "    biases_ratio_df = pd.DataFrame(\n",
    "        {\"cell_count\": list(reordered.values())}, index=list(reordered.keys())\n",
    "    )\n",
    "    return biases_ratio_df\n",
    "\n",
    "\n",
    "def plot_biases(axis, biases_count: pd.DataFrame):\n",
    "\n",
    "    # set colors for combination of biases\n",
    "    oversplit_plus_overmerged = np.array([[0.6, 0.9, 0.6], [0, 0.7, 1]]).mean(axis=0)\n",
    "    well_detected_plus_correlated_units_plus_overmerged = np.array(\n",
    "        [[1, 0, 0], [0, 0.7, 1]]\n",
    "    ).mean(axis=0)\n",
    "\n",
    "    # set all colors\n",
    "    colors = [\n",
    "        [0.7, 0.1, 0.1],  # \"well_detected\" (strong red)\n",
    "        [1, 0, 0],  # \"well_detected_plus_correlated_units\" (red)\n",
    "        well_detected_plus_correlated_units_plus_overmerged,\n",
    "        [1, 0.85, 0.85],  # \"poorly_detected\" (pink)\n",
    "        [0, 0.7, 1],  # \"overmerged\" (green)\n",
    "        [0.6, 0.9, 0.6],  # \"oversplit\" (blue)\n",
    "        oversplit_plus_overmerged,\n",
    "        [0.95, 0.95, 0.95],  # \"below chance\"\n",
    "        \"k\",  # \"missed\"\n",
    "    ]\n",
    "\n",
    "    biases_ratio = biases_count / biases_count.sum()\n",
    "\n",
    "    # plot\n",
    "    ax = (biases_ratio).T.plot.bar(\n",
    "        ax=axis,\n",
    "        stacked=True,\n",
    "        color=colors,\n",
    "        width=0.9,\n",
    "        edgecolor=[0.5, 0.5, 0.5],\n",
    "        linewidth=0.2,\n",
    "    )\n",
    "\n",
    "    # set axis legend\n",
    "    ax.spines[[\"left\", \"right\", \"top\", \"bottom\"]].set_visible(False)\n",
    "    y_axis = ax.axes.get_yaxis()\n",
    "    y_axis.set_visible(False)\n",
    "    ax.set_xticklabels(biases_ratio.columns, rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel(\"Sorting biases (ratio)\", fontsize=9)\n",
    "\n",
    "    ax.legend(\n",
    "        biases_count.index,\n",
    "        ncol=1,\n",
    "        loc=\"lower left\",\n",
    "        bbox_to_anchor=(1, 0),\n",
    "        frameon=False,\n",
    "        handletextpad=0.6,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return axis\n",
    "\n",
    "\n",
    "def plot_heatmap(overmerging_matx_2):\n",
    "\n",
    "    # plot\n",
    "    # fig, axis = plt.subplots(1, 1, figsize=(2, 10))\n",
    "\n",
    "    # plot agreement matrix\n",
    "    mx_to_plot = overmerging_matx_2.iloc[:500, :500].values\n",
    "    fig, axis = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        mx_to_plot,\n",
    "        cmap=\"jet\",\n",
    "        cbar_kws={\"shrink\": 0.5},\n",
    "        yticklabels=False,\n",
    "        xticklabels=False,\n",
    "    )\n",
    "    plt.xlabel(\"true units\")\n",
    "    plt.ylabel(\"sorted units\")\n",
    "    ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sorted x true agreement matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 2 min\n",
    "\n",
    "# get true/sorted matching object\n",
    "MatchingObject_b = get_SpikeInterface_matching_object(\n",
    "    GT_SORTING_PATH_b, KS3_SORTING_PATH_b\n",
    ")\n",
    "MatchingObject_m = get_SpikeInterface_matching_object(\n",
    "    GT_SORTING_PATH_m, KS3_SORTING_PATH_m\n",
    ")\n",
    "MatchingObject_h = get_SpikeInterface_matching_object(\n",
    "    GT_SORTING_PATH_h, KS3_SORTING_PATH_h\n",
    ")\n",
    "MatchingObject_e = get_SpikeInterface_matching_object(\n",
    "    GT_SORTING_PATH_e, KS3_SORTING_PATH_e\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sort each row in descending order. The columns are not labelled as the raw ground truth anymore but become labelled as best match ground truth to the worst match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreem_mx_b = format_agreement_matrix(MatchingObject_b)\n",
    "agreem_mx_m = format_agreement_matrix(MatchingObject_m)\n",
    "agreem_mx_h = format_agreement_matrix(MatchingObject_h)\n",
    "agreem_mx_e = format_agreement_matrix(MatchingObject_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot biases (matching only the best matching sorted single units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the sorted single units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the sorted single units\n",
    "\n",
    "# buccino\n",
    "Sorting = si.load_extractor(KS3_SORTING_PATH_b)\n",
    "agreem_mx_b = agreem_mx_b.loc[\n",
    "    Sorting.unit_ids[Sorting.get_property(\"KSLabel\") == \"good\"], :\n",
    "]\n",
    "\n",
    "# marques\n",
    "Sorting = si.load_extractor(KS3_SORTING_PATH_m)\n",
    "agreem_mx_m = agreem_mx_m.loc[\n",
    "    Sorting.unit_ids[Sorting.get_property(\"KSLabel\") == \"good\"], :\n",
    "]\n",
    "\n",
    "# horvath\n",
    "Sorting = si.load_extractor(KS3_SORTING_PATH_h)\n",
    "agreem_mx_h = agreem_mx_h.loc[\n",
    "    Sorting.unit_ids[Sorting.get_property(\"KSLabel\") == \"good\"], :\n",
    "]\n",
    "\n",
    "# evoked\n",
    "Sorting = si.load_extractor(KS3_SORTING_PATH_e)\n",
    "agreem_mx_e = agreem_mx_e.loc[\n",
    "    Sorting.unit_ids[Sorting.get_property(\"KSLabel\") == \"good\"], :\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1527208</th>\n",
       "      <th>930739</th>\n",
       "      <th>132958</th>\n",
       "      <th>2203721</th>\n",
       "      <th>545960</th>\n",
       "      <th>236454</th>\n",
       "      <th>357418</th>\n",
       "      <th>1845334</th>\n",
       "      <th>103528</th>\n",
       "      <th>1811293</th>\n",
       "      <th>...</th>\n",
       "      <th>987908</th>\n",
       "      <th>1001676</th>\n",
       "      <th>1741866</th>\n",
       "      <th>1747441</th>\n",
       "      <th>3541654</th>\n",
       "      <th>3547327</th>\n",
       "      <th>1509317</th>\n",
       "      <th>1514245</th>\n",
       "      <th>2696195</th>\n",
       "      <th>1725884</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 1310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1527208  930739   132958    2203721  545960    236454   357418   \\\n",
       "66   0.000000      0.0      0.0  0.000000      0.0  0.000000      0.0   \n",
       "67   0.000000      0.0      0.0  0.000000      0.0  0.000000      0.0   \n",
       "77   0.000000      0.0      0.0  0.000000      0.0  0.000000      0.0   \n",
       "81   0.000000      0.0      0.0  0.000000      0.0  0.000000      0.0   \n",
       "82   0.000000      0.0      0.0  0.000000      0.0  0.000000      0.0   \n",
       "..        ...      ...      ...       ...      ...       ...      ...   \n",
       "749  0.000000      0.0      0.0  0.000000      0.0  0.000000      0.0   \n",
       "767  0.000000      0.0      0.0  0.000000      0.0  0.000000      0.0   \n",
       "770  0.000959      0.0      0.0  0.001048      0.0  0.000000      0.0   \n",
       "799  0.000000      0.0      0.0  0.000000      0.0  0.000000      0.0   \n",
       "834  0.000362      0.0      0.0  0.000000      0.0  0.000374      0.0   \n",
       "\n",
       "     1845334   103528    1811293  ...  987908   1001676  1741866  1747441  \\\n",
       "66       0.0  0.000000  0.000000  ...      0.0      0.0      0.0      0.0   \n",
       "67       0.0  0.000000  0.000000  ...      0.0      0.0      0.0      0.0   \n",
       "77       0.0  0.000000  0.000000  ...      0.0      0.0      0.0      0.0   \n",
       "81       0.0  0.000000  0.001166  ...      0.0      0.0      0.0      0.0   \n",
       "82       0.0  0.000000  0.000571  ...      0.0      0.0      0.0      0.0   \n",
       "..       ...       ...       ...  ...      ...      ...      ...      ...   \n",
       "749      0.0  0.000000  0.000000  ...      0.0      0.0      0.0      0.0   \n",
       "767      0.0  0.000000  0.000660  ...      0.0      0.0      0.0      0.0   \n",
       "770      0.0  0.000000  0.000000  ...      0.0      0.0      0.0      0.0   \n",
       "799      0.0  0.000866  0.001097  ...      0.0      0.0      0.0      0.0   \n",
       "834      0.0  0.000379  0.000908  ...      0.0      0.0      0.0      0.0   \n",
       "\n",
       "     3541654  3547327  1509317  1514245  2696195  1725884  \n",
       "66       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "67       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "77       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "81       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "82       0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "..       ...      ...      ...      ...      ...      ...  \n",
       "749      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "767      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "770      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "799      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "834      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[228 rows x 1310 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreem_mx_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination of biases: ['oversplit' 'poorly detected']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([83])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_labels = classify_true_unit_biases(agreem_mx_m, DET_THRESH, CHANCE_THRESH)\n",
    "sum(bias_labels.values == \"poorly detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination of biases: ['oversplit' 'poorly detected' 'well detected, correlated']\n",
      "combination of biases: ['oversplit' 'poorly detected']\n",
      "combination of biases: ['oversplit' 'poorly detected']\n",
      "combination of biases: ['poorly detected']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53209/1555949988.py:206: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 50x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# takes 2 secs\n",
    "\n",
    "# record agreement matrices for each dataset\n",
    "agreem_mxs = [agreem_mx_b, agreem_mx_m, agreem_mx_h, agreem_mx_e]\n",
    "agreem_names = [\"Buccino\", \"Marques\", \"Horvath\", \"Evoked\"]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for ix, mx_i in enumerate(agreem_mxs):\n",
    "\n",
    "    # classify sorting biases for this dataset\n",
    "    bias_labels = classify_true_unit_biases(mx_i, DET_THRESH, CHANCE_THRESH)\n",
    "\n",
    "    # calculate proportions of biases for this dataset\n",
    "    biases_ratio_df = create_true_biases_df(bias_labels)\n",
    "    df[agreem_names[ix]] = biases_ratio_df[\"cell_count\"].values\n",
    "\n",
    "df.index = biases_ratio_df.index\n",
    "\n",
    "# plot\n",
    "fig, axis = plt.subplots(1, 1, figsize=(0.5, 1))\n",
    "axis = plot_biases(axis, df)\n",
    "axis.set_xlabel(\"Simulated recordings\")\n",
    "\n",
    "# save figures\n",
    "plt.savefig(\n",
    "    \"/gpfs/bbp.cscs.ch/project/proj85/home/laquitai/spikebias/figures/3_bias/svg/sorting_accuracy_and_biases_ks3.svg\",\n",
    "    **savefig_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot biases for remaining least matching sorted single units (if any)\n",
    "\n",
    "False positive are units that share no spikes with the ground truth units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53209/1239660473.py:59: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 50x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FALSE POSITIVES\n",
    "\n",
    "# sorted units are in rows\n",
    "n_false_pos = sum(agreem_mx_b.sum(axis=1) == 0)\n",
    "n_sorted = agreem_mx_b.shape[0]\n",
    "false_pos_ratio_b = n_false_pos / n_sorted\n",
    "\n",
    "# sorted units are in rows\n",
    "n_false_pos = sum(agreem_mx_m.sum(axis=1) == 0)\n",
    "n_sorted = agreem_mx_m.shape[0]\n",
    "false_pos_ratio_m = n_false_pos / n_sorted\n",
    "\n",
    "# sorted units are in rows\n",
    "n_false_pos = sum(agreem_mx_h.sum(axis=1) == 0)\n",
    "n_sorted = agreem_mx_h.shape[0]\n",
    "false_pos_ratio_h = n_false_pos / n_sorted\n",
    "\n",
    "# sorted units are in rows\n",
    "n_false_pos = sum(agreem_mx_e.sum(axis=1) == 0)\n",
    "n_sorted = agreem_mx_e.shape[0]\n",
    "false_pos_ratio_e = n_false_pos / n_sorted\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Buccino\", \"Marques\", \"Horvath\", \"Evoked\"])\n",
    "df[\"Buccino\"] = [false_pos_ratio_b, 1 - false_pos_ratio_b]\n",
    "df[\"Marques\"] = [false_pos_ratio_m, 1 - false_pos_ratio_m]\n",
    "df[\"Horvath\"] = [false_pos_ratio_h, 1 - false_pos_ratio_h]\n",
    "df[\"Evoked\"] = [false_pos_ratio_e, 1 - false_pos_ratio_e]\n",
    "df.index = [\"false positive\", \"true positive\"]\n",
    "df\n",
    "\n",
    "# plot\n",
    "fig, axis = plt.subplots(1, 1, figsize=(0.5, 1))\n",
    "ax = (df).T.plot.bar(\n",
    "    ax=axis,\n",
    "    stacked=True,\n",
    "    color=[(0.5, 0.5, 0.5), (1, 1, 1)],\n",
    "    width=0.9,\n",
    "    edgecolor=[0, 0, 0],\n",
    "    linewidth=0.2,\n",
    ")\n",
    "\n",
    "# set axis legend\n",
    "ax.spines[[\"left\", \"right\", \"top\", \"bottom\"]].set_visible(False)\n",
    "y_axis = ax.axes.get_yaxis()\n",
    "y_axis.set_visible(False)\n",
    "ax.set_xticklabels(df.columns, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Sorting biases (ratio)\", fontsize=9)\n",
    "\n",
    "ax.legend(\n",
    "    df.index,\n",
    "    ncol=1,\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(1, 0),\n",
    "    frameon=False,\n",
    "    handletextpad=0.6,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# save figures\n",
    "plt.savefig(\n",
    "    \"/gpfs/bbp.cscs.ch/project/proj85/home/laquitai/spikebias/figures/3_bias/svg/false_positives_ratio_ks3.svg\",\n",
    "    **savefig_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality of sorted units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_kilosort_silico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
