{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# False positives\n",
    "\n",
    "author: steeve.laquitaine@epfl.ch  \n",
    "last modified: 13-02-2024\n",
    "\n",
    "**Method**:\n",
    "\n",
    "* **delta_time (Δ𝑡)** = 1.3 ms: the time windows before and after the spike timestamp of a ground truth. When a the timestamp of a sorted unit falls within this time window, they coincide and the sorted timestamp is a hit.\n",
    "* **chance level score**: see paper\n",
    "* **dark (missed) units**: ground truth units with sorting accuracy below the chance agreement score (their best match with a sorted unit produce an agreement score below chance).\n",
    "* **false positive units**: units which timestamps never hit the timestamps of the ground truth units wihin 50 microns of the probe: they never fall withing the delta_time window.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Create or activate env `spikeinterf...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-26 10:47:12,229 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-08-26 10:47:12,356 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2024-08-26 10:47:12,360 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-08-26 10:47:12,429 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2024-08-26 10:47:12,430 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-08-26 10:47:12,495 - root - utils.py - get_config - INFO - Reading experiment config. - done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import spikeinterface as si\n",
    "from spikeinterface import comparison\n",
    "import copy\n",
    "proj_path = \"/gpfs/bbp.cscs.ch/project/proj85/home/laquitai/preprint_2023/\"\n",
    "os.chdir(proj_path)\n",
    "\n",
    "from src.nodes.postpro.cell_matching import get_SpikeInterface_matching_object\n",
    "from src.nodes.utils import get_config\n",
    "from src.nodes.postpro.feateng import (add_firing_rates)\n",
    "from src.nodes.analysis.failures import accuracy as acc\n",
    "from src.nodes.metrics.metrics import get_firing_rate\n",
    "\n",
    "# PARAMETERS\n",
    "REC_DURATION = 600 # 10 minutes recording\n",
    "DET = 0.8\n",
    "CHANCE_THRESH = 0.1\n",
    "\n",
    "# DATASETS\n",
    "\n",
    "# NPX\n",
    "# Synthetic\n",
    "cfg_nb, _ = get_config(\"buccino_2020\", \"2020\").values()\n",
    "GT_nb_10m = cfg_nb[\"sorting\"][\"simulation\"][\"ground_truth\"][\"10m\"][\"output\"]\n",
    "KS4_nb = cfg_nb[\"sorting\"][\"sorters\"][\"kilosort3\"][\"10m\"][\"output\"]\n",
    "REC_nb = cfg_nb[\"probe_wiring\"][\"full\"][\"output\"]\n",
    "\n",
    "# biophy spont\n",
    "cfg_ns, _ = get_config(\"silico_neuropixels\", \"concatenated\").values()\n",
    "KS4_ns = cfg_ns[\"sorting\"][\"sorters\"][\"kilosort3\"][\"output\"]\n",
    "GT_ns_10m = cfg_ns[\"sorting\"][\"simulation\"][\"ground_truth\"][\"10m\"][\"output\"]\n",
    "REC_ns = cfg_ns[\"probe_wiring\"][\"full\"][\"output\"]\n",
    "\n",
    "# biophy evoked\n",
    "cfg_ne, _ = get_config(\"silico_neuropixels\", \"stimulus\").values()\n",
    "KS4_ne = cfg_ne[\"sorting\"][\"sorters\"][\"kilosort3\"][\"output\"]\n",
    "GT_ne_10m = cfg_ne[\"sorting\"][\"simulation\"][\"ground_truth\"][\"10m\"][\"output\"]\n",
    "REC_ne = cfg_ne[\"probe_wiring\"][\"full\"][\"output\"]\n",
    "\n",
    "# FIGURE SETTINGS\n",
    "COLOR_VIVO = (0.7, 0.7, 0.7)\n",
    "COLOR_SILI = (0.84, 0.27, 0.2)\n",
    "COLOR_STIM = (0.6, 0.75, 0.1)\n",
    "BOX_ASPECT = 1                  # square fig\n",
    "FIG_SIZE = (1,1)\n",
    "plt.rcParams['figure.figsize'] = (2,1)\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 6\n",
    "plt.rcParams['lines.linewidth'] = 0.2\n",
    "plt.rcParams['axes.linewidth'] = 0.5\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['xtick.major.width'] = 0.3\n",
    "plt.rcParams['xtick.minor.size'] = 0.1\n",
    "plt.rcParams['xtick.major.size'] = 1.5\n",
    "plt.rcParams['ytick.major.size'] = 1.5\n",
    "plt.rcParams['ytick.major.width'] = 0.3\n",
    "legend_cfg = {\"frameon\": False, \"handletextpad\": 0.1}\n",
    "savefig_cfg = {\"transparent\":True}\n",
    "# print(plt.rcParams.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012999992676670962"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate chance score for a 1 Hz sorted unit (spikes/secs)\n",
    "fr_gt = 1\n",
    "fr_s = 1\n",
    "delta_time = 1.3  # in ms\n",
    "rec_dur = 600  # recording duration\n",
    "\n",
    "# calculate chance agreement score\n",
    "# - chance probability of hits\n",
    "# - chance score\n",
    "p_chance_hit = acc.get_p_chance_hit(1 / 1000, 1.3)\n",
    "chance_acc = acc.get_unit_chance_agreement_score(fr_gt, fr_s, 600, p_chance_hit)\n",
    "chance_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sorted_unit_biases(agreem_mx, det):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        agreem_mx (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        (dict):\n",
    "        - \"match\" (pd.DataFrame): N ground truth unit indices, N best-match sorted units\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # note: with this approach (BEST matching approach), the same sorted unit can be paired with more than one true unit\n",
    "    # we only keep the pairings with highest agreement scores\n",
    "    # true-sorted unit pairing\n",
    "    pairing = agreem_mx.T.idxmax(axis=1)\n",
    "    pairing = pairing.to_frame()\n",
    "    pairing.columns = [\"sorted\"]\n",
    "\n",
    "    # add agreement score\n",
    "    accuracy = agreem_mx.T.max(axis=1)\n",
    "    pairing[\"accuracy\"] = accuracy\n",
    "\n",
    "    # check if the only sorted unit paired with this true unit\n",
    "    sorted_ids = agreem_mx.index\n",
    "\n",
    "    df = copy.copy(pairing.iloc[0, :].to_frame().T)\n",
    "    false_positives = []\n",
    "\n",
    "    # else keep the pairing with highest agreement score\n",
    "    # loop over all sorted single unit units\n",
    "    for ix in range(len(sorted_ids)):\n",
    "        # case the sorted unit was paired with a ground truth unit\n",
    "        if any(pairing[\"sorted\"] == sorted_ids[ix]):\n",
    "            sorted_pairings = pairing[pairing[\"sorted\"] == sorted_ids[ix]].sort_values(\n",
    "                by=\"accuracy\", ascending=False\n",
    "            )\n",
    "            # take max pairing (first row)\n",
    "            df = pd.concat([df, sorted_pairings.iloc[0, :].to_frame().T])\n",
    "        else:\n",
    "            # case the sorted unit was paired with none of the ground truth units\n",
    "            false_positives.append(sorted_ids[ix])\n",
    "\n",
    "    df = df[1:]\n",
    "    df[\"sorted\"] = df[\"sorted\"].astype(int)\n",
    "\n",
    "    # count biases\n",
    "    n_good = sum(df[\"accuracy\"] >= det)\n",
    "    n_poor = sum((df[\"accuracy\"] >= CHANCE_THRESH) & (df[\"accuracy\"] < det))\n",
    "    n_below_chance = sum((df[\"accuracy\"] > 0) & (df[\"accuracy\"] < CHANCE_THRESH))\n",
    "    n_false_pos = len(false_positives)\n",
    "\n",
    "    # sanity check\n",
    "    # assert n_good + n_poor + n_below_chance + n_false_pos == len(\n",
    "    #     sorted_ids\n",
    "    # ), \"They must match\"\n",
    "    return {\n",
    "        \"n_good\": n_good,\n",
    "        \"n_poor\": n_poor,\n",
    "        \"n_below_chance\": n_below_chance,\n",
    "        \"n_false_pos\": n_false_pos,\n",
    "        \"match\": pairing,\n",
    "    }\n",
    "\n",
    "\n",
    "# def get_sorting_quality(scores: pd.DataFrame):\n",
    "#     \"\"\"qualify sorted units\n",
    "\n",
    "#     Args:\n",
    "#         scores (_type_): agreement scores for N rows\n",
    "#         of sorted units x M columns of ground truth units\n",
    "\n",
    "#     Returns:\n",
    "#         dict: _description_\n",
    "#     \"\"\"\n",
    "\n",
    "#     # The same sorted unit can be paired with more than one true unit\n",
    "#     # we only keep the pairings with highest agreement scores\n",
    "#     # true-sorted unit pairing\n",
    "#     match = scores.T.idxmax(axis=1)\n",
    "#     match = match.to_frame()\n",
    "#     match.index.name = \"true\"\n",
    "#     match.columns = [\"sorted\"]\n",
    "\n",
    "#     # add agreement score\n",
    "#     accuracy = scores.max(axis=0)\n",
    "#     match[\"accuracy\"] = accuracy\n",
    "\n",
    "#     sorted_ids = scores.index\n",
    "\n",
    "#     df = pd.DataFrame()\n",
    "#     false_positives = []\n",
    "\n",
    "#     # else keep the match with highest agreement score\n",
    "#     # loop over all sorted single unit units\n",
    "#     for ix in range(len(sorted_ids)):\n",
    "#         # case the sorted unit was paired with a ground truth unit\n",
    "#         if any(match[\"sorted\"] == sorted_ids[ix]):\n",
    "#             sorted_matchs = match[match[\"sorted\"] == sorted_ids[ix]].sort_values(\n",
    "#                 by=\"accuracy\", ascending=False\n",
    "#             )\n",
    "#             # take max pairing (first row)\n",
    "#             df = pd.concat([df, sorted_matchs.iloc[0, :].to_frame().T])\n",
    "#         else:\n",
    "#             # case the sorted unit was paired with none of the ground truth units\n",
    "#             false_positives.append(sorted_ids[ix])\n",
    "\n",
    "#     df[\"sorted\"] = df[\"sorted\"].astype(int)\n",
    "\n",
    "#     # count biases\n",
    "#     n_good = sum(df[\"accuracy\"] >= DET_THRESH)\n",
    "#     n_poor = sum((df[\"accuracy\"] >= CHANCE_THRESH) & (df[\"accuracy\"] < DET_THRESH))\n",
    "#     n_below_chance = sum((df[\"accuracy\"] > 0) & (df[\"accuracy\"] < CHANCE_THRESH))\n",
    "#     n_false_pos = len(false_positives)\n",
    "\n",
    "#     # sanity check\n",
    "#     # assert n_good + n_poor + n_below_chance + n_false_pos == len(\n",
    "#     #    sorted_ids\n",
    "#     # ), \"They must match\"\n",
    "#     return {\n",
    "#         \"n_good\": n_good,\n",
    "#         \"n_poor\": n_poor,\n",
    "#         \"n_below_chance\": n_below_chance,\n",
    "#         \"n_false_pos\": n_false_pos,\n",
    "#         \"match\": match,\n",
    "#     }\n",
    "\n",
    "\n",
    "def plot_sorting_quality(ax, scores_by_exp):\n",
    "\n",
    "    # set all colors\n",
    "    colors = [\n",
    "        [0.7, 0.1, 0.1],  # \"good\" (strong red)\n",
    "        [1, 0.85, 0.85],  # \"poor\" (pink)\n",
    "        [0.95, 0.95, 0.95],  # \"below chance\"\n",
    "        \"w\",  # \"false positive\"\n",
    "    ]\n",
    "\n",
    "    # count sorted unit biases for each dataset\n",
    "    # agreem_names = [\"Buccino\", \"Marques\", \"Horvath\", \"Evoked\"]\n",
    "    exps = [\"NS\"]\n",
    "\n",
    "    df2 = pd.DataFrame()\n",
    "\n",
    "    for ix in range(len(exps)):\n",
    "        out = get_sorting_quality(scores_by_exp[ix])\n",
    "        df2[exps[ix]] = [\n",
    "            out[\"n_good\"],\n",
    "            out[\"n_poor\"],\n",
    "            out[\"n_below_chance\"],\n",
    "            out[\"n_false_pos\"],\n",
    "        ]\n",
    "    df2.index = [\"good\", \"poor\", \"below chance\", \"false positive\"]\n",
    "    df2_ratio = df2 / df2.sum()\n",
    "\n",
    "    ax = (df2_ratio).T.plot.bar(\n",
    "        ax=ax,\n",
    "        stacked=True,\n",
    "        color=colors,\n",
    "        width=0.9,\n",
    "        edgecolor=[0, 0, 0],\n",
    "        linewidth=0.2,\n",
    "    )\n",
    "\n",
    "    # set axis legend\n",
    "    ax.spines[[\"left\", \"right\", \"top\", \"bottom\"]].set_visible(False)\n",
    "    y_axis = ax.axes.get_yaxis()\n",
    "    y_axis.set_visible(False)\n",
    "    ax.set_xticklabels(df2_ratio.columns, rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel(\"Sorting biases (ratio)\", fontsize=9)\n",
    "\n",
    "    ax.legend(\n",
    "        df2.index,\n",
    "        ncol=1,\n",
    "        loc=\"lower left\",\n",
    "        bbox_to_anchor=(1, 0),\n",
    "        frameon=False,\n",
    "        handletextpad=0.6,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def get_true_unit_best_match(scores: pd.DataFrame):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Some scores can be 0, if they were the best found\n",
    "\n",
    "    Args:\n",
    "        scores (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # the same sorted unit can be paired with more than one true unit\n",
    "    # we keep the pairings with highest agreement scores\n",
    "    # true-sorted unit pairing\n",
    "    match = scores.idxmax(axis=0)\n",
    "    match = match.to_frame()\n",
    "    match.columns = [\"sorted\"]\n",
    "    match.index.name = \"true\"\n",
    "\n",
    "    # record agreement score\n",
    "    match[\"accuracy\"] = scores.max(axis=0)\n",
    "    return match\n",
    "\n",
    "\n",
    "def count_match(match: pd.DataFrame, sorted: int):\n",
    "    \"\"\"count the number of true units\n",
    "    one sorted unit matches\n",
    "\n",
    "    Args:\n",
    "        match (pd.DataFrame):\n",
    "        - index: true units id\n",
    "        - columns:\n",
    "        - - \"sorted\": best-match sorted unit id\n",
    "        - - \"accuracy\": best-match agreement score\n",
    "        (true unit sorting accuracy)\n",
    "    \"\"\"\n",
    "    return sum(match[\"sorted\"] == sorted)\n",
    "\n",
    "\n",
    "def get_best_matched_true_unit(match, s_id):\n",
    "    \"\"\"get true unit matchs\n",
    "\n",
    "    Args:\n",
    "        match (_type_): _description_\n",
    "        s_id (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    units = match[match[\"sorted\"] == s_id].index.values\n",
    "    if len(units) == 1:\n",
    "        units = units[0]\n",
    "    return units\n",
    "\n",
    "\n",
    "def get_all_matched_true_unit(s_id, scores):\n",
    "    \"\"\"get all true unit matchs\n",
    "\n",
    "    Args:\n",
    "        match (_type_): _description_\n",
    "        s_id (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    return np.array(scores.columns[scores.loc[s_id, :] > 0])\n",
    "\n",
    "\n",
    "def get_chance_score(gt_id, s_id, Sorting_ns, SortingTrue_ns, duration, delta_time):\n",
    "    fr_s = get_firing_rate(s_id, Sorting_ns, duration)\n",
    "    fr_gt = get_firing_rate(gt_id, SortingTrue_ns, duration)\n",
    "    p_chance_hit = acc.get_p_chance_hit(min(fr_gt, fr_s) / 1000, delta_time)\n",
    "    return acc.get_unit_chance_agreement_score(fr_gt, fr_s, duration, p_chance_hit)\n",
    "\n",
    "\n",
    "def get_score(scores, s_id, gt_id):\n",
    "    try:\n",
    "        return scores.loc[s_id, gt_id]\n",
    "    except:\n",
    "        from ipdb import set_trace\n",
    "\n",
    "        set_trace()\n",
    "\n",
    "\n",
    "def is_score_at_chance(\n",
    "    scores, s_id, gt_id, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "):\n",
    "    score = get_score(scores, s_id, gt_id)\n",
    "    chance = get_chance_score(\n",
    "        gt_id, s_id, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "    )\n",
    "    return score <= chance\n",
    "\n",
    "\n",
    "def are_all_scores_at_chance(\n",
    "    s_id, gt_id, scores, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "):\n",
    "    \"\"\"check whether a sorted unit agreement scores with the many\n",
    "    ground truth units it matches are all at chance (it is a false\n",
    "    positive)\n",
    "\n",
    "    Args:\n",
    "        s_id (_type_): sorted unit id\n",
    "        gt_id (_type_): ground truth unit id\n",
    "        scores (_type_): _description_\n",
    "        match (_type_): _description_\n",
    "        Sorting_ns (_type_): _description_\n",
    "        SortingTrue_ns (_type_): _description_\n",
    "        duration (_type_): _description_\n",
    "        delta_time (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # make an 1D array\n",
    "    gt_id = make_1darray(gt_id)\n",
    "\n",
    "    # start counting scores below chance\n",
    "    d = 0\n",
    "    for _, g_i in enumerate(gt_id):\n",
    "        d += is_score_at_chance(\n",
    "            scores, s_id, g_i, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "        )\n",
    "    return d == len(gt_id)\n",
    "\n",
    "\n",
    "def make_1darray(gt_id):\n",
    "    if isinstance(gt_id, np.ndarray):\n",
    "        return gt_id\n",
    "    else:\n",
    "        return np.array([gt_id])\n",
    "\n",
    "\n",
    "def is_oversplitter_1(\n",
    "    scores, match, s_id, gt_id, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "):\n",
    "    \"\"\"check when sorted unit matches only one ground truth unit\n",
    "\n",
    "    Args:\n",
    "        scores (_type_): _description_\n",
    "        match (_type_): _description_\n",
    "        s_id (_type_): _description_\n",
    "        gt_id (_type_): _description_\n",
    "        Sorting_ns (_type_): _description_\n",
    "        SortingTrue_ns (_type_): _description_\n",
    "        duration (_type_): _description_\n",
    "        delta_time (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # find all sorted units that match this ground truth unit\n",
    "    sorteds = match[match.index == gt_id][\"sorted\"].values.tolist()\n",
    "\n",
    "    d = 0\n",
    "    # loop over sorted unit match\n",
    "    for _, s_i in enumerate(sorteds):\n",
    "\n",
    "        # check for other sorted unit match\n",
    "        # than the target match s_id\n",
    "        if not s_i == s_id:\n",
    "            d += is_score_at_chance(\n",
    "                scores,\n",
    "                s_i,\n",
    "                gt_id,\n",
    "                Sorting_ns,\n",
    "                SortingTrue_ns,\n",
    "                duration,\n",
    "                delta_time,\n",
    "            )\n",
    "    return d > 0\n",
    "\n",
    "\n",
    "def is_oversplitter_2(\n",
    "    s_id, gt_id, scores, match, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "):\n",
    "    \"\"\"check when sorted unit matches many ground truth units\n",
    "\n",
    "    Args:\n",
    "        s_id (_type_): _description_\n",
    "        scores (_type_): _description_\n",
    "        match (_type_): _description_\n",
    "        Sorting_ns (_type_): _description_\n",
    "        SortingTrue_ns (_type_): _description_\n",
    "        duration (_type_): _description_\n",
    "        delta_time (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    d = 0\n",
    "    for _, g_i in enumerate(gt_id):\n",
    "        d += is_oversplitter_1(\n",
    "            scores,\n",
    "            match,\n",
    "            s_id,\n",
    "            g_i,\n",
    "            Sorting_ns,\n",
    "            SortingTrue_ns,\n",
    "            duration,\n",
    "            delta_time,\n",
    "        )\n",
    "    return d > 0\n",
    "\n",
    "\n",
    "def is_poor(det, scores, gt_id, s_id, Sorting_ns, SortingTrue_ns, duration, delta_time):\n",
    "    \"\"\"is poor (score between chance and threshold for \"good\" (80%))\n",
    "\n",
    "    Args:\n",
    "        scores (_type_): _description_\n",
    "        gt_id (_type_): _description_\n",
    "        s_id (_type_): _description_\n",
    "        Sorting_ns (_type_): _description_\n",
    "        SortingTrue_ns (_type_): _description_\n",
    "        duration (_type_): _description_\n",
    "        delta_time (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    chance = get_chance_score(\n",
    "        gt_id, s_id, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "    )\n",
    "    score = get_score(scores, s_id, gt_id)\n",
    "    return (score > chance) & (score < det)\n",
    "\n",
    "\n",
    "def is_poor_2(\n",
    "    s_id, gt_id, scores, Sorting_ns, SortingTrue_ns, duration, delta_time, det\n",
    "):\n",
    "    \"\"\"is poor when sorted unit matches many ground truth units\n",
    "    (all its scores with the ground truth are below the \"good\" threshold\n",
    "    and it has at least one score with a ground truth above chance\n",
    "\n",
    "    Args:\n",
    "        s_id (_type_): _description_\n",
    "        match (_type_): _description_\n",
    "        Sorting_ns (_type_): _description_\n",
    "        SortingTrue_ns (_type_): _description_\n",
    "        duration (_type_): _description_\n",
    "        delta_time (_type_): _description_\n",
    "        det (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    chance_all = []\n",
    "    score_all = []\n",
    "\n",
    "    for _, g_i in enumerate(gt_id):\n",
    "        chance_all.append(\n",
    "            get_chance_score(\n",
    "                g_i, s_id, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "            )\n",
    "        )\n",
    "        score_all.append(get_score(scores, s_id, g_i))\n",
    "\n",
    "    # all scores are below DET\n",
    "    test_1 = all(np.array(score_all) < det)\n",
    "\n",
    "    # at least one score is above chance\n",
    "    test_2 = any(np.array(score_all) > np.array(chance_all))\n",
    "    return test_1 & test_2\n",
    "\n",
    "\n",
    "def is_overmerger_2(\n",
    "    s_id, gt_id, scores, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "):\n",
    "    \"\"\"is an overmerger: the sorted unit matches more than one ground\n",
    "    truth with above chance scores\n",
    "\n",
    "    Args:\n",
    "        s_id (_type_): _description_\n",
    "        match (_type_): _description_\n",
    "        Sorting_ns (_type_): _description_\n",
    "        SortingTrue_ns (_type_): _description_\n",
    "        duration (_type_): _description_\n",
    "        delta_time (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # get there scores\n",
    "    chance_all = []\n",
    "    score_all = []\n",
    "\n",
    "    for _, g_i in enumerate(gt_id):\n",
    "        # get chance scores\n",
    "        chance_all.append(\n",
    "            get_chance_score(\n",
    "                g_i, s_id, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "            )\n",
    "        )\n",
    "        # get scores\n",
    "        score_all.append(get_score(scores, s_id, g_i))\n",
    "    return sum(np.array(score_all) > np.array(chance_all)) > 1\n",
    "\n",
    "\n",
    "def is_good(det, scores, gt_id, s_id):\n",
    "    \"\"\"is good (score above good unit threshold (80%)\n",
    "\n",
    "    Args:\n",
    "        scores (_type_): _description_\n",
    "        gt_id (_type_): _description_\n",
    "        s_id (_type_): _description_\n",
    "        det (float); good unit lower agreement score threshold\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    score = get_score(scores, s_id, gt_id)\n",
    "    return score >= det\n",
    "\n",
    "\n",
    "def is_good_2(s_id, gt_id, scores, Sorting_ns, SortingTrue_ns, duration, delta_time):\n",
    "    \"\"\"is sorted unit good: it matches one ground truth with > 80% and no\n",
    "    other ground truth with\n",
    "\n",
    "    Args:\n",
    "        s_id (_type_): _description_\n",
    "        scores (_type_): _description_\n",
    "        match (_type_): _description_\n",
    "        Sorting_ns (_type_): _description_\n",
    "        SortingTrue_ns (_type_): _description_\n",
    "        duration (_type_): _description_\n",
    "        delta_time (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # get there scores\n",
    "    chance_all = []\n",
    "    score_all = []\n",
    "\n",
    "    for _, g_i in enumerate(gt_id):\n",
    "        # get chance scores\n",
    "        chance_all.append(\n",
    "            get_chance_score(\n",
    "                g_i, s_id, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "            )\n",
    "        )\n",
    "        # get scores\n",
    "        score_all.append(get_score(scores, s_id, g_i))\n",
    "\n",
    "    # tests\n",
    "    test_1 = sum(np.array(score_all) >= DET) == 1\n",
    "    test_2 = sum(np.array(score_all) > np.array(chance_all)) == 1\n",
    "    return test_1 & test_2\n",
    "\n",
    "\n",
    "def set_df(df, sorted, true, quality, score):\n",
    "    df.loc[sorted, \"sorted\"] = sorted\n",
    "    df.loc[sorted, \"true\"] = true\n",
    "    df.loc[sorted, \"score\"] = score\n",
    "    qual = df.loc[sorted, \"quality\"]\n",
    "    # record quality if nan (empty)\n",
    "    # else append new quality\n",
    "    if isinstance(qual, str):\n",
    "        df.loc[sorted, \"quality\"] += quality\n",
    "    else:\n",
    "        df.loc[sorted, \"quality\"] = quality\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_scores(\n",
    "    SortingTrue,\n",
    "    Sorting,\n",
    "    delta_time: float,\n",
    "):\n",
    "    comp = comparison.compare_sorter_to_ground_truth(\n",
    "        SortingTrue,\n",
    "        Sorting,\n",
    "        exhaustive_gt=True,\n",
    "        delta_time=delta_time,\n",
    "    )\n",
    "    # return comp.agreement_scores.max(axis=1).sort_values(ascending=False).values\n",
    "    return comp.agreement_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/project/proj85/scratch/laquitai/4_preprint_2023/envs/spikinterf0_100_5/lib/python3.9/site-packages/spikeinterface/core/base.py:1079: UserWarning: Versions are not the same. This might lead to compatibility errors. Using spikeinterface==0.96.1 is recommended\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load SortingExtractors\n",
    "SortingTrue_ns = si.load_extractor(GT_ns_10m)\n",
    "Sorting_ns = si.load_extractor(KS4_ns)\n",
    "Rec_ns = si.load_extractor(REC_ns)\n",
    "\n",
    "# get scores (N sorted units rows x N true units columns)\n",
    "scores_ns = get_scores(SortingTrue_ns, Sorting_ns, 1.3)\n",
    "scores_ns = scores_ns.T\n",
    "\n",
    "# curate (get single-unit only)\n",
    "scores_ns = scores_ns.loc[\n",
    "    Sorting_ns.unit_ids[Sorting_ns.get_property(\"KSLabel\") == \"good\"], :\n",
    "]\n",
    "\n",
    "scores_by_exp = [scores_ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute sorting quality\n",
    "out = classify_sorted_unit_biases(scores_ns, DET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method**:\n",
    "\n",
    "* For each true unit we find its best-match sorted unit\n",
    "* calculate chance level for all units is pairs is consuming-\n",
    "* all NaN scores are sorted units' will many ground truth matches.\n",
    "* 15 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores_ns\n",
    "\n",
    "match = get_true_unit_best_match(scores_ns)\n",
    "\n",
    "# qualify all sorted units\n",
    "duration = min(Rec_ns.get_total_duration(), REC_DURATION)\n",
    "sorted_ids = scores.index\n",
    "false_pos = []\n",
    "\n",
    "df = pd.DataFrame({\"sorted\": [], \"true\": [], \"quality\": np.nan})\n",
    "\n",
    "many = []\n",
    "ones = []\n",
    "test1 = []\n",
    "test2 = []\n",
    "\n",
    "sorted_copy = copy.copy(sorted_ids)\n",
    "\n",
    "# qualify each sorted single-unit\n",
    "for _, s_id in enumerate(sorted_ids):\n",
    "\n",
    "    # get all ground truths matched by this sorted unit\n",
    "    gt_id = get_all_matched_true_unit(s_id, scores)\n",
    "\n",
    "    # false positive: all scores are at chance\n",
    "    if are_all_scores_at_chance(\n",
    "        s_id, gt_id, scores, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "    ):\n",
    "        df = set_df(df, s_id, np.nan, \"+ false_pos \", np.nan)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # if it best-detected a true unit\n",
    "        if s_id in match[\"sorted\"].values:\n",
    "\n",
    "            # get best-matched ground truths\n",
    "            gt_id = get_best_matched_true_unit(match, s_id)\n",
    "\n",
    "            # if it detected a single true unit\n",
    "            # - can be a false positive\n",
    "            # - poor (chance - 80%)\n",
    "            # - an oversplitter\n",
    "            # - good (above 80%)\n",
    "            # - cannot be an overmerger\n",
    "            if count_match(match, s_id) == 1:\n",
    "\n",
    "                gt_id = int(gt_id)\n",
    "                s_id = int(s_id)\n",
    "                score = get_score(scores, s_id, gt_id)\n",
    "\n",
    "                # poor (chance < score < DET)\n",
    "                if is_poor(\n",
    "                    DET,\n",
    "                    scores,\n",
    "                    gt_id,\n",
    "                    s_id,\n",
    "                    Sorting_ns,\n",
    "                    SortingTrue_ns,\n",
    "                    duration,\n",
    "                    delta_time,\n",
    "                ):\n",
    "                    df = set_df(df, s_id, gt_id, \"+ poor \", score)\n",
    "\n",
    "                # oversplitter\n",
    "                if is_oversplitter_1(\n",
    "                    scores,\n",
    "                    match,\n",
    "                    s_id,\n",
    "                    gt_id,\n",
    "                    Sorting_ns,\n",
    "                    SortingTrue_ns,\n",
    "                    duration,\n",
    "                    delta_time,\n",
    "                ):\n",
    "                    df = set_df(df, s_id, gt_id, \"+ oversplitter \", score)\n",
    "\n",
    "                # good\n",
    "                if is_good(DET, scores, gt_id, s_id):\n",
    "                    df = set_df(df, s_id, gt_id, \"+ good \", score)\n",
    "\n",
    "                ones.append(s_id)\n",
    "\n",
    "            # many ground truths are matched\n",
    "            else:\n",
    "\n",
    "                # oversplitter\n",
    "                if is_oversplitter_2(\n",
    "                    s_id,\n",
    "                    gt_id,\n",
    "                    scores,\n",
    "                    match,\n",
    "                    Sorting_ns,\n",
    "                    SortingTrue_ns,\n",
    "                    duration,\n",
    "                    delta_time,\n",
    "                ):\n",
    "                    df = set_df(df, s_id, np.nan, \"+ oversplitter \", np.nan)\n",
    "\n",
    "                # overmerger\n",
    "                if is_overmerger_2(\n",
    "                    s_id,\n",
    "                    gt_id,\n",
    "                    scores,\n",
    "                    Sorting_ns,\n",
    "                    SortingTrue_ns,\n",
    "                    duration,\n",
    "                    delta_time,\n",
    "                ):\n",
    "                    df = set_df(df, s_id, np.nan, \"+ overmerger \", np.nan)\n",
    "\n",
    "                # poor\n",
    "                if is_poor_2(\n",
    "                    s_id,\n",
    "                    gt_id,\n",
    "                    scores,\n",
    "                    Sorting_ns,\n",
    "                    SortingTrue_ns,\n",
    "                    duration,\n",
    "                    delta_time,\n",
    "                    DET,\n",
    "                ):\n",
    "                    df = set_df(df, s_id, np.nan, \"+ poor \", np.nan)\n",
    "\n",
    "                # good\n",
    "                if is_good_2(\n",
    "                    s_id,\n",
    "                    gt_id,\n",
    "                    scores,\n",
    "                    Sorting_ns,\n",
    "                    SortingTrue_ns,\n",
    "                    duration,\n",
    "                    delta_time,\n",
    "                ):\n",
    "                    df = set_df(df, s_id, np.nan, \"+ good \", np.nan)\n",
    "\n",
    "        # if it was not the best match to any true unit\n",
    "        if not s_id in match[\"sorted\"].values:\n",
    "\n",
    "            many.append(s_id)\n",
    "\n",
    "            gt_id = get_all_matched_true_unit(s_id, scores)\n",
    "\n",
    "            # # if it matched one true unit\n",
    "\n",
    "            # oversplitter: it matched more than\n",
    "            # else:\n",
    "\n",
    "# unit-test\n",
    "# assert len(df) == len(sorted_ids), \"some sorted units were not qualified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['+ overmerger + poor ', '+ poor '], dtype=object)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.quality.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_id = 326  # 326  # 326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffe3b01f370>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAAB+CAYAAABhy172AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAALsElEQVR4nO3cW0wU9x4H8O9wUaTgUhHpKtRLOcUTQ8uxWQW2e5FeQrXSk5SWtjk2TV8IPtQ+tOljm/ahz/aSpmmaGtOgsX0pae3N6LJQje65sBHsUaAeQaDAyrLLLuyyO/s/D8i2VhiXsuMM4/cTH3TnPzO/GfzuzDDzG0kIIUBE88rQugAiPWNAiBQwIEQKGBAiBQwIkQIGhEgBA0KkgAEhUsCAECnQVUCam5u1LoHoBroKyODgoNYlEN1AVwEh0hsGRAW+UBTDgWmty6A0YEBUMD0jYzIS17oMSgMGRCUJdhEYAgOiEjnBgBgBA6ISHkCMgQFRCY8gxrCogLzxxhuw2WzYt28fYrFY8vNLly6hsrISOTk5CIVCyc/z8/PhdDrhdDpx/vz59FW9DPAaxBhSDojX68Xg4CDa29uxdetWfPnll8lpJSUlaGtrQ1VV1Q3zlJeXw+VyweVyoaKiIn1VLwMMiDGkHJDTp0/j8ccfBwDU1dXhp59+Sk7Lzc2FyWS6aZ6+vj7Y7XY0NzcjEoksuGyPxwOPx7OYunWPZ1jGkHJA/H4/Vq9eDQAwmUwYHx+/5Ty9vb1wu90wm8348MMP/3yVy4wQvAYxipQDUlBQgGAwCAAIBAJYs2bNLecpLCwEADQ0NMDr9S44zmKxwGKxpFrKssBTLGNIOSA1NTU4ceIEAOD777+H1WpVHB8OhyHLMgCgvb0dZWVlSyhz+UkktK6A0iHlgFRWVqK4uBg2mw3d3d14+umn0dTUBGD29OvRRx+F1+vF3r178e2336KnpwcWiwV2ux3Hjx/HgQMHVNsIPeIRxBgkPb1Zsb6+Hq2trVqXsWT916bQ5wthV/k6rUuhJeKNQhUICOjoe4eWgAFRicxrEENgQFTCaxBjYEBUkuB9EENgQFTCfBgDA6ICIQCZp1iGwICohL/FMgYGRCV8FssYGBCVMB/GwICoQIC/xTIKBkQlvEg3BgZEJbxRaAyq9qQfPHgQVqsV9fX1yV6SOwXPsIxBtZ50n8+H1tZWdHR0oLGx8Y7qKCTjUK0n3ePxwOFwQJKkm8YbHe+BGEdWqgP9fj/MZjOA1HrSF9PDbrQXNpBxqNaT/md62In0RrWedIvFArfbndJ4I760QdK6AEoL1XrSi4qKsGfPHlitVrS0tGD//v2qbQSRWtiTroK+sRDO9F3DP6o2al0KLRFvFBIpYEBUIvEixBAYECIFDIgK9HNVR0vFgBApYEBUIvFOiCEwIEQKGBAiBQyIKniVbhQMiEp4H8QYGBAiBQwIkQIGhEhBWl7aIMsyXn75ZdhsNrz66qvJz/Pz8+F0OuF0OnH+/Pm0Fa13vJNuHGl5acPXX3+N9evXo729HeFwGGfOnAEAlJeXw+VyweVyoaKiIv3V6xiv0Y0hLS9tWGhaX18f7HY7mpubEYlEFly2x+NhXzrpUsoBUXoJw0LTent74Xa7YTab+dofWpbS8tKGhaYVFhYCABoaGuD1ehdcttF60nkJYhxpeWnDfNPC4TBkWQYAtLe3o6ysLJ11E90WaXlpw5NPPon+/n7YbDbk5OSguroaPT09sFgssNvtOH78OA4cOKDaRugR76QbA1/aoIJLI5P4T78fjZZ7tS6Flog3CokUMCAq0M8xmZaKASFSwICohC23xsCAEClgQFQgeKvQMBgQIgUMiFp4CWIIDAiRAgaESAEDogLeKDQOBkQlvAQxBlV70g8ePAir1Yr6+vpkvwjRcqJaT7rP50Nrays6OjrQ2NjIjkJallTrSfd4PHA4HJAk6abxSxGJyfCForjsC+OXsRDC0fhNYy6NTOJ0nw+B6dg8SwDC0Tj6r01hYHwKo8EIekcnbxozEly4hz4VCSFwq06CmXgCfde34cJQEKOTEYwGI/h5ePZo2zsaQjASgxACMTkBABgYn4IQAq6Lo/CFogCQnAbM7p/e0RAiMRkjwQiu+mfHz8QTEEJATszWNVebEAL/uuLHqf+OIjTPvpwjhEBgKoahiWnE5ATkhEiu+9dABF2DAXQNBvDLWAi/BiIIRmKI/66uuWX0jk4iMB3DL2Oh5GdX/VOYjMSS2wMAoWgcl33h5Hrmah8Yn0qOicsJXPaFk/tLTgj8PBxEJCYjMB275f5PRVaqA/1+P8xmM4DUetKVetj/KJUXNvy734/JSBwrMjOQn5OF/JwsSFIGLgwHEY7GIUlScocUr87BetMqdA8GMHP9h/T76UIAGwtzIQCMTkaRtzILpy6OJq8b5IRA12AQD5aaIF3vfJqbV/pDJ9R8P4TAdAz3FeXBdWkM0jzzzM2XnZmB4tUrce5/45iYmkH3kMBfivMRkxM4dXEUADDgn8L0jIysDAkZkoTsrAx0DwVhWpWNrsFAst6szAwIIbAyKxPRuIxfAxEU5GZDkma/MC77prBl7V1ICIEMSQJm/yAhBB4sKcDduSvQdmkMkrTwNppWZeOulVm47AsjGpdn68nMwNq8lbjHlAMhgOkZGRPTMxgKyJiekRFP/LZ/EkIgFImjZySE++/Jvx7yGRSvXomJqRg2FuYmt2l0MopoTEbJmlxkSBIiMRkrsjIwE0+gdywECbNfFmXr8nHsnwP4+982IDgdQ//4FEruXoVITMbOzYXYtPauW/7fUpJyQBbbk15QUIDe3t55x/8Z2++9e97P7y3MXXCexeyc8nvyb/j3I38tTnnepSpbl3/rQUuwbb0ppXG7tq5Ladz9xemp976ivLQsp/q+wrQsZz6q9aRbLBa43e55x/+R0V7aQMahWk96UVER9uzZA6vVipaWFuzfv1+1jSBSi6560rdt25Z8VVBBQYG2xQCYmJgAoH0teqkD0E8tS61jw4YN+Oijj245TlcBAX67YNfDKZdeatFLHYB+arlddeguIER6wkdNiBQwIEQKGBAiBQwIkQLdBWShJ4Zvt0AggB07diAvLw9dXV2a1XHu3DlUV1fDbrfj+eef13SfjIyMoKamBg6HA7W1tRgeHtasFgA4cuQIioqKVF2HrgKi9MTw7Zabm4tvvvkGDQ0NmtUAAKWlpTh58iTcbjc2bdqEr776SrNa1q5di46ODrS1teHFF1/Ep59+qlktsizjiy++QGlpqarr0VVAlJ4Yvt2ys7NV/3ZKhdlsxqpVqwAAK1asQEaGdj+yzMzM5PonJyexbds2zWo5cuQInnnmGdX3h64CspgngO80V65cwQ8//IC9e/dqWkdnZyd27tyJDz74ANu3b9ekBlmWcezYMTQ2Nqq+Ll0FROmJ4TtZMBjEvn37cOjQIWRnZ2taS2VlJc6ePYt33nkH7777riY1fP7553j22Wdvy9FUVwFRemL4ThWPx/Hcc8/hzTffRHl5uaa1zMzMJP9uMpmQm7twq4GaLly4gMOHD6Ourg49PT145ZVX1FuZ0JnXXntNPPzww+KFF14Q0WhU01qeeOIJYTabRVVVlfjss880qeHw4cNizZo1wuFwCIfDIY4ePapJHUIIcfbsWWGz2YTT6RR1dXViaGhIs1rmPPTQQ6oun89iESnQ1SkWkd4wIEQKGBAiBQwIkQIGhEgBA0LLVqoPlEajUTQ1NaG2thZPPfXUotaR8nuxiPRm7oHS119/XXHc+++/j927dy86HACPILSMzfdA6aFDh2Cz2VBTU4OTJ08CAL777jt0dHTA6XTi448/XtQ6GBAyjGvXruHo0aNwu9348ccf8fbbbwMABgYGsGPHDpw4cQItLS24evVqysvkKRYZRl9fH7q7u7Fr1y4AwNjYGIDZh2Bra2uRlZWFmpoaXLx4ESUlJSktk0cQMowtW7bggQcewKlTp+ByudDZ2QkAsFqtyb97vV5s3rw55WXyWSxa1nbv3o3Ozk5s3LgRTU1NyMzMxCeffILMzExUVFTgvffew8jICF566SUEg0E89thjeOutt1JePgNCpICnWEQKGBAiBQwIkQIGhEgBA0KkgAEhUsCAEClgQIgUMCBEChgQIgUMCJGC/wPCR1WVnl5OCgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 200x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1979150"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1979150]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_234397/4156573646.py:412: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 50x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(0.5, 1))\n",
    "plot_sorting_quality(ax, scores_by_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_236392/888313127.py:53: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 50x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set all colors\n",
    "colors = [\n",
    "    [0.7, 0.1, 0.1],  # \"good\" (strong red)\n",
    "    [1, 0.85, 0.85],  # \"poor\" (pink)\n",
    "    [0.95, 0.95, 0.95],  # \"below chance\"\n",
    "    \"w\",  # \"false positive\"\n",
    "]\n",
    "\n",
    "# count sorted unit biases for each dataset\n",
    "# agreem_names = [\"Buccino\", \"Marques\", \"Horvath\", \"Evoked\"]\n",
    "exps = [\"NS\"]\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for ix in range(len(exps)):\n",
    "    out = classify_sorted_units(exp_scores[ix])\n",
    "    df2[exps[ix]] = [\n",
    "        out[\"n_good\"],\n",
    "        out[\"n_poor\"],\n",
    "        out[\"n_below_chance\"],\n",
    "        out[\"n_false_pos\"],\n",
    "    ]\n",
    "df2.index = [\"good\", \"poor\", \"below chance\", \"false positive\"]\n",
    "df2_ratio = df2 / df2.sum()\n",
    "\n",
    "fig, axis = plt.subplots(1, 1, figsize=(0.5, 1))\n",
    "ax = (df2_ratio).T.plot.bar(\n",
    "    ax=axis,\n",
    "    stacked=True,\n",
    "    color=colors,\n",
    "    width=0.9,\n",
    "    edgecolor=[0, 0, 0],\n",
    "    linewidth=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "# set axis legend\n",
    "ax.spines[[\"left\", \"right\", \"top\", \"bottom\"]].set_visible(False)\n",
    "y_axis = ax.axes.get_yaxis()\n",
    "y_axis.set_visible(False)\n",
    "ax.set_xticklabels(df2_ratio.columns, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Sorting biases (ratio)\", fontsize=9)\n",
    "\n",
    "ax.legend(\n",
    "    df2.index,\n",
    "    ncol=1,\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(1, 0),\n",
    "    frameon=False,\n",
    "    handletextpad=0.6,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# # save figures\n",
    "# plt.savefig(\n",
    "#     \"/gpfs/bbp.cscs.ch/project/proj85/home/laquitai/preprint_2023/figures/3_bias/svg/sorted_unit_biases_ks3.svg\",\n",
    "#     **savefig_cfg,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPLREMENTARY: For a comprehensive descriptions of biases for ground truth and sorted units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination of biases: ['oversplit' 'poorly detected']\n"
     ]
    }
   ],
   "source": [
    "overmerging_matx_2 = agreem_mx_m\n",
    "det_thresh = 0.8\n",
    "chance = 0.1\n",
    "\n",
    "# create masks\n",
    "mask_above_det = overmerging_matx_2 >= det_thresh\n",
    "mask_below_chance = overmerging_matx_2 <= chance\n",
    "mask_in_between = np.logical_and(\n",
    "    overmerging_matx_2 < det_thresh, overmerging_matx_2 > chance\n",
    ")\n",
    "mask_entirely_missed = overmerging_matx_2 == 0\n",
    "\n",
    "# implement tree to classify ground truths\n",
    "# find ground truth (cols) with one mask_above_det=True and other mask_below_chance = True\n",
    "\n",
    "gt_classes = []\n",
    "df = pd.DataFrame(\n",
    "    data=np.array([[0], [0], [0], [0]]).T,\n",
    "    columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    ")\n",
    "\n",
    "# loop over ground truth units\n",
    "for gt_i in range(overmerging_matx_2.shape[1]):\n",
    "\n",
    "    # check if that ground truth has a single sorted unit\n",
    "    # with an agreement score above detection threshold\n",
    "    if any(mask_above_det.iloc[:, gt_i]):\n",
    "\n",
    "        # get this ground truth detection stata\n",
    "        is_detected = mask_above_det.iloc[:, gt_i]\n",
    "        detected_loc = np.where(is_detected)[0]\n",
    "        detected_id = is_detected.index[detected_loc]\n",
    "\n",
    "        # get other correlated unit ids\n",
    "        other_sorted_unit_ids = is_detected.drop(index=detected_id).index\n",
    "\n",
    "        # get this ground truth below chance stata\n",
    "        is_below_chance = mask_below_chance.iloc[:, gt_i]\n",
    "\n",
    "        # check if all other sorted units are below chance\n",
    "        if all(is_below_chance.loc[other_sorted_unit_ids]):\n",
    "            gt_classes.append(\"well detected\")\n",
    "\n",
    "            # pair true and sorted units\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        [overmerging_matx_2.columns[gt_i]],\n",
    "                        [detected_id[0]],\n",
    "                        [\"well detected\"],\n",
    "                        [\"good\"],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "\n",
    "        # if another unit has an agreement score\n",
    "        # above chance level, it is: well detected + correlated unit\n",
    "        else:\n",
    "            gt_classes.append(\"well detected, correlated\")\n",
    "\n",
    "            # pair true and the well detected sorted unit\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        [overmerging_matx_2.columns[gt_i]],\n",
    "                        [detected_id[0]],\n",
    "                        [\"well detected, correlated\"],\n",
    "                        [\"good\"],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "\n",
    "            # pair true and the other redundant sorted unit\n",
    "            n_redundants = len(other_sorted_unit_ids.tolist())\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        n_redundants * [overmerging_matx_2.columns[gt_i]],\n",
    "                        other_sorted_unit_ids.tolist(),\n",
    "                        n_redundants * [\"poorly detected\"],\n",
    "                        n_redundants * [\"redundant\"],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "\n",
    "    # case where ground truth matches only one sorted unit\n",
    "    # with a score b/w detection and chance and\n",
    "    # other units below chance\n",
    "    # no scores are above detection\n",
    "    elif (sum(mask_in_between.iloc[:, gt_i]) == 1) and (\n",
    "        any(mask_above_det.iloc[:, gt_i]) == False\n",
    "    ):\n",
    "        gt_classes.append(\"poorly detected\")\n",
    "\n",
    "        # pair units\n",
    "        unit_id = overmerging_matx_2.index[\n",
    "            np.where(mask_in_between.iloc[:, gt_i] == 1)[0][0]\n",
    "        ]\n",
    "        df2 = pd.DataFrame(\n",
    "            data=np.array(\n",
    "                [\n",
    "                    [overmerging_matx_2.columns[gt_i]],\n",
    "                    [unit_id],\n",
    "                    [\"poorly detected\"],\n",
    "                    [\"poor unit\"],\n",
    "                ]\n",
    "            ).T,\n",
    "            columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "        )\n",
    "        df = pd.concat([df, df2])\n",
    "\n",
    "    # case a true unit is associated is a sorted unit with score\n",
    "    # between detection and chance that is associated with other\n",
    "    # true units with scores between detection and chances\n",
    "    elif sum(mask_in_between.iloc[:, gt_i]) > 1:\n",
    "        gt_classes.append(\"oversplit\")\n",
    "\n",
    "        # pair units\n",
    "        unit_ids = overmerging_matx_2.index[\n",
    "            np.where(mask_in_between.iloc[:, gt_i])[0].tolist()\n",
    "        ].tolist()\n",
    "        n_oversplitters = len(unit_ids)\n",
    "\n",
    "        df2 = pd.DataFrame(\n",
    "            data=np.array(\n",
    "                [\n",
    "                    n_oversplitters * [overmerging_matx_2.columns[gt_i]],\n",
    "                    unit_ids,\n",
    "                    n_oversplitters * [\"oversplit\"],\n",
    "                    n_oversplitters * [\"oversplitters\"],\n",
    "                ]\n",
    "            ).T,\n",
    "            columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "        )\n",
    "        df = pd.concat([df, df2])\n",
    "\n",
    "    # check that all sorted units have scores below\n",
    "    # chance\n",
    "    elif all(mask_below_chance.iloc[:, gt_i]):\n",
    "        if all(mask_entirely_missed.iloc[:, gt_i]):\n",
    "            gt_classes.append(\"missed\")\n",
    "\n",
    "            # pair units\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        [overmerging_matx_2.columns[gt_i]],\n",
    "                        [np.nan],\n",
    "                        [\"missed\"],\n",
    "                        [np.nan],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "        else:\n",
    "            gt_classes.append(\"below chance\")\n",
    "            unit_ids = overmerging_matx_2.index[\n",
    "                np.where(\n",
    "                    (overmerging_matx_2.iloc[:, gt_i] <= chance)\n",
    "                    * (overmerging_matx_2.iloc[:, gt_i] > 0)\n",
    "                )[0]\n",
    "            ].tolist()\n",
    "            n_below_chance = len(unit_ids)\n",
    "\n",
    "            df2 = pd.DataFrame(\n",
    "                data=np.array(\n",
    "                    [\n",
    "                        n_below_chance * [overmerging_matx_2.columns[gt_i]],\n",
    "                        unit_ids,\n",
    "                        n_below_chance * [\"below chance\"],\n",
    "                        n_below_chance * [\"below chance\"],\n",
    "                    ]\n",
    "                ).T,\n",
    "                columns=[\"ground truth\", \"sorted\", \"ground truth bias\", \"sorted bias\"],\n",
    "            )\n",
    "            df = pd.concat([df, df2])\n",
    "\n",
    "\n",
    "# Detect overmerged units and combinations -------------\n",
    "\n",
    "# if one of its sorted units with score between\n",
    "# detection and chance has also a score between\n",
    "# detection and chance with another true unit\n",
    "# the true unit is overmerged (with another true unit)\n",
    "true_units_loc = np.where(mask_in_between.sum(axis=0) >= 1)[0]\n",
    "true_units = mask_in_between.columns[true_units_loc]\n",
    "gt_overmerged = dict()\n",
    "\n",
    "for gt_i in range(len(true_units_loc)):\n",
    "    target_true_units_mx = mask_in_between.iloc[:, true_units_loc]\n",
    "    sorted_u = np.where(target_true_units_mx.iloc[:, gt_i])[0]\n",
    "\n",
    "    # check overmerged (that sorted unit merges other true units)\n",
    "    if any(mask_in_between.iloc[sorted_u, :].sum(axis=1) > 1):\n",
    "        overmerged_bool = mask_in_between.iloc[sorted_u, :].sum(axis=1) > 1\n",
    "        overmerging_sorted = overmerged_bool.index[\n",
    "            np.where(overmerged_bool)[0]\n",
    "        ].to_list()\n",
    "        gt_overmerged[true_units[gt_i]] = overmerging_sorted\n",
    "\n",
    "# what other biases do overmerged units have?\n",
    "all_true_units = overmerging_matx_2.columns\n",
    "gt_classes_df = pd.DataFrame(data=gt_classes, index=all_true_units.to_list())\n",
    "print(\"combination of biases:\", np.unique(gt_classes_df.loc[gt_overmerged.keys(), :]))\n",
    "\n",
    "# label combination of biases\n",
    "gt_classes_df.loc[gt_overmerged.keys(), :] = gt_classes_df.loc[\n",
    "    gt_overmerged.keys(), :\n",
    "].apply(lambda x: x + \", overmerged\")\n",
    "\n",
    "# poorly detected + overmerged units are poorly detected because overmerged so simply overmerged\n",
    "gt_classes_df[gt_classes_df == \"poorly detected, overmerged\"] = \"overmerged\"\n",
    "df = df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground truth</th>\n",
       "      <th>sorted</th>\n",
       "      <th>ground truth bias</th>\n",
       "      <th>sorted bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1527208</td>\n",
       "      <td>99</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1527208</td>\n",
       "      <td>117</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1527208</td>\n",
       "      <td>124</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1527208</td>\n",
       "      <td>164</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1527208</td>\n",
       "      <td>198</td>\n",
       "      <td>below chance</td>\n",
       "      <td>below chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3547327</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1509317</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514245</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2696195</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1725884</td>\n",
       "      <td>nan</td>\n",
       "      <td>missed</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24696 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ground truth sorted ground truth bias   sorted bias\n",
       "0       1527208     99      below chance  below chance\n",
       "1       1527208    117      below chance  below chance\n",
       "2       1527208    124      below chance  below chance\n",
       "3       1527208    164      below chance  below chance\n",
       "4       1527208    198      below chance  below chance\n",
       "..          ...    ...               ...           ...\n",
       "0       3547327    nan            missed           nan\n",
       "0       1509317    nan            missed           nan\n",
       "0       1514245    nan            missed           nan\n",
       "0       2696195    nan            missed           nan\n",
       "0       1725884    nan            missed           nan\n",
       "\n",
       "[24696 rows x 4 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A sorted unit can show several biases (with different ground truth units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['below chance', 'redundant', 'poor unit'], dtype=object)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 20\n",
    "\n",
    "sorted_ids = df[\"sorted\"].unique()\n",
    "df[df[\"sorted\"] == sorted_ids[ix]][\"sorted bias\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# references\n",
    "\n",
    "(1) https://neuronaldynamics.epfl.ch/online/Ch7.S2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_kilosort_silico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
