{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed up chance calculation for score matrix\n",
    "\n",
    "author: steeve.laquitaine@epfl.ch  \n",
    "last modified: 13-02-2024\n",
    "\n",
    "**Method**:\n",
    "\n",
    "* **delta_time (Î”ð‘¡)** = 1.3 ms: the time windows before and after the spike timestamp of a ground truth. When a the timestamp of a sorted unit falls within this time window, they coincide and the sorted timestamp is a hit.\n",
    "* **chance level score**: see paper\n",
    "* **dark (missed) units**: ground truth units with sorting accuracy below the chance agreement score (their best match with a sorted unit produce an agreement score below chance).\n",
    "* **false positive units**: units which timestamps never hit the timestamps of the ground truth units wihin 50 microns of the probe: they never fall withing the delta_time window.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Create or activate env `spikeinterf...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "2024-08-26 17:17:19,237 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-08-26 17:17:19,282 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2024-08-26 17:17:19,287 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-08-26 17:17:19,348 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2024-08-26 17:17:19,350 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-08-26 17:17:19,432 - root - utils.py - get_config - INFO - Reading experiment config. - done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import spikeinterface as si\n",
    "from spikeinterface import comparison\n",
    "import copy\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "proj_path = \"/gpfs/bbp.cscs.ch/project/proj85/home/laquitai/preprint_2023/\"\n",
    "os.chdir(proj_path)\n",
    "\n",
    "from src.nodes.postpro.cell_matching import get_SpikeInterface_matching_object\n",
    "from src.nodes.utils import get_config\n",
    "from src.nodes.postpro.feateng import (add_firing_rates)\n",
    "from src.nodes.analysis.failures import accuracy as acc\n",
    "from src.nodes.metrics.metrics import get_firing_rate\n",
    "\n",
    "# PARAMETERS\n",
    "REC_DURATION = 600 # 10 minutes recording\n",
    "DET = 0.8\n",
    "CHANCE_THRESH = 0.1\n",
    "\n",
    "#Â DATASETS\n",
    "\n",
    "# NPX\n",
    "# Synthetic\n",
    "cfg_nb, _ = get_config(\"buccino_2020\", \"2020\").values()\n",
    "GT_nb_10m = cfg_nb[\"sorting\"][\"simulation\"][\"ground_truth\"][\"10m\"][\"output\"]\n",
    "KS4_nb = cfg_nb[\"sorting\"][\"sorters\"][\"kilosort3\"][\"10m\"][\"output\"]\n",
    "REC_nb = cfg_nb[\"probe_wiring\"][\"full\"][\"output\"]\n",
    "\n",
    "# biophy spont\n",
    "cfg_ns, _ = get_config(\"silico_neuropixels\", \"concatenated\").values()\n",
    "KS4_ns = cfg_ns[\"sorting\"][\"sorters\"][\"kilosort3\"][\"output\"]\n",
    "GT_ns_10m = cfg_ns[\"sorting\"][\"simulation\"][\"ground_truth\"][\"10m\"][\"output\"]\n",
    "REC_ns = cfg_ns[\"probe_wiring\"][\"full\"][\"output\"]\n",
    "\n",
    "# biophy evoked\n",
    "cfg_ne, _ = get_config(\"silico_neuropixels\", \"stimulus\").values()\n",
    "KS4_ne = cfg_ne[\"sorting\"][\"sorters\"][\"kilosort3\"][\"output\"]\n",
    "GT_ne_10m = cfg_ne[\"sorting\"][\"simulation\"][\"ground_truth\"][\"10m\"][\"output\"]\n",
    "REC_ne = cfg_ne[\"probe_wiring\"][\"full\"][\"output\"]\n",
    "\n",
    "# FIGURE SETTINGS\n",
    "COLOR_VIVO = (0.7, 0.7, 0.7)\n",
    "COLOR_SILI = (0.84, 0.27, 0.2)\n",
    "COLOR_STIM = (0.6, 0.75, 0.1)\n",
    "BOX_ASPECT = 1                  # square fig\n",
    "FIG_SIZE = (1,1)\n",
    "plt.rcParams['figure.figsize'] = (2,1)\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 6\n",
    "plt.rcParams['lines.linewidth'] = 0.2\n",
    "plt.rcParams['axes.linewidth'] = 0.5\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['xtick.major.width'] = 0.3\n",
    "plt.rcParams['xtick.minor.size'] = 0.1\n",
    "plt.rcParams['xtick.major.size'] = 1.5\n",
    "plt.rcParams['ytick.major.size'] = 1.5\n",
    "plt.rcParams['ytick.major.width'] = 0.3\n",
    "legend_cfg = {\"frameon\": False, \"handletextpad\": 0.1}\n",
    "savefig_cfg = {\"transparent\":True}\n",
    "# print(plt.rcParams.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012999992676670962"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate chance score for a 1 Hz sorted unit (spikes/secs)\n",
    "fr_gt = 1\n",
    "fr_s = 1\n",
    "delta_time = 1.3  # in ms\n",
    "rec_dur = 600  # recording duration\n",
    "\n",
    "# calculate chance agreement score\n",
    "# - chance probability of hits\n",
    "# - chance score\n",
    "p_chance_hit = acc.get_p_chance_hit(1 / 1000, 1.3)\n",
    "chance_acc = acc.get_unit_chance_agreement_score(fr_gt, fr_s, 600, p_chance_hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sorted_unit_biases(agreem_mx, det):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        agreem_mx (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        (dict):\n",
    "        - \"match\" (pd.DataFrame): N ground truth unit indices, N best-match sorted units\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # note: with this approach (BEST matching approach), the same sorted unit can be paired with more than one true unit\n",
    "    # we only keep the pairings with highest agreement scores\n",
    "    # true-sorted unit pairing\n",
    "    pairing = agreem_mx.T.idxmax(axis=1)\n",
    "    pairing = pairing.to_frame()\n",
    "    pairing.columns = [\"sorted\"]\n",
    "\n",
    "    # add agreement score\n",
    "    accuracy = agreem_mx.T.max(axis=1)\n",
    "    pairing[\"accuracy\"] = accuracy\n",
    "\n",
    "    # check if the only sorted unit paired with this true unit\n",
    "    sorted_ids = agreem_mx.index\n",
    "\n",
    "    df = copy.copy(pairing.iloc[0, :].to_frame().T)\n",
    "    false_positives = []\n",
    "\n",
    "    # else keep the pairing with highest agreement score\n",
    "    # loop over all sorted single unit units\n",
    "    for ix in range(len(sorted_ids)):\n",
    "        # case the sorted unit was paired with a ground truth unit\n",
    "        if any(pairing[\"sorted\"] == sorted_ids[ix]):\n",
    "            sorted_pairings = pairing[pairing[\"sorted\"] == sorted_ids[ix]].sort_values(\n",
    "                by=\"accuracy\", ascending=False\n",
    "            )\n",
    "            # take max pairing (first row)\n",
    "            df = pd.concat([df, sorted_pairings.iloc[0, :].to_frame().T])\n",
    "        else:\n",
    "            # case the sorted unit was paired with none of the ground truth units\n",
    "            false_positives.append(sorted_ids[ix])\n",
    "\n",
    "    df = df[1:]\n",
    "    df[\"sorted\"] = df[\"sorted\"].astype(int)\n",
    "\n",
    "    # count biases\n",
    "    n_good = sum(df[\"accuracy\"] >= det)\n",
    "    n_poor = sum((df[\"accuracy\"] >= CHANCE_THRESH) & (df[\"accuracy\"] < det))\n",
    "    n_below_chance = sum((df[\"accuracy\"] > 0) & (df[\"accuracy\"] < CHANCE_THRESH))\n",
    "    n_false_pos = len(false_positives)\n",
    "\n",
    "    # sanity check\n",
    "    # assert n_good + n_poor + n_below_chance + n_false_pos == len(\n",
    "    #     sorted_ids\n",
    "    # ), \"They must match\"\n",
    "    return {\n",
    "        \"n_good\": n_good,\n",
    "        \"n_poor\": n_poor,\n",
    "        \"n_below_chance\": n_below_chance,\n",
    "        \"n_false_pos\": n_false_pos,\n",
    "        \"match\": pairing,\n",
    "    }\n",
    "\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Some scores can be 0, if they were the best found\n",
    "\n",
    "    Args:\n",
    "        scores (pd.DataFrame): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # the same sorted unit can be paired with more than one true unit\n",
    "    # we keep the pairings with highest agreement scores\n",
    "    # true-sorted unit pairing\n",
    "    match = scores.idxmax(axis=0)\n",
    "    match = match.to_frame()\n",
    "    match.columns = [\"sorted\"]\n",
    "    match.index.name = \"true\"\n",
    "\n",
    "    # record agreement score\n",
    "    match[\"accuracy\"] = scores.max(axis=0)\n",
    "    return match\n",
    "\n",
    "\n",
    "def count_match(match: pd.DataFrame, sorted: int):\n",
    "    \"\"\"count the number of true units\n",
    "    one sorted unit matches\n",
    "\n",
    "    Args:\n",
    "        match (pd.DataFrame):\n",
    "        - index: true units id\n",
    "        - columns:\n",
    "        - - \"sorted\": best-match sorted unit id\n",
    "        - - \"accuracy\": best-match agreement score\n",
    "        (true unit sorting accuracy)\n",
    "    \"\"\"\n",
    "    return sum(match[\"sorted\"] == sorted)\n",
    "\n",
    "\n",
    "def get_best_matched_true_unit(match, s_id):\n",
    "    \"\"\"get true unit matchs\n",
    "\n",
    "    Args:\n",
    "        match (_type_): _description_\n",
    "        s_id (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    units = match[match[\"sorted\"] == s_id].index.values\n",
    "    if len(units) == 1:\n",
    "        units = units[0]\n",
    "    return units\n",
    "\n",
    "\n",
    "def get_all_matched_true_unit(s_id, scores):\n",
    "    \"\"\"get all true unit matchs\n",
    "\n",
    "    Args:\n",
    "        match (_type_): _description_\n",
    "        s_id (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    return np.array(scores.columns[scores.loc[s_id, :] > 0])\n",
    "\n",
    "\n",
    "def get_chance_score(gt_id, s_id, Sorting_ns, SortingTrue_ns, duration, delta_time):\n",
    "    fr_s = get_firing_rate(s_id, Sorting_ns, duration)\n",
    "    fr_gt = get_firing_rate(gt_id, SortingTrue_ns, duration)\n",
    "    p_chance_hit = acc.get_p_chance_hit(min(fr_gt, fr_s) / 1000, delta_time)\n",
    "    return acc.get_unit_chance_agreement_score(fr_gt, fr_s, duration, p_chance_hit)\n",
    "\n",
    "\n",
    "def get_score(scores, s_id, gt_id):\n",
    "    try:\n",
    "        return scores.loc[s_id, gt_id]\n",
    "    except:\n",
    "        from ipdb import set_trace\n",
    "\n",
    "        set_trace()\n",
    "\n",
    "\n",
    "def is_score_at_chance(\n",
    "    scores, s_id, gt_id, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "):\n",
    "    score = get_score(scores, s_id, gt_id)\n",
    "    chance = get_chance_score(\n",
    "        gt_id, s_id, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "    )\n",
    "    return score <= chance\n",
    "\n",
    "\n",
    "def are_all_scores_at_chance(\n",
    "    s_id, gt_id, scores, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "):\n",
    "    \"\"\"check whether a sorted unit agreement scores with the many\n",
    "    ground truth units it matches are all at chance (it is a false\n",
    "    positive)\n",
    "\n",
    "    Args:\n",
    "        s_id (_type_): sorted unit id\n",
    "        gt_id (_type_): ground truth unit id\n",
    "        scores (_type_): _description_\n",
    "        match (_type_): _description_\n",
    "        Sorting_ns (_type_): _description_\n",
    "        SortingTrue_ns (_type_): _description_\n",
    "        duration (_type_): _description_\n",
    "        delta_time (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # make an 1D array\n",
    "    gt_id = make_1darray(gt_id)\n",
    "\n",
    "    # start counting scores below chance\n",
    "    d = 0\n",
    "    for _, g_i in enumerate(gt_id):\n",
    "        d += is_score_at_chance(\n",
    "            scores, s_id, g_i, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "        )\n",
    "    return d == len(gt_id)\n",
    "\n",
    "\n",
    "def make_1darray(gt_id):\n",
    "    if isinstance(gt_id, np.ndarray):\n",
    "        return gt_id\n",
    "    else:\n",
    "        return np.array([gt_id])\n",
    "\n",
    "\n",
    "def is_oversplitter_1(\n",
    "    scores, match, s_id, gt_id, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "):\n",
    "    \"\"\"check when sorted unit matches only one ground truth unit\n",
    "\n",
    "    Args:\n",
    "        scores (_type_): _description_\n",
    "        match (_type_): _description_\n",
    "        s_id (_type_): _description_\n",
    "        gt_id (_type_): _description_\n",
    "        Sorting_ns (_type_): _description_\n",
    "        SortingTrue_ns (_type_): _description_\n",
    "        duration (_type_): _description_\n",
    "        delta_time (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # find all sorted units that match this ground truth unit\n",
    "    sorteds = match[match.index == gt_id][\"sorted\"].values.tolist()\n",
    "\n",
    "    d = 0\n",
    "    # loop over sorted unit match\n",
    "    for _, s_i in enumerate(sorteds):\n",
    "\n",
    "        # check for other sorted unit match\n",
    "        # than the target match s_id\n",
    "        if not s_i == s_id:\n",
    "            d += is_score_at_chance(\n",
    "                scores,\n",
    "                s_i,\n",
    "                gt_id,\n",
    "                Sorting_ns,\n",
    "                SortingTrue_ns,\n",
    "                duration,\n",
    "                delta_time,\n",
    "            )\n",
    "    return d > 0\n",
    "\n",
    "\n",
    "def is_oversplitter_2(\n",
    "    s_id, gt_id, scores, match, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "):\n",
    "    \"\"\"check when sorted unit matches many ground truth units\n",
    "\n",
    "    Args:\n",
    "        s_id (_type_): _description_\n",
    "        scores (_type_): _description_\n",
    "        match (_type_): _description_\n",
    "        Sorting_ns (_type_): _description_\n",
    "        SortingTrue_ns (_type_): _description_\n",
    "        duration (_type_): _description_\n",
    "        delta_time (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    d = 0\n",
    "    for _, g_i in enumerate(gt_id):\n",
    "        d += is_oversplitter_1(\n",
    "            scores,\n",
    "            match,\n",
    "            s_id,\n",
    "            g_i,\n",
    "            Sorting_ns,\n",
    "            SortingTrue_ns,\n",
    "            duration,\n",
    "            delta_time,\n",
    "        )\n",
    "    return d > 0\n",
    "\n",
    "\n",
    "def is_poor(det, scores, gt_id, s_id, Sorting_ns, SortingTrue_ns, duration, delta_time):\n",
    "    \"\"\"is poor (score between chance and threshold for \"good\" (80%))\n",
    "\n",
    "    Args:\n",
    "        scores (_type_): _description_\n",
    "        gt_id (_type_): _description_\n",
    "        s_id (_type_): _description_\n",
    "        Sorting_ns (_type_): _description_\n",
    "        SortingTrue_ns (_type_): _description_\n",
    "        duration (_type_): _description_\n",
    "        delta_time (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    chance = get_chance_score(\n",
    "        gt_id, s_id, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "    )\n",
    "    score = get_score(scores, s_id, gt_id)\n",
    "    return (score > chance) & (score < det)\n",
    "\n",
    "\n",
    "def is_poor_2(\n",
    "    s_id, gt_id, scores, Sorting_ns, SortingTrue_ns, duration, delta_time, det\n",
    "):\n",
    "    \"\"\"is poor when sorted unit matches many ground truth units\n",
    "    (all its scores with the ground truth are below the \"good\" threshold\n",
    "    and it has at least one score with a ground truth above chance\n",
    "\n",
    "    Args:\n",
    "        s_id (_type_): _description_\n",
    "        match (_type_): _description_\n",
    "        Sorting_ns (_type_): _description_\n",
    "        SortingTrue_ns (_type_): _description_\n",
    "        duration (_type_): _description_\n",
    "        delta_time (_type_): _description_\n",
    "        det (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    chance_all = []\n",
    "    score_all = []\n",
    "\n",
    "    for _, g_i in enumerate(gt_id):\n",
    "        chance_all.append(\n",
    "            get_chance_score(\n",
    "                g_i, s_id, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "            )\n",
    "        )\n",
    "        score_all.append(get_score(scores, s_id, g_i))\n",
    "\n",
    "    # all scores are below DET\n",
    "    test_1 = all(np.array(score_all) < det)\n",
    "\n",
    "    # at least one score is above chance\n",
    "    test_2 = any(np.array(score_all) > np.array(chance_all))\n",
    "    return test_1 & test_2\n",
    "\n",
    "\n",
    "def is_overmerger_2(\n",
    "    s_id, gt_id, scores, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "):\n",
    "    \"\"\"is an overmerger: the sorted unit matches at least two ground\n",
    "    truths with above chance scores\n",
    "\n",
    "    Args:\n",
    "        s_id (_type_): _description_\n",
    "        match (_type_): _description_\n",
    "        Sorting_ns (_type_): _description_\n",
    "        SortingTrue_ns (_type_): _description_\n",
    "        duration (_type_): _description_\n",
    "        delta_time (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # get there scores\n",
    "    chance_all = []\n",
    "    score_all = []\n",
    "\n",
    "    for _, g_i in enumerate(gt_id):\n",
    "        # get chance scores\n",
    "        chance_all.append(\n",
    "            get_chance_score(\n",
    "                g_i, s_id, Sorting_ns, SortingTrue_ns, duration, delta_time\n",
    "            )\n",
    "        )\n",
    "        # get scores\n",
    "        score_all.append(get_score(scores, s_id, g_i))\n",
    "    return sum(np.array(score_all) > np.array(chance_all)) > 1\n",
    "\n",
    "\n",
    "def is_good_2(s_id, gt_id, scores):\n",
    "    \"\"\"is sorted unit good: it matches one ground truth with 80% and no\n",
    "    other ground truth with\n",
    "\n",
    "    Args:\n",
    "        s_id (_type_): _description_\n",
    "        scores (_type_): _description_\n",
    "        match (_type_): _description_\n",
    "        Sorting_ns (_type_): _description_\n",
    "        SortingTrue_ns (_type_): _description_\n",
    "        duration (_type_): _description_\n",
    "        delta_time (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    score_all = []\n",
    "    for _, g_i in enumerate(gt_id):\n",
    "        score_all.append(get_score(scores, s_id, g_i))\n",
    "    return any(np.array(score_all) >= DET)\n",
    "\n",
    "\n",
    "def set_df(df, sorted, true, quality, score):\n",
    "    df.loc[sorted, \"sorted\"] = sorted\n",
    "    df.loc[sorted, \"true\"] = true\n",
    "    df.loc[sorted, \"score\"] = score\n",
    "    qual = df.loc[sorted, \"quality\"]\n",
    "    # record quality if nan (empty)\n",
    "    # else append new quality\n",
    "    if isinstance(qual, str):\n",
    "        df.loc[sorted, \"quality\"] += quality\n",
    "    else:\n",
    "        df.loc[sorted, \"quality\"] = quality\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_scores(\n",
    "    SortingTrue,\n",
    "    Sorting,\n",
    "    delta_time: float,\n",
    "):\n",
    "    comp = comparison.compare_sorter_to_ground_truth(\n",
    "        SortingTrue,\n",
    "        Sorting,\n",
    "        exhaustive_gt=True,\n",
    "        delta_time=delta_time,\n",
    "    )\n",
    "    # return comp.agreement_scores.max(axis=1).sort_values(ascending=False).values\n",
    "    return comp.agreement_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/project/proj85/scratch/laquitai/4_preprint_2023/envs/spikinterf0_100_5/lib/python3.9/site-packages/spikeinterface/core/base.py:1079: UserWarning: Versions are not the same. This might lead to compatibility errors. Using spikeinterface==0.96.1 is recommended\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load SortingExtractors\n",
    "SortingTrue_ns = si.load_extractor(GT_ns_10m)\n",
    "Sorting_ns = si.load_extractor(KS4_ns)\n",
    "Rec_ns = si.load_extractor(REC_ns)\n",
    "\n",
    "# get scores (N sorted units rows x N true units columns)\n",
    "scores_ns = get_scores(SortingTrue_ns, Sorting_ns, 1.3)\n",
    "scores_ns = scores_ns.T\n",
    "\n",
    "# curate (get single-unit only)\n",
    "scores_ns = scores_ns.loc[\n",
    "    Sorting_ns.unit_ids[Sorting_ns.get_property(\"KSLabel\") == \"good\"], :\n",
    "]\n",
    "\n",
    "scores_by_exp = [scores_ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute sorting quality\n",
    "out = classify_sorted_unit_biases(scores_ns, DET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method**:\n",
    "\n",
    "* For each true unit we find its best-match sorted unit\n",
    "* calculate chance level for all units is pairs is consuming-\n",
    "* all NaN scores are sorted units' will many ground truth matches.\n",
    "* 15 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12165</th>\n",
       "      <th>16652</th>\n",
       "      <th>18371</th>\n",
       "      <th>19690</th>\n",
       "      <th>21040</th>\n",
       "      <th>24768</th>\n",
       "      <th>29248</th>\n",
       "      <th>30168</th>\n",
       "      <th>32331</th>\n",
       "      <th>37423</th>\n",
       "      <th>...</th>\n",
       "      <th>4213917</th>\n",
       "      <th>4215563</th>\n",
       "      <th>4216128</th>\n",
       "      <th>4217493</th>\n",
       "      <th>4221920</th>\n",
       "      <th>4223302</th>\n",
       "      <th>4225319</th>\n",
       "      <th>4228700</th>\n",
       "      <th>4229218</th>\n",
       "      <th>4229506</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows Ã— 1388 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       12165    16652     18371    19690    21040    24768    29248    \\\n",
       "143   0.000000      0.0  0.000000      0.0      0.0      0.0      0.0   \n",
       "201   0.000000      0.0  0.000000      0.0      0.0      0.0      0.0   \n",
       "208   0.000000      0.0  0.000000      0.0      0.0      0.0      0.0   \n",
       "215   0.000000      0.0  0.000000      0.0      0.0      0.0      0.0   \n",
       "217   0.000000      0.0  0.000000      0.0      0.0      0.0      0.0   \n",
       "...        ...      ...       ...      ...      ...      ...      ...   \n",
       "1596  0.000000      0.0  0.000000      0.0      0.0      0.0      0.0   \n",
       "1612  0.000000      0.0  0.000000      0.0      0.0      0.0      0.0   \n",
       "1613  0.000000      0.0  0.000000      0.0      0.0      0.0      0.0   \n",
       "1632  0.000109      0.0  0.000109      0.0      0.0      0.0      0.0   \n",
       "1693  0.000000      0.0  0.000000      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       30168    32331    37423    ...   4213917   4215563   4216128  4217493  \\\n",
       "143   0.000000      0.0      0.0  ...  0.000000  0.000000  0.000000      0.0   \n",
       "201   0.000000      0.0      0.0  ...  0.001315  0.000804  0.000649      0.0   \n",
       "208   0.000000      0.0      0.0  ...  0.001019  0.002314  0.000000      0.0   \n",
       "215   0.000000      0.0      0.0  ...  0.001202  0.000451  0.001184      0.0   \n",
       "217   0.000000      0.0      0.0  ...  0.000622  0.000282  0.000000      0.0   \n",
       "...        ...      ...      ...  ...       ...       ...       ...      ...   \n",
       "1596  0.000000      0.0      0.0  ...  0.000000  0.000000  0.000000      0.0   \n",
       "1612  0.000000      0.0      0.0  ...  0.000964  0.001316  0.001433      0.0   \n",
       "1613  0.000000      0.0      0.0  ...  0.002236  0.000537  0.000000      0.0   \n",
       "1632  0.000109      0.0      0.0  ...  0.001555  0.002293  0.001065      0.0   \n",
       "1693  0.000000      0.0      0.0  ...  0.000751  0.000000  0.000000      0.0   \n",
       "\n",
       "       4221920  4223302  4225319   4228700  4229218   4229506  \n",
       "143   0.000000      0.0      0.0  0.000000      0.0  0.001927  \n",
       "201   0.001650      0.0      0.0  0.001612      0.0  0.000878  \n",
       "208   0.000391      0.0      0.0  0.000000      0.0  0.000000  \n",
       "215   0.000970      0.0      0.0  0.000391      0.0  0.000000  \n",
       "217   0.000453      0.0      0.0  0.000599      0.0  0.002375  \n",
       "...        ...      ...      ...       ...      ...       ...  \n",
       "1596  0.000000      0.0      0.0  0.000000      0.0  0.000000  \n",
       "1612  0.000842      0.0      0.0  0.001188      0.0  0.000590  \n",
       "1613  0.001676      0.0      0.0  0.000000      0.0  0.000000  \n",
       "1632  0.001194      0.0      0.0  0.001063      0.0  0.000525  \n",
       "1693  0.000000      0.0      0.0  0.000000      0.0  0.000000  \n",
       "\n",
       "[335 rows x 1388 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = scores_ns\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1388 [1:01:48<162:45:51, 424.91s/it]"
     ]
    }
   ],
   "source": [
    "from scipy.stats import poisson\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "def get_p_chance_hit(fr: float, delta_time: float):\n",
    "    \"\"\"derive the chance probability of hits\n",
    "    (coincidences between two independent sorted and\n",
    "    ground truth unit spike trains)\n",
    "\n",
    "    We should use the firing rate of the less firing\n",
    "    of the two. It determines the expected maximum\n",
    "    possible number of coincidences.\n",
    "\n",
    "    Args:\n",
    "        fr (float): firing rate in spikes/ms\n",
    "        delta_time (float): SpikeInterface delta_time interval in ms\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    k = 0  # we want the probability of k=0 coincidences\n",
    "    interval_ms = 2 * delta_time  # time interval in ms\n",
    "    n_sp = interval_ms * fr  # expected nb of coincidences\n",
    "    return 1.0 - poisson.pmf(k=k, mu=n_sp)\n",
    "\n",
    "\n",
    "def get_unit_chance_agreement_score(\n",
    "    fr_gt: float, fr_s: float, rec_dur: float, p_chance_hit: float\n",
    "):\n",
    "    \"\"\"get unit chance scorey\n",
    "\n",
    "    The chance scorey metrics should change with the ground truth firing rate.\n",
    "    It is not the case with the current calculation.\n",
    "    Intuition: the more a ground truth unit spikes within the duration of recording (say 600 secs),\n",
    "    the more spikes will be missed when compared a sorting unit of a fixed firing rate.\n",
    "    The increasing number of misses should decrease the value of the chance score metrics,\n",
    "    which is currently not the case.\n",
    "\n",
    "    Args:\n",
    "        fr_gt (float): ground truth firing rate (spikes/secs)\n",
    "        fr_s (float): sorted unit firing rate (spikes/secs)\n",
    "        p_chance_hit (float): chance probability of hits\n",
    "        rec_dur (float): recording duration\n",
    "    \"\"\"\n",
    "    # nb of spikes\n",
    "    n_gt = fr_gt * rec_dur\n",
    "    n_s = fr_s * rec_dur\n",
    "\n",
    "    # nb of hits, false positives, misses\n",
    "    # - the smallers spike train min(n_gt, n_s) determines\n",
    "    # the maximum possible number of hits\n",
    "    n_h = p_chance_hit * min(n_gt, n_s)\n",
    "    n_fp = n_s - n_h\n",
    "    n_m = n_gt - n_h\n",
    "    return n_h / (n_h + n_m + n_fp)\n",
    "\n",
    "\n",
    "def get_chance_score(gt_id, s_id, Sorting_ns, SortingTrue_ns, duration, delta_time):\n",
    "    fr_s = get_firing_rate(s_id, Sorting_ns, duration)\n",
    "    fr_gt = get_firing_rate(gt_id, SortingTrue_ns, duration)\n",
    "    p_chance_hit = get_p_chance_hit(min(fr_gt, fr_s) / 1000, delta_time)\n",
    "    return get_unit_chance_agreement_score(fr_gt, fr_s, duration, p_chance_hit)\n",
    "\n",
    "\n",
    "def get_firing_rate(unit_id: int, Sorting, rec_duration: float):\n",
    "    \"\"\"get a unit's firing rate\n",
    "\n",
    "    Returns:\n",
    "        (float): firing rate in spikes/secs\n",
    "    \"\"\"\n",
    "    n_spikes = Sorting.count_num_spikes_per_unit()[unit_id]\n",
    "    return n_spikes / rec_duration\n",
    "\n",
    "\n",
    "# warning: all get_chance_score's underlying functions must be in the same module\n",
    "chance_df = Parallel(n_jobs=-1)(\n",
    "    delayed(get_chance_score)(i, j, Sorting_ns, SortingTrue_ns, 600, delta_time)\n",
    "    for _, i in enumerate(tqdm(scores.columns))\n",
    "    for j in scores.index\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_kilosort_silico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
