{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert spike timepoints index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 11:57:35,607 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2023-12-01 11:57:35,639 - root - utils.py - get_config - INFO - Reading experiment config. - done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spikeinterface as si\n",
    "\n",
    "# move to project path\n",
    "PROJ_PATH = \"/gpfs/bbp.cscs.ch/project/proj68/home/laquitai/spikebias/\"\n",
    "os.chdir(PROJ_PATH)\n",
    "\n",
    "from src.nodes.utils import get_config\n",
    "from src.nodes.truth.silico import ground_truth\n",
    "\n",
    "EXPERIMENT = \"silico_horvath\"\n",
    "RUN = \"concatenated/probe_2\"\n",
    "data_conf, param_conf = get_config(EXPERIMENT, RUN).values()\n",
    "\n",
    "gt = data_conf[\"sorting\"][\"simulation\"][\"ground_truth\"][\"output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- index is in milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get read paths\n",
    "SPIKE_FILE_PATH = data_conf[\"dataeng\"][\"campaign\"][\"output\"][\"spike_file_path\"]\n",
    "LFP_FILE_PATH = data_conf[\"dataeng\"][\"campaign\"][\"output\"][\"trace_file_path\"]\n",
    "\n",
    "# get spikes and lfp\n",
    "spike = pd.read_pickle(SPIKE_FILE_PATH)\n",
    "lfp = pd.read_pickle(LFP_FILE_PATH)\n",
    "truth = si.load_extractor(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes ...\n",
    "\n",
    "# carefully deal with numerical precision issues\n",
    "SPIKE_SAMP_FREQ = 40000\n",
    "TRACE_SAMP_FREQ = 20000\n",
    "SPIKE_SFREQ_MS = SPIKE_SAMP_FREQ / 1000\n",
    "TRACE_SFREQ_MS = TRACE_SAMP_FREQ / 1000\n",
    "\n",
    "# get number of timepoints on spike index reference\n",
    "spike_npoint_for_40KHz = spike.index.values * SPIKE_SFREQ_MS\n",
    "\n",
    "# get number of timepoints on trace index reference\n",
    "conv_factor = TRACE_SFREQ_MS / SPIKE_SFREQ_MS\n",
    "spike_tpoints_for_20KHz = (spike_npoint_for_40KHz * conv_factor).astype(int)\n",
    "\n",
    "# narrow the search space for each spike\n",
    "spike_loc = []\n",
    "for s_i, spike_ms_i in enumerate(spike.index):\n",
    "    # define narrower search window\n",
    "    start_wind = spike_tpoints_for_20KHz[s_i] - 30\n",
    "    end_wind = spike_tpoints_for_20KHz[s_i] + 30\n",
    "\n",
    "    # for the last spike,  end window at lfp's last timepoint\n",
    "    if s_i == spike.index.shape[0]:\n",
    "        end_wind = lfp.shape[0]\n",
    "    search_window = np.arange(start_wind, end_wind, 1)\n",
    "\n",
    "    # append spike timepoints\n",
    "    loc_in_window = np.abs(lfp.index[search_window] - spike_ms_i).argmin()\n",
    "    spike_loc.append(start_wind + loc_in_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23519946"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(end_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit testing\n",
    "np.array_equal(np.array(spike_loc), truth.get_all_spike_trains()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implemented as module in src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/project/proj68/scratch/laquitai/3_sfn_2023/envs/npx_10m_384ch_unit_classes/lib/python3.9/site-packages/pandas/core/indexes/multi.py:643: DeprecationWarning: `cumproduct` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `cumprod` instead.\n",
      "  codes = cartesian_product(codes)\n",
      "/gpfs/bbp.cscs.ch/project/proj68/scratch/laquitai/3_sfn_2023/envs/npx_10m_384ch_unit_classes/lib/python3.9/site-packages/pandas/core/reshape/util.py:60: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  return [\n",
      "/gpfs/bbp.cscs.ch/project/proj68/scratch/laquitai/3_sfn_2023/envs/npx_10m_384ch_unit_classes/lib/python3.9/site-packages/pandas/core/reshape/util.py:60: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  return [\n",
      "/gpfs/bbp.cscs.ch/project/proj68/scratch/laquitai/3_sfn_2023/envs/npx_10m_384ch_unit_classes/lib/python3.9/site-packages/pandas/core/indexes/multi.py:643: DeprecationWarning: `cumproduct` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `cumprod` instead.\n",
      "  codes = cartesian_product(codes)\n",
      "/gpfs/bbp.cscs.ch/project/proj68/scratch/laquitai/3_sfn_2023/envs/npx_10m_384ch_unit_classes/lib/python3.9/site-packages/pandas/core/reshape/util.py:60: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  return [\n",
      "/gpfs/bbp.cscs.ch/project/proj68/scratch/laquitai/3_sfn_2023/envs/npx_10m_384ch_unit_classes/lib/python3.9/site-packages/pandas/core/reshape/util.py:60: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  return [\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-30 19:10:08,480 - root - ground_truth.py - create_sorting_object - INFO - Creating SpikeInterface's SortingTrue extractor\n"
     ]
    }
   ],
   "source": [
    "from src.nodes.load import load_campaign_params\n",
    "\n",
    "simulation = load_campaign_params(data_conf)\n",
    "truth = ground_truth.load_spike_fast(simulation, data_conf, param_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit testing\n",
    "np.array_equal(np.array(spike_loc), truth.get_all_spike_trains()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npx_10m_384ch_unit_classes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
