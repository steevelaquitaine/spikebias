{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model (FLR-metrics)\n",
    "\n",
    "\n",
    "* fractional logistic regression -> predict scores (R2, goodness-of-fit, metric weights)\n",
    "* logistic regression -> isolate high-quality units (R2, goodness-of-fit,)\n",
    "\n",
    "* simplest model: logistic regression on quality metrics (reference to literature)\n",
    "\n",
    "* we can increase the number of units by adding all non-good units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "2024-09-19 16:29:39,282 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-09-19 16:29:39,450 - root - utils.py - get_config - INFO - Reading experiment config. - done\n",
      "2024-09-19 16:29:39,469 - root - utils.py - get_config - INFO - Reading experiment config.\n",
      "2024-09-19 16:29:39,618 - root - utils.py - get_config - INFO - Reading experiment config. - done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import spikeinterface as si\n",
    "import spikeinterface.core.template_tools as ttools\n",
    "from spikeinterface import comparison\n",
    "import pandas as pd\n",
    "from cebra import CEBRA\n",
    "import cebra\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import cebra.models\n",
    "import pickle\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# set project path\n",
    "proj_path = \"/gpfs/bbp.cscs.ch/project/proj85/home/laquitai/spikebias/\"\n",
    "os.chdir(proj_path)\n",
    "\n",
    "from src.nodes.utils import get_config\n",
    "from src.nodes import utils\n",
    "from src.nodes.metrics.quality import get_scores\n",
    "\n",
    "# npx spont. biophy.\n",
    "cfg_ns, _ = get_config(\"silico_neuropixels\", \"concatenated\").values()\n",
    "KS4_ns_10m = cfg_ns[\"sorting\"][\"sorters\"][\"kilosort4\"][\"10m\"][\n",
    "    \"output\"\n",
    "]  # sorting with KS4\n",
    "GT_ns_10m = cfg_ns[\"sorting\"][\"simulation\"][\"ground_truth\"][\"10m\"][\"output\"] # KS4 sorting\n",
    "STUDY_ns = cfg_ns[\"postprocessing\"][\"waveform\"][\"sorted\"][\"study\"][\"kilosort4\"][\n",
    "    \"10m\"\n",
    "]  # WaveformExtractor\n",
    "STUDY_ns_su = '/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/0_silico/neuropixels/concatenated_campaigns/postpro/realism/spike/sorted/study_ks4_10m_single_units'\n",
    "\n",
    "# npx evoked biophy.\n",
    "cfg_ne, _ = get_config(\"silico_neuropixels\", \"stimulus\").values()\n",
    "KS4_ne_10m = cfg_ne[\"sorting\"][\"sorters\"][\"kilosort4\"][\"10m\"][\"output\"]\n",
    "GT_ne_10m = cfg_ne[\"sorting\"][\"simulation\"][\"ground_truth\"][\"10m\"][\"output\"]\n",
    "STUDY_ne = cfg_ne[\"postprocessing\"][\"waveform\"][\"sorted\"][\"study\"][\"kilosort4\"][\n",
    "    \"10m\"\n",
    "]  # WaveformExtractor\n",
    "STUDY_ne_su = '/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/postprocessing/biophy/4_spikesorting_stimulus_test_neuropixels_8-1-24__8slc_80f_360r_50t_200ms_1_smallest_fiber_gids/sorted/study_ks4_10m_single_units'\n",
    "\n",
    "\n",
    "# PATHS\n",
    "\n",
    "# pre-computed sorted unit quality\n",
    "quality_path = \"/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/analysis/sorting_quality/sorting_quality.csv\"\n",
    "\n",
    "# model save path\n",
    "error_path = \"/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/analysis/sorting_quality/models/cebra/sf_40Khz/error_path_s2s\"\n",
    "\n",
    "# axes\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 6  # 5-7 with Nature neuroscience as reference\n",
    "plt.rcParams[\"lines.linewidth\"] = 0.5 # typically between 0.5 and 1\n",
    "plt.rcParams[\"axes.linewidth\"] = 0.5 #1\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"xtick.major.width\"] = 0.5 #0.8 #* 1.3\n",
    "plt.rcParams[\"xtick.minor.width\"] = 0.5 #0.8 #* 1.3\n",
    "plt.rcParams[\"ytick.major.width\"] = 0.5 #0.8 #* 1.3\n",
    "plt.rcParams[\"ytick.minor.width\"] = 0.5 #0.8 #* 1.3\n",
    "plt.rcParams[\"xtick.major.size\"] = 3.5 * 1.1\n",
    "plt.rcParams[\"xtick.minor.size\"] = 2 * 1.1\n",
    "plt.rcParams[\"ytick.major.size\"] = 3.5 * 1.1\n",
    "plt.rcParams[\"ytick.minor.size\"] = 2 * 1.1\n",
    "# legend\n",
    "legend_cfg = {\"frameon\": False, \"handletextpad\": 0.5}\n",
    "tight_layout_cfg = {\"pad\": 0.001}\n",
    "LG_FRAMEON = False              # no legend frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDNN VERSION: 90100\n",
      "__Number CUDA Devices: 4\n",
      "__CUDA Device Name: Tesla V100-SXM2-16GB\n",
      "__CUDA Device Total Memory [GB]: 16.935419904\n"
     ]
    }
   ],
   "source": [
    "# check for GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print(\"__CUDNN VERSION:\", torch.backends.cudnn.version())\n",
    "    print(\"__Number CUDA Devices:\", torch.cuda.device_count())\n",
    "    print(\"__CUDA Device Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\n",
    "        \"__CUDA Device Total Memory [GB]:\",\n",
    "        torch.cuda.get_device_properties(0).total_memory / 1e9,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_good_sorted_unit_ids(\n",
    "    quality, quality_path: str, sorter: str, exp: str, layer: str, fltd_unit: list\n",
    "):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        quality (_type_): _description_\n",
    "        quality_path (str): _description_\n",
    "        sorter (str): _description_\n",
    "        exp (str): _description_\n",
    "        layer (str): _description_\n",
    "        fltd_unit (list): _description_\n",
    "\n",
    "    Returns:\n",
    "        np.array(int): filtered sorted unit ids\n",
    "    \"\"\"\n",
    "    # load quality results\n",
    "    unit_quality = pd.read_csv(quality_path)\n",
    "\n",
    "    # select a sorted unit and conditions\n",
    "    df = unit_quality[\n",
    "        (unit_quality[\"quality\"].str.contains(quality))\n",
    "        & (unit_quality[\"experiment\"] == exp)\n",
    "        & (unit_quality[\"sorter\"] == sorter)\n",
    "        & (unit_quality[\"layer\"] == layer)\n",
    "    ]\n",
    "    # filter units based on previous conditions\n",
    "    df = df[df[\"sorted\"].isin(fltd_unit)]\n",
    "    return df[\"sorted\"].values.astype(int)\n",
    "\n",
    "\n",
    "def get_poor_sorted_unit_ids(\n",
    "    quality, quality_path: str, sorter: str, exp: str, layer: str, fltd_unit: list\n",
    "):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        quality (_type_): _description_\n",
    "        quality_path (str): _description_\n",
    "        sorter (str): _description_\n",
    "        exp (str): _description_\n",
    "        layer (str): _description_\n",
    "        fltd_unit (list[int]): _description_\n",
    "\n",
    "    Returns:\n",
    "        np.array[int]: filtered sorted unit ids\n",
    "    \"\"\"\n",
    "    np.array(fltd_unit).astype(int)\n",
    "\n",
    "    # load quality results\n",
    "    unit_quality = pd.read_csv(quality_path)\n",
    "\n",
    "    # select a sorted unit and conditions\n",
    "    df = unit_quality[\n",
    "        (unit_quality[\"quality\"] == quality)\n",
    "        & (unit_quality[\"experiment\"] == exp)\n",
    "        & (unit_quality[\"sorter\"] == sorter)\n",
    "        & (unit_quality[\"layer\"] == layer)\n",
    "    ]\n",
    "    df = df[df[\"sorted\"].isin(fltd_unit)]\n",
    "    return df[\"sorted\"].values.astype(int)\n",
    "\n",
    "\n",
    "def get_spike_dataset_for(\n",
    "    unit_ids: np.array,\n",
    "    we,\n",
    "    max_spikes: int,\n",
    "    interval_ms: float,\n",
    "    sfreq: int,\n",
    "    downsample: int,\n",
    "):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        unit_ids (np.array[int]): _description_\n",
    "        we (_type_): _description_\n",
    "        max_spikes (int): _description_\n",
    "        interval_ms (float): _description_\n",
    "        sfreq (int): _description_\n",
    "        downsample (int): downsample waveforms to produce\n",
    "        - a lower sampling frequency (e.g., 2 to reduce a 40 KHz frequency\n",
    "        to 20 KHz)\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # convert interval in ms to samples\n",
    "    ttp_sp = we.nbefore\n",
    "    bef_aft_sp = interval_ms * sfreq / 1000\n",
    "    interval = np.arange(ttp_sp - bef_aft_sp, ttp_sp + bef_aft_sp, 1).astype(int)\n",
    "\n",
    "    # get all units nearest channels (with extremum amplitude)\n",
    "    max_chids = ttools.get_template_extremum_channel(we, peak_sign=\"both\")\n",
    "\n",
    "    # loop over good units\n",
    "    # 240 samples (-3 to 3 ms at 40KHz)\n",
    "    wvs = np.zeros((int(max_spikes * we.nbefore * 2 / downsample), 1))\n",
    "    unit_label = []\n",
    "    for unit in unit_ids:\n",
    "\n",
    "        # get its waveforms (num_spikes, num_samples, num_channels)\n",
    "        wv = we.get_waveforms(unit_id=unit)\n",
    "\n",
    "        # get its nearest channel\n",
    "        c_ids = we.sparsity.unit_id_to_channel_ids[unit]\n",
    "        max_chid = max_chids[unit]\n",
    "        max_chid_ix = np.where(c_ids == max_chid)[0][0]\n",
    "\n",
    "        # get waveform for that channels (2D)\n",
    "        # and (num_samples, num_spikes)\n",
    "        # TODO: sample instead of taking the first ones\n",
    "        wv_i = np.array(wv[:max_spikes, interval[::downsample], max_chid_ix]).flatten()[\n",
    "            :, None\n",
    "        ]\n",
    "\n",
    "        # record waveforms\n",
    "        wvs = np.hstack([wvs, wv_i])\n",
    "\n",
    "    wvs = wvs[:, 1:]\n",
    "    # unit_label = np.array(unit_label)\n",
    "    unit_label = np.array(unit_ids)\n",
    "    return wvs, unit_label\n",
    "\n",
    "\n",
    "def get_sorted_unit_best_score(\n",
    "    KS4_ns_10m: str,\n",
    "    GT_ns_10m: str,\n",
    "):\n",
    "    \"\"\"Get sorted unit best agreement scores\n",
    "\n",
    "    Args:\n",
    "        KS4_ns_10m (str): path of SortingExtractor\n",
    "        GT_ns_10m (str): path of GroundTruth SortingExtractor\n",
    "\n",
    "    Returns:\n",
    "        pd.Series:\n",
    "        - index_ sorted units\n",
    "        - values: agreement scores\n",
    "    \"\"\"\n",
    "    SortingTrue = si.load_extractor(GT_ns_10m)\n",
    "    SortingTrue = SortingTrue.remove_empty_units()\n",
    "    Sorting = si.load_extractor(KS4_ns_10m)\n",
    "    comp = comparison.compare_sorter_to_ground_truth(\n",
    "        SortingTrue,\n",
    "        Sorting,\n",
    "        match_mode=\"hungarian\",\n",
    "        exhaustive_gt=True,\n",
    "        delta_time=1.3,\n",
    "        compute_labels=True,\n",
    "        compute_misclassifications=False,\n",
    "        well_detected_score=0.8,\n",
    "        match_score=0.8,  # modified\n",
    "        redundant_score=0.2,  # default - we don't use that info in this analysis\n",
    "        overmerged_score=0.2,  # default - we don't use that info in this analysis\n",
    "        chance_score=0.1,  # default - we don't use that info in this analysis\n",
    "    )\n",
    "    return comp.agreement_scores.max()\n",
    "\n",
    "\n",
    "def get_dataset_for(\n",
    "    we,\n",
    "    quality_path: str,\n",
    "    sorter: str,\n",
    "    exp: str,\n",
    "    layer: str,\n",
    "    max_spikes: int,\n",
    "    flt_unit: list[int],\n",
    "    interval_ms: float,\n",
    "    sfreq: int,\n",
    "    downsample: int,\n",
    "):\n",
    "    \"\"\"get dataset\n",
    "\n",
    "    Args:\n",
    "        we (WaveformExtractor): WaveformExtractor\n",
    "        quality_path (str): path of the pandas dataframe\n",
    "        - containing sorted unit quality classification\n",
    "        sorter (str): one of \"KS4\", \"KS3\", \"KS2.5\", \"KS2\"...\n",
    "        - contained in the quality dataframe in the \"sorter\" column\n",
    "        exp (str): _description_\n",
    "        layer (str): _description_\n",
    "        max_spikes (int): _description_\n",
    "        flt_unit (list[int]): _description_\n",
    "        interval_ms (float): _description_\n",
    "        sfreq (int): _description_\n",
    "        downsample\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # get good units (filtered based on some conditions)\n",
    "    g_units = get_good_sorted_unit_ids(\n",
    "        \"good\", quality_path, sorter, exp, layer, flt_unit\n",
    "    )\n",
    "    wvs_good, good_unit_label = get_spike_dataset_for(\n",
    "        g_units, we, max_spikes, interval_ms, sfreq, downsample\n",
    "    )\n",
    "\n",
    "    # poor units (filtered based on some conditions)\n",
    "    p_units = get_poor_sorted_unit_ids(\n",
    "        \"mixed: overmerger + oversplitter\", quality_path, sorter, exp, layer, flt_unit\n",
    "    )\n",
    "    wvs_poor, poor_unit_label = get_spike_dataset_for(\n",
    "        p_units, we, max_spikes, interval_ms, sfreq, downsample\n",
    "    )\n",
    "\n",
    "    # spike dataset\n",
    "    spike_data = np.hstack([wvs_good, wvs_poor]).T\n",
    "\n",
    "    # quality label (1D discrete, CEBRA can handle only one)\n",
    "    quality_label = np.hstack(\n",
    "        [np.array([1] * len(good_unit_label)), np.array([0] * len(poor_unit_label))]\n",
    "    )\n",
    "\n",
    "    # unit ids\n",
    "    unit_ids = np.hstack([g_units, p_units])\n",
    "\n",
    "    return spike_data, quality_label, unit_ids\n",
    "\n",
    "\n",
    "def get_dataset_by_layer(\n",
    "    sort_path: str,\n",
    "    gt_path: str,\n",
    "    study: str,\n",
    "    quality_path: str,\n",
    "    sorter: str,\n",
    "    exp: str,\n",
    "    num_spike: int,\n",
    "    interval_ms: float,\n",
    "    downsample: int,\n",
    "):\n",
    "    \"\"\"get a dataset by layer\n",
    "\n",
    "    Args:\n",
    "        sort_path (str): _description_\n",
    "        gt_path (str): ground truth SortingExtractor\n",
    "        STUDY (str): _description_\n",
    "        quality_path (str): _description_\n",
    "        sorter (str): _description_\n",
    "        exp (str): _description_\n",
    "        num_spike (int): _description_\n",
    "        interval_ms (float): _description_\n",
    "        downsample (int): can be a factor of 1, 2, 3 ...\n",
    "\n",
    "    Returns:\n",
    "        dict: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate the common maximum number\n",
    "    # of spikes that it is possible to use\n",
    "    # across all units (the number of spikes of the\n",
    "    # least active unit)\n",
    "    Sorting = si.load_extractor(sort_path)\n",
    "    unit_spike = Sorting.get_total_num_spikes()\n",
    "    sfreq = Sorting.get_sampling_frequency()\n",
    "    print(\"Recording sampling frequency:\", sfreq)\n",
    "\n",
    "    # select unit ids with at least num_spikes\n",
    "    n_spike = [unit_spike[key] for key in unit_spike]\n",
    "    if num_spike == None:\n",
    "        num_spike = min(n_spike)\n",
    "        flt_unit = [unit for unit in unit_spike]\n",
    "    else:\n",
    "        flt_unit = [unit for unit in unit_spike if unit_spike[unit] > num_spike]\n",
    "\n",
    "    # get waveformExtractor\n",
    "    we = si.WaveformExtractor.load_from_folder(study)\n",
    "\n",
    "    # get data for CEBRA by layer\n",
    "    # L2/3\n",
    "    # spike_data_l23, quality_label_l23, unit_ids_l23 = get_dataset_for(\n",
    "    #     we,\n",
    "    #     quality_path,\n",
    "    #     sorter,\n",
    "    #     exp,\n",
    "    #     \"L2/3\",\n",
    "    #     num_spike,\n",
    "    #     flt_unit,\n",
    "    #     interval_ms,\n",
    "    #     sfreq,\n",
    "    #     downsample,\n",
    "    # )\n",
    "    # L4\n",
    "    spike_data_l4, quality_label_l4, unit_ids_l4 = get_dataset_for(\n",
    "        we,\n",
    "        quality_path,\n",
    "        sorter,\n",
    "        exp,\n",
    "        \"L4\",\n",
    "        num_spike,\n",
    "        flt_unit,\n",
    "        interval_ms,\n",
    "        sfreq,\n",
    "        downsample,\n",
    "    )\n",
    "    # L5\n",
    "    spike_data_l5, quality_label_l5, unit_ids_l5 = get_dataset_for(\n",
    "        we,\n",
    "        quality_path,\n",
    "        sorter,\n",
    "        exp,\n",
    "        \"L5\",\n",
    "        num_spike,\n",
    "        flt_unit,\n",
    "        interval_ms,\n",
    "        sfreq,\n",
    "        downsample,\n",
    "    )\n",
    "    # L6\n",
    "    spike_data_l6, quality_label_l6, unit_ids_l6 = get_dataset_for(\n",
    "        we,\n",
    "        quality_path,\n",
    "        sorter,\n",
    "        exp,\n",
    "        \"L6\",\n",
    "        num_spike,\n",
    "        flt_unit,\n",
    "        interval_ms,\n",
    "        sfreq,\n",
    "        downsample,\n",
    "    )\n",
    "\n",
    "    # get best scores of sorted unit\n",
    "    best_score = get_sorted_unit_best_score(\n",
    "        sort_path,\n",
    "        gt_path,\n",
    "    )\n",
    "    print(\"ex. data shape (L4):\", spike_data_l4.shape)\n",
    "    print(\"ex. label shape (L4):\", quality_label_l4.shape)\n",
    "\n",
    "    # bundle dataset for model 1 (by layer)\n",
    "    dataset1 = {\n",
    "        # \"data_l23\": spike_data_l23,\n",
    "        \"data_l4\": spike_data_l4,\n",
    "        \"data_l5\": spike_data_l5,\n",
    "        \"data_l6\": spike_data_l6,\n",
    "        # \"label_l23\": quality_label_l23,\n",
    "        \"label_l4\": quality_label_l4,\n",
    "        \"label_l5\": quality_label_l5,\n",
    "        \"label_l6\": quality_label_l6,\n",
    "        # \"unit_ids_l23\": unit_ids_l23,\n",
    "        \"unit_ids_l4\": unit_ids_l4,\n",
    "        \"unit_ids_l5\": unit_ids_l5,\n",
    "        \"unit_ids_l6\": unit_ids_l6,\n",
    "        \"best_score\": best_score,\n",
    "        \"nb_spikes\": num_spike,\n",
    "    }\n",
    "    return dataset1\n",
    "\n",
    "\n",
    "def get_dataset_pooled(dat1):\n",
    "\n",
    "    # spike_data = np.vstack(\n",
    "    #     [dat1[\"data_l23\"], dat1[\"data_l4\"], dat1[\"data_l5\"], dat1[\"data_l6\"]]\n",
    "    # )\n",
    "    # quality_label = np.hstack(\n",
    "    #     [dat1[\"label_l23\"], dat1[\"label_l4\"], dat1[\"label_l5\"], dat1[\"label_l6\"]]\n",
    "    # )\n",
    "    # unit_ids = np.hstack(\n",
    "    #     [\n",
    "    #         dat1[\"unit_ids_l23\"],\n",
    "    #         dat1[\"unit_ids_l4\"],\n",
    "    #         dat1[\"unit_ids_l5\"],\n",
    "    #         dat1[\"unit_ids_l6\"],\n",
    "    #     ]\n",
    "    # )\n",
    "    spike_data = np.vstack([dat1[\"data_l4\"], dat1[\"data_l5\"], dat1[\"data_l6\"]])\n",
    "    quality_label = np.hstack([dat1[\"label_l4\"], dat1[\"label_l5\"], dat1[\"label_l6\"]])\n",
    "    unit_ids = np.hstack(\n",
    "        [\n",
    "            dat1[\"unit_ids_l4\"],\n",
    "            dat1[\"unit_ids_l5\"],\n",
    "            dat1[\"unit_ids_l6\"],\n",
    "        ]\n",
    "    )\n",
    "    return {\"data\": spike_data, \"label\": quality_label, \"unit_ids\": unit_ids}\n",
    "\n",
    "\n",
    "def vanilla_cv_split(label, split, seed):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # get good unit indices\n",
    "    good_ix = np.where(label)[0]\n",
    "    n_tr = int(np.floor(len(good_ix) * split))\n",
    "    shuffled = np.random.permutation(good_ix)\n",
    "    g_tr_ix = shuffled[:n_tr]\n",
    "\n",
    "    # get poor unit indices\n",
    "    poor_ix = np.where(label == 0)[0]\n",
    "    n_tr = int(np.floor(len(poor_ix) * split))\n",
    "    shuffled = np.random.permutation(poor_ix)\n",
    "    p_tr_ix = shuffled[:n_tr]\n",
    "\n",
    "    # get train and test indices\n",
    "    tr_ix = np.hstack([g_tr_ix, p_tr_ix])\n",
    "    all_ix = np.arange(0, len(label), 1)\n",
    "    test_ix = np.where(~np.isin(all_ix, tr_ix))[0]\n",
    "    return tr_ix, test_ix\n",
    "\n",
    "\n",
    "def get_model1(model_cfg: dict, train: bool, model_path: str, dataset, max_iter):\n",
    "    \"\"\"train discrete label-supervised CEBRA\"\"\"\n",
    "    if train:\n",
    "        # instantiate model\n",
    "        CebraL23 = CEBRA(**model_cfg)\n",
    "        CebraL4 = CEBRA(**model_cfg)\n",
    "        CebraL5 = CEBRA(**model_cfg)\n",
    "        CebraL6 = CEBRA(**model_cfg)\n",
    "\n",
    "        # train model\n",
    "        # CebraL23.fit(dataset[\"data_l23\"], dataset[\"label_l23\"])\n",
    "        CebraL4.fit(dataset[\"data_l4\"], dataset[\"label_l4\"])\n",
    "        CebraL5.fit(dataset[\"data_l5\"], dataset[\"label_l5\"])\n",
    "        CebraL6.fit(dataset[\"data_l6\"], dataset[\"label_l6\"])\n",
    "\n",
    "        # save model\n",
    "        utils.create_if_not_exists(model_path)\n",
    "        # CebraL23.save(model_path + \"cebra_l23.pt\")\n",
    "        CebraL4.save(model_path + \"cebra_l4.pt\")\n",
    "        CebraL5.save(model_path + \"cebra_l5.pt\")\n",
    "        CebraL6.save(model_path + \"cebra_l6.pt\")\n",
    "    else:\n",
    "        # load\n",
    "        # CebraL23 = cebra.CEBRA.load(model_path + \"cebra_l23.pt\")\n",
    "        CebraL4 = cebra.CEBRA.load(model_path + \"cebra_l4.pt\")\n",
    "        CebraL5 = cebra.CEBRA.load(model_path + \"cebra_l5.pt\")\n",
    "        CebraL6 = cebra.CEBRA.load(model_path + \"cebra_l6.pt\")\n",
    "\n",
    "    # get embedding\n",
    "    # CebraL23_em = CebraL23.transform(dataset[\"data_l23\"])\n",
    "    CebraL4_em = CebraL4.transform(dataset[\"data_l4\"])\n",
    "    CebraL5_em = CebraL5.transform(dataset[\"data_l5\"])\n",
    "    CebraL6_em = CebraL6.transform(dataset[\"data_l6\"])\n",
    "    return {\n",
    "        # \"model_l23\": CebraL23,\n",
    "        \"model_l4\": CebraL4,\n",
    "        \"model_l5\": CebraL5,\n",
    "        \"model_l6\": CebraL6,\n",
    "        # \"l23\": CebraL23_em,\n",
    "        \"l4\": CebraL4_em,\n",
    "        \"l5\": CebraL5_em,\n",
    "        \"l6\": CebraL6_em,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_model2(model_cfg: dict, train: bool, model_path, dataset, max_iter):\n",
    "    \"\"\"train discrete label-supervised CEBRA\n",
    "    Args\n",
    "        train (bool)\n",
    "        model_path (str): save path\n",
    "        dataset (dict):\n",
    "        - \"data\": spike data\n",
    "        - \"label\": supervised labels\n",
    "        max_iter (int): number of training iterations\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    if train:\n",
    "        # instantiate model\n",
    "        CebraPooled = CEBRA(**model_cfg)\n",
    "        # train model\n",
    "        CebraPooled.fit(dataset[\"data\"], dataset[\"label\"])\n",
    "        # save model\n",
    "        utils.create_if_not_exists(model_path)\n",
    "        CebraPooled.save(model_path + \"cebra_pooled.pt\")\n",
    "    else:\n",
    "        # load\n",
    "        CebraPooled = cebra.CEBRA.load(model_path + \"cebra_pooled.pt\")\n",
    "\n",
    "    # get embedding\n",
    "    CebraPooled_em = CebraPooled.transform(dataset[\"data\"])\n",
    "    return {\"model\": CebraPooled, \"embedding\": CebraPooled_em}\n",
    "\n",
    "\n",
    "def plot_em(ax, CebraL4_em, quality_label, xlim):\n",
    "    \"\"\"plot the embedding, on which dots are\n",
    "    sorted units colored by sorting quality\n",
    "    (good in \"red\", poor in \"black\")\n",
    "\n",
    "    Args:\n",
    "        ax (_type_): axis\n",
    "        CebraL4_em (np.array): embedding\n",
    "        quality_label (np.array): quality labels\n",
    "        - (1: good, 0: poor)\n",
    "\n",
    "    Returns:\n",
    "        scat: plot handle\n",
    "    \"\"\"\n",
    "    # set color for good units in red, poor in black\n",
    "    colr = np.array([\"None\"] * len(quality_label))\n",
    "    colr[quality_label == 1] = \"r\"\n",
    "    colr[quality_label == 0] = \"k\"\n",
    "\n",
    "    # plot\n",
    "    ax.view_init(20, 45, 0)  # elevation, azimuth, roll\n",
    "    scat = ax.scatter(\n",
    "        CebraL4_em[:, 0],\n",
    "        CebraL4_em[:, 1],\n",
    "        CebraL4_em[:, 2],\n",
    "        c=colr,\n",
    "        edgecolors=\"w\",\n",
    "        linewidths=0.2,\n",
    "        s=20,\n",
    "    )\n",
    "    # aesthetics\n",
    "    # disconnect axes (R style)\n",
    "    ax.spines[[\"right\", \"top\"]].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_position((\"axes\", -0.05))\n",
    "    ax.spines[\"left\"].set_position((\"axes\", -0.05))\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(xlim)\n",
    "    ax.set_zlim(xlim)\n",
    "    return scat\n",
    "\n",
    "\n",
    "def plot_model1_em_by_layer(fig, dataset, em, xlim):\n",
    "\n",
    "    # L2/3\n",
    "    # ax = fig.add_subplot(1, 4, 1, projection=\"3d\")\n",
    "    # scat = plot_em(ax, em[\"l23\"], dataset[\"label_l23\"], xlim)\n",
    "    # ax.set_title(\"L2/3\")\n",
    "    # L4\n",
    "    # ax = fig.add_subplot(1, 4, 2, projection=\"3d\")\n",
    "    ax = fig.add_subplot(1, 3, 1, projection=\"3d\")\n",
    "    scat = plot_em(ax, em[\"l4\"], dataset[\"label_l4\"], xlim)\n",
    "    ax.set_title(\"L4\")\n",
    "    # L5\n",
    "    # ax = fig.add_subplot(1, 4, 3, projection=\"3d\")\n",
    "    ax = fig.add_subplot(1, 3, 2, projection=\"3d\")\n",
    "    scat = plot_em(ax, em[\"l5\"], dataset[\"label_l5\"], xlim)\n",
    "    ax.set_title(\"L5\")\n",
    "    # L6\n",
    "    # ax = fig.add_subplot(1, 4, 4, projection=\"3d\")\n",
    "    ax = fig.add_subplot(1, 3, 3, projection=\"3d\")\n",
    "    scat = plot_em(ax, em[\"l6\"], dataset[\"label_l6\"], xlim)\n",
    "    ax.set_title(\"L6\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_model2_em_by_layer(fig, dataset, em, xlim):\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "    scat = plot_em(ax, em, dataset[\"label\"], xlim)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def decode(embed_train, embed_test, label_train, label_test):\n",
    "    \"\"\"decoding using a k-Nearest Neighbor clustering technique\n",
    "    We use the fixed number of neighbors 2\n",
    "    \"\"\"\n",
    "    # predict\n",
    "    decoder = cebra.KNNDecoder(n_neighbors=2, metric=\"cosine\")\n",
    "\n",
    "    # train kNN on training embedding\n",
    "    decoder.fit(embed_train, label_train)\n",
    "\n",
    "    # decode test embedding\n",
    "    prediction = decoder.predict(embed_test)\n",
    "\n",
    "    # calculate performance metrics\n",
    "    # precision and recall are for label 1 (\"good\" units)\n",
    "    accuracy = sklearn.metrics.accuracy_score(label_test, prediction)\n",
    "    bal_accuracy = sklearn.metrics.balanced_accuracy_score(label_test, prediction)\n",
    "    precision = sklearn.metrics.precision_score(label_test, prediction, pos_label=1)\n",
    "    recall = sklearn.metrics.recall_score(label_test, prediction, pos_label=1)\n",
    "    f1_score = sklearn.metrics.f1_score(label_test, prediction, pos_label=1)\n",
    "    mae = np.median(abs(prediction - label_test))\n",
    "    r2 = sklearn.metrics.r2_score(label_test, prediction)\n",
    "    return {\n",
    "        \"metrics\": {\n",
    "            \"mae\": mae,\n",
    "            \"r2\": r2,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"bal_accuracy\": bal_accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1_score,\n",
    "        },\n",
    "        \"prediction\": prediction,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from spikeinterface.postprocessing import compute_principal_components\n",
    "from spikeinterface.qualitymetrics import compute_quality_metrics as qm\n",
    "\n",
    "job_kwargs = dict(n_jobs=-1, progress_bar=True)\n",
    "\n",
    "\n",
    "def get_waveformExtractor_for_single_units(\n",
    "    sort_path: str,\n",
    "    study_path,\n",
    "    save_path: str,\n",
    "    n_sites=384,\n",
    "    load_if_exists: bool = False,\n",
    "    add_pca: bool = True,\n",
    "    n_components=5,\n",
    "):\n",
    "    \"\"\"Setup WaveformExtractors to calculate quality metrics for single units\n",
    "\n",
    "    Args:\n",
    "        sort_path (str): _description_\n",
    "        study_path (_type_): _description_\n",
    "        save_path (str): _description_\n",
    "        n_sites (int, optional): _description_. Defaults to 384.\n",
    "        load_if_exists: bool=False (bool)\n",
    "        add_pca (bool): only if load_if_exists=False\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # compute\n",
    "    if not load_if_exists:\n",
    "        # get single units\n",
    "        Sorting = si.load_extractor(sort_path)\n",
    "        su_ix = np.where(Sorting.get_property(\"KSLabel\") == \"good\")[0]\n",
    "        su_unit_ids = Sorting.unit_ids[su_ix]\n",
    "\n",
    "        # load WaveformExtractor\n",
    "        We = si.WaveformExtractor.load_from_folder(study_path)\n",
    "\n",
    "        # create waveformExtractor for single units\n",
    "        # which we will keep for all downstream analyses\n",
    "        # this should speed up computations\n",
    "        shutil.rmtree(save_path, ignore_errors=True)\n",
    "        WeSu = We.select_units(unit_ids=su_unit_ids, new_folder=save_path)\n",
    "\n",
    "        # setup two properties required to calculate some quality metrics\n",
    "        WeSu.recording.set_property(\"gain_to_uV\", np.ones((n_sites,)))\n",
    "        WeSu.recording.set_property(\"offset_to_uV\", np.zeros((n_sites,)))\n",
    "\n",
    "        # augment extractors with pca results\n",
    "        if add_pca:\n",
    "            _ = compute_principal_components(\n",
    "                waveform_extractor=WeSu,\n",
    "                n_components=n_components,\n",
    "                mode=\"by_channel_local\",\n",
    "                **job_kwargs,\n",
    "            )\n",
    "    else:\n",
    "        # or load existing\n",
    "        WeSu = si.WaveformExtractor.load_from_folder(save_path)\n",
    "    return WeSu\n",
    "\n",
    "\n",
    "def add_spike_amplitude_extension(we, n_sites, load_if_exists: bool):\n",
    "    \"\"\"Add spike amplitudes to WaveformExtractor\n",
    "\n",
    "    Args:\n",
    "        we (WaveformExtractor): _description_\n",
    "        n_sites (int): typically 384 for neuropixels\n",
    "        load_if_exists (bool): load if exists\n",
    "\n",
    "    Returns:\n",
    "        WaveformExtractor: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # these two properties are required to compute amplitudes\n",
    "    we.recording.set_property(\"gain_to_uV\", np.ones((n_sites,)))\n",
    "    we.recording.set_property(\"offset_to_uV\", np.zeros((n_sites,)))\n",
    "\n",
    "    # compute spike amplitudes\n",
    "    # or it as an extension\n",
    "    if not load_if_exists:\n",
    "        _ = si.postprocessing.compute_spike_amplitudes(we, outputs=\"by_unit\")\n",
    "    else:\n",
    "        we.load_extension(\"spike_amplitudes\")\n",
    "\n",
    "    # unit-test\n",
    "    assert we.has_extension(\"spike_amplitudes\"), \"load spike_amplitudes extension\"\n",
    "    return we\n",
    "\n",
    "\n",
    "def get_quality_metrics(KS4_ns_10m, STUDY_ns, STUDY_ns_su, n_sites, load_if_exists):\n",
    "\n",
    "    # (40s)for single units\n",
    "    # note: adding PCA takes 3 hours (do once, then set load_if_exists=True)\n",
    "    WeNs = get_waveformExtractor_for_single_units(\n",
    "        KS4_ns_10m, STUDY_ns, STUDY_ns_su, n_sites=384, load_if_exists=True\n",
    "    )\n",
    "    # add spike amplitudes\n",
    "    WeNs = add_spike_amplitude_extension(WeNs, n_sites=384, load_if_exists=True)\n",
    "\n",
    "    # pre-compute Spiketinterface quality metrics\n",
    "    # 20 secs/unit\n",
    "    qmetrics = qm(\n",
    "        WeNs,\n",
    "        qm_params={\n",
    "            \"amplitude_cutoff\": {\n",
    "                \"peak_sign\": \"neg\",\n",
    "                \"num_histogram_bins\": 100,\n",
    "                \"histogram_smoothing_value\": 3,\n",
    "                \"amplitudes_bins_min_ratio\": 0,  # instead of 5\n",
    "            }\n",
    "        },\n",
    "        load_if_exists=load_if_exists,\n",
    "        skip_pc_metrics=True,\n",
    "        **job_kwargs,\n",
    "    )\n",
    "    qmetrics = qmetrics[\n",
    "        [\n",
    "            \"amplitude_cutoff\",\n",
    "            \"firing_range\",\n",
    "            \"firing_rate\",\n",
    "            \"isi_violations_ratio\",\n",
    "            \"presence_ratio\",\n",
    "            \"rp_contamination\",\n",
    "            \"rp_violations\",\n",
    "            \"sd_ratio\",\n",
    "            \"snr\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # add silhouette metric (pca-based but fast enough)\n",
    "    silhouette = qm(\n",
    "        WeNs,\n",
    "        metric_names=[\"silhouette\"],\n",
    "        **job_kwargs,\n",
    "    )\n",
    "    qmetrics[\"silhouette\"] = silhouette.values\n",
    "\n",
    "    # handle missing metrics\n",
    "    print(\"****************** Analysing data completion ***************\")\n",
    "\n",
    "    print(\"Data completion:\", qmetrics.notna().sum())\n",
    "\n",
    "    print(\"quality metrics are:\", qmetrics.columns)\n",
    "\n",
    "    return qmetrics\n",
    "\n",
    "\n",
    "def get_best_site_mad_noise(we, max_chids, unit):\n",
    "\n",
    "    # get waveforms\n",
    "    wv, _ = we.get_waveforms(unit_id=unit, with_index=True)\n",
    "\n",
    "    # get channel ids (sparse)\n",
    "    c_ids = we.sparsity.unit_id_to_channel_ids[unit]\n",
    "\n",
    "    # get nearest channel\n",
    "    max_chid = max_chids[unit]\n",
    "    max_chid_ix = np.where(c_ids == max_chid)[0][0]\n",
    "    return wv[:, :, max_chid_ix].flatten()\n",
    "\n",
    "\n",
    "def mad(data):\n",
    "    mean_data = np.mean(data)\n",
    "    return np.mean(np.absolute(data - mean_data))\n",
    "\n",
    "\n",
    "def get_mad_ratio(spike_amp, noise_amp):\n",
    "    \"\"\"calculate an sd_ratio robust to outliers\n",
    "\n",
    "    Args:\n",
    "        spike_amp (_type_): _description_\n",
    "        noise_amp (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    mad_unit = mad(spike_amp)  # twice smaller than std\n",
    "    mad_noise = mad(noise_amp)\n",
    "    return mad_unit / mad_noise\n",
    "\n",
    "\n",
    "def get_mad_ratio_all_units(unit_ids, WeNS, spike_amp):\n",
    "    max_chids = ttools.get_template_extremum_channel(WeNS, peak_sign=\"both\")\n",
    "    mad_ratio = []\n",
    "    for unit in unit_ids:\n",
    "        noise_amp = get_best_site_mad_noise(WeNS, max_chids, unit)\n",
    "        mad_ratio.append(get_mad_ratio(spike_amp[unit], noise_amp))\n",
    "    return mad_ratio\n",
    "\n",
    "\n",
    "def load_results(file_path):\n",
    "    with open(file_path, \"rb\") as input_file:\n",
    "        predictions_all = pickle.load(input_file)\n",
    "    return predictions_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import random\n",
    "from statsmodels.tools.validation import float_like\n",
    "\n",
    "\n",
    "def loglike(fit_output, params, scale: float, exog: np.ndarray, endog: np.array):\n",
    "    \"\"\"Calculate the log likelihood of observing the true sorting accuracies \"endog\"\n",
    "    given the fitted glm model \"fit_output\"\n",
    "    you can get by inspecting result_1.model.loglike\n",
    "    code = inspect.getsource(result_1.model.loglike)\n",
    "    print(code)\n",
    "\n",
    "    Args:\n",
    "        fit_output: fitted glm model\n",
    "        exog: predictive features used to make predictions\n",
    "        - independent variables\n",
    "        endog: true sorting accuracy (dependent variable)\n",
    "\n",
    "    Note:\n",
    "        Setting the args as below should produce llf == fit_output.llf\n",
    "        that is the log likelihood nproduced from fitting the training\n",
    "        data\n",
    "        - exog = fit_output.model.exog\n",
    "        - endog = fit_output.model.endog\n",
    "    \"\"\"\n",
    "    scale = float_like(scale, \"scale\", optional=True)\n",
    "    var_weights = np.ones(exog.shape[0])\n",
    "    freq_weights = np.ones(exog.shape[0])\n",
    "\n",
    "    # make predictions\n",
    "    # - same as calling result.model.predict(params, exog)\n",
    "    linear_preds = np.dot(exog, params) + fit_output.model._offset_exposure\n",
    "    expval = fit_output.model.family.link.inverse(linear_preds)\n",
    "    if scale is None:\n",
    "        scale = fit_output.model.estimate_scale(expval)\n",
    "\n",
    "    # calculate loglikelihood of data\n",
    "    llf = fit_output.model.family.loglike(\n",
    "        endog,  # true sorting accuracy\n",
    "        expval,  # predicted sorting accuracy\n",
    "        var_weights,  # 1 by default\n",
    "        freq_weights,  # 1 by default\n",
    "        scale,\n",
    "    )\n",
    "    return llf\n",
    "\n",
    "\n",
    "def get_single_fold_mcf_r2(\n",
    "    model_formula: str,\n",
    "    dataset: pd.DataFrame,\n",
    "    split_ratio: float = 0.75,\n",
    "    seed: int = 0,\n",
    "    scale_data=False,\n",
    "):\n",
    "    \"\"\"Calculate mcfadden pseudo r-squared for a single fold, sampling\n",
    "    split_ratio instances of the dataset as train and 1-split_ratio as test\n",
    "\n",
    "    Args:\n",
    "        model_formula\n",
    "\n",
    "    note:\n",
    "        - mcfadden r2 formula: (1 - result_1.llf / result_1.llnull)\n",
    "        - produced by statsmodel r2 = test_model.pseudo_rsquared(kind=\"mcf\")\n",
    "\n",
    "    Returns:\n",
    "        mcfadden pseudo r-squared (float)\n",
    "    \"\"\"\n",
    "    # GET MCF R2 FOR TEST MODEL\n",
    "    random.seed(seed)\n",
    "\n",
    "    # TRAIN -----------\n",
    "    # calculate 75% of train\n",
    "    n_train = np.round(split_ratio * dataset.shape[0]).astype(int)\n",
    "\n",
    "    # sample n_train\n",
    "    indices = np.arange(0, dataset.shape[0], 1).tolist()\n",
    "    train_indices = random.sample(indices, n_train)\n",
    "    train_dataset = dataset.iloc[train_indices, :]\n",
    "\n",
    "    assert (\n",
    "        not \"quality_label\" in dataset.columns\n",
    "    ), \"should drop quality_label from dataset\"\n",
    "\n",
    "    # apply scaling\n",
    "    if scale_data:\n",
    "        standard_scaler = StandardScaler()\n",
    "        predictors = dataset.columns.tolist()\n",
    "        predictors.remove(\"sorting_accuracy\")\n",
    "        train_dataset[predictors] = standard_scaler.fit_transform(\n",
    "            train_dataset[predictors]\n",
    "        )\n",
    "\n",
    "    # train model on this fold\n",
    "    try:\n",
    "        model_1 = sm.GLM.from_formula(\n",
    "            model_formula,\n",
    "            family=sm.families.Binomial(),\n",
    "            data=train_dataset,\n",
    "        )\n",
    "        result_1 = model_1.fit()\n",
    "    except:\n",
    "        raise ValueError(\"Model formula is wrong\")\n",
    "\n",
    "    # TEST -----------\n",
    "    # create test dataset with remaining instances\n",
    "    test_indices = list(set(indices) - set(train_indices))\n",
    "    test_dataset = dataset.iloc[test_indices, :]\n",
    "\n",
    "    # apply scaling\n",
    "    if scale_data:\n",
    "        test_dataset[predictors] = standard_scaler.transform(test_dataset[predictors])\n",
    "\n",
    "    # reorder test dataset features and add intercept\n",
    "    # to make predictions and get loglikelihood\n",
    "    features = result_1.params.index[1:]\n",
    "    test_features = test_dataset.loc[:, features]\n",
    "    test_features.insert(0, \"intercept\", 1)\n",
    "\n",
    "    # test and eval\n",
    "    llf = loglike(\n",
    "        result_1,\n",
    "        result_1.params,\n",
    "        None,\n",
    "        exog=test_features,\n",
    "        endog=test_dataset[\"sorting_accuracy\"],\n",
    "    )\n",
    "\n",
    "    # GET MCF R2 FOR NULL MODEL\n",
    "\n",
    "    # train\n",
    "    null_model = sm.GLM.from_formula(\n",
    "        \"sorting_accuracy ~ 1\",\n",
    "        family=sm.families.Binomial(),\n",
    "        data=train_dataset,\n",
    "    )\n",
    "    null_model = null_model.fit()\n",
    "\n",
    "    # test and eval\n",
    "    ll_null = loglike(\n",
    "        null_model,\n",
    "        null_model.params,\n",
    "        None,\n",
    "        exog=np.array([test_features[\"intercept\"]]).T,\n",
    "        endog=test_dataset[\"sorting_accuracy\"],\n",
    "    )\n",
    "\n",
    "    # fix r-squared in case ll_null==0\n",
    "    if llf > 0 and ll_null == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return 1 - llf / ll_null\n",
    "\n",
    "\n",
    "def get_crossval_mcf_r2(\n",
    "    dataset: pd.DataFrame,\n",
    "    model_formula: str,\n",
    "    split_ratio: float = 0.75,\n",
    "    seeds: np.array = np.arange(0, 100, 1),\n",
    "    scale_data=False,\n",
    "):\n",
    "    \"\"\"Calculate cross-validated mcfadden pseudo r-squared\n",
    "    on test dataset\n",
    "\n",
    "    Args:\n",
    "        model_formula (str): glm model formula\n",
    "        split_ratio (float, optional): _description_. Defaults to 0.75.\n",
    "        seeds (np.array, optional): _description_. Defaults to np.arange(0, 100, 1).\n",
    "\n",
    "    Returns:\n",
    "        np.array: mcfadden pseudo r-squared\n",
    "    \"\"\"\n",
    "    r2_all = []\n",
    "    for seed in range(len(seeds)):\n",
    "        r2 = get_single_fold_mcf_r2(\n",
    "            model_formula,\n",
    "            dataset,\n",
    "            split_ratio=split_ratio,\n",
    "            seed=seed,\n",
    "            scale_data=scale_data,\n",
    "        )\n",
    "        # print(\n",
    "        #     \"Nan because SVD did not converge in Linear Least Squares because of wrong covariance matrix()\"\n",
    "        # )\n",
    "        # # can fail if SVD did not converge in Linear Least Squares\n",
    "        # # because of wrong covariance matrix\n",
    "        # r2 = np.nan\n",
    "        r2_all.append(r2)\n",
    "    return np.array(r2_all)\n",
    "\n",
    "\n",
    "def get_single_fold_flclassifier_metrics(\n",
    "    model_formula: str,\n",
    "    dataset: pd.DataFrame,\n",
    "    split_ratio: float = 0.75,\n",
    "    seed: int = 0,\n",
    "    thresh: float = 0.8,\n",
    "    scale_data=False,\n",
    "):\n",
    "    \"\"\"Calculate the cross-validated precisions\n",
    "    and recalls of a fractional logistic classifier\n",
    "    trained to predict high-quality unit label-\n",
    "\n",
    "    Args:\n",
    "        model_formula\n",
    "\n",
    "    Returns:\n",
    "        precisions and recalls for each fold\n",
    "    \"\"\"\n",
    "    # GET MCF R2 FOR TEST MODEL\n",
    "    random.seed(seed)\n",
    "\n",
    "    # unit-test\n",
    "    # this is a ground truth label that should not\n",
    "    # be in the dataset\n",
    "    assert (\n",
    "        not \"sorting_accuracy\" in dataset.columns\n",
    "    ), \"drop sorting_accuracy from dataset\"\n",
    "\n",
    "    # TRAIN -----------\n",
    "    # calculate 75% of train\n",
    "    n_train = np.round(split_ratio * dataset.shape[0]).astype(int)\n",
    "\n",
    "    # sample n_train\n",
    "    indices = np.arange(0, dataset.shape[0], 1).tolist()\n",
    "    train_indices = random.sample(indices, n_train)\n",
    "    train_dataset = dataset.iloc[train_indices, :]\n",
    "\n",
    "    # apply scaling\n",
    "    if scale_data:\n",
    "        standard_scaler = StandardScaler()\n",
    "        predictors = dataset.columns.tolist()\n",
    "        predictors.remove(\"quality_label\")\n",
    "        train_dataset[predictors] = standard_scaler.fit_transform(\n",
    "            train_dataset[predictors]\n",
    "        )\n",
    "\n",
    "    # train model on this fold\n",
    "    try:\n",
    "        model_1 = sm.GLM.from_formula(\n",
    "            model_formula,\n",
    "            family=sm.families.Binomial(),\n",
    "            data=train_dataset,\n",
    "        )\n",
    "        result_1 = model_1.fit()\n",
    "    except:\n",
    "        raise ValueError(\"Model formula is wrong\")\n",
    "\n",
    "    # TEST -----------\n",
    "    # create test dataset with remaining instances\n",
    "    # make sure to drop quality label from test dataset\n",
    "    test_indices = list(set(indices) - set(train_indices))\n",
    "    test_dataset = dataset.iloc[test_indices, :]\n",
    "    test_label = test_dataset[\"quality_label\"]\n",
    "    test_dataset = test_dataset.drop(columns=[\"quality_label\"])\n",
    "\n",
    "    # apply scaling\n",
    "    if scale_data:\n",
    "        test_dataset[predictors] = standard_scaler.fit_transform(\n",
    "            test_dataset[predictors]\n",
    "        )\n",
    "\n",
    "    # unit-test\n",
    "    assert not \"quality_label\" in test_dataset.columns, \"drop quality label from test\"\n",
    "\n",
    "    # reorder test dataset features and add intercept\n",
    "    # to make predictions\n",
    "    features = result_1.params.index[1:]\n",
    "    test_features = test_dataset.loc[:, features]\n",
    "    test_features.insert(0, \"intercept\", 1)\n",
    "\n",
    "    # unit-test\n",
    "    assert not \"quality_label\" in features, \"drop quality label from features\"\n",
    "\n",
    "    # predict -------------\n",
    "    # thresholded binary predictions\n",
    "    predictions = (result_1.predict(test_features) >= thresh).astype(int)\n",
    "    precision = metrics.precision_score(test_label, predictions)\n",
    "    recall = metrics.recall_score(test_label, predictions)\n",
    "    return {\"precision\": precision, \"recall\": recall}\n",
    "\n",
    "\n",
    "def train_classifier_on_full_dataset(\n",
    "    model_formula: str,\n",
    "    dataset: pd.DataFrame,\n",
    "):\n",
    "    \"\"\"train the classifier on the full dataset\n",
    "\n",
    "    Args:\n",
    "        model_formula\n",
    "\n",
    "    Returns:\n",
    "        precisions and recalls for each fold\n",
    "    \"\"\"\n",
    "    # unit-test\n",
    "    # this is a ground truth label that should not\n",
    "    # be in the dataset\n",
    "    assert (\n",
    "        not \"sorting_accuracy\" in dataset.columns\n",
    "    ), \"drop sorting_accuracy from dataset\"\n",
    "\n",
    "    # train the model\n",
    "    try:\n",
    "        model = sm.GLM.from_formula(\n",
    "            model_formula,\n",
    "            family=sm.families.Binomial(),\n",
    "            data=dataset,\n",
    "        )\n",
    "        result = model.fit()\n",
    "    except:\n",
    "        raise ValueError(\"Model formula is wrong\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_crossval_flclassifier_metrics(\n",
    "    dataset: pd.DataFrame,\n",
    "    model_formula: str,\n",
    "    split_ratio: float = 0.75,\n",
    "    seeds: np.array = np.arange(0, 100, 1),\n",
    "    thresh: float = 0.8,\n",
    "    scale_data=False,\n",
    "):\n",
    "    \"\"\"Calculate cross-validated mcfadden pseudo r-squared\n",
    "    on test dataset\n",
    "\n",
    "    Args:\n",
    "        model_formula (str): glm model formula\n",
    "        split_ratio (float, optional): _description_. Defaults to 0.75.\n",
    "        seeds (np.array, optional): _description_. Defaults to np.arange(0, 100, 1).\n",
    "\n",
    "    Returns:\n",
    "        np.array: mcfadden pseudo r-squared\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for seed in range(len(seeds)):\n",
    "        result = get_single_fold_flclassifier_metrics(\n",
    "            model_formula,\n",
    "            dataset,\n",
    "            split_ratio=split_ratio,\n",
    "            seed=seed,\n",
    "            thresh=thresh,\n",
    "            scale_data=scale_data,\n",
    "        )\n",
    "        results.append(result)\n",
    "    return np.array(results)\n",
    "\n",
    "\n",
    "# best_model_weights = best_model_on_full_dataset.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1m)Load dataset\n",
    "\n",
    "* the dataset is a dataframe that contains the sorted single-units (indices), their quality metrics and their quality label ()\"good\" or \"bad\" units evaluated with our ground truth, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator IncrementalPCA from version 1.4.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00300c9ca6224a96a501915128625b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** Analysing data completion ***************\n",
      "Data completion: amplitude_cutoff        184\n",
      "firing_range            184\n",
      "firing_rate             184\n",
      "isi_violations_ratio    184\n",
      "presence_ratio          184\n",
      "rp_contamination        184\n",
      "rp_violations           184\n",
      "sd_ratio                184\n",
      "snr                     184\n",
      "silhouette              182\n",
      "dtype: int64\n",
      "quality metrics are: Index(['amplitude_cutoff', 'firing_range', 'firing_rate',\n",
      "       'isi_violations_ratio', 'presence_ratio', 'rp_contamination',\n",
      "       'rp_violations', 'sd_ratio', 'snr', 'silhouette'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from src.nodes.models import dataset_flc\n",
    "\n",
    "data_dict = dataset_flc.load_dataset(\n",
    "    quality_path, \"NS\", \"KS4\", KS4_ns_10m, STUDY_ns, STUDY_ns_su, GT_ns_10m\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amplitude_cutoff</th>\n",
       "      <th>firing_range</th>\n",
       "      <th>firing_rate</th>\n",
       "      <th>isi_violations_ratio</th>\n",
       "      <th>rp_contamination</th>\n",
       "      <th>rp_violations</th>\n",
       "      <th>sd_ratio</th>\n",
       "      <th>snr</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>mad_ratio</th>\n",
       "      <th>quality_label</th>\n",
       "      <th>sorting_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amplitude_cutoff</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.182577</td>\n",
       "      <td>-0.183618</td>\n",
       "      <td>0.365864</td>\n",
       "      <td>0.010510</td>\n",
       "      <td>-0.034537</td>\n",
       "      <td>0.441776</td>\n",
       "      <td>0.607915</td>\n",
       "      <td>0.340212</td>\n",
       "      <td>0.142342</td>\n",
       "      <td>-0.061456</td>\n",
       "      <td>-0.025305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firing_range</th>\n",
       "      <td>-0.182577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996525</td>\n",
       "      <td>-0.081202</td>\n",
       "      <td>0.206018</td>\n",
       "      <td>0.442963</td>\n",
       "      <td>-0.083530</td>\n",
       "      <td>-0.213638</td>\n",
       "      <td>-0.258664</td>\n",
       "      <td>0.073932</td>\n",
       "      <td>0.026902</td>\n",
       "      <td>0.012170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firing_rate</th>\n",
       "      <td>-0.183618</td>\n",
       "      <td>0.996525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.080729</td>\n",
       "      <td>0.198882</td>\n",
       "      <td>0.429786</td>\n",
       "      <td>-0.097636</td>\n",
       "      <td>-0.206282</td>\n",
       "      <td>-0.239320</td>\n",
       "      <td>0.051711</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.052015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isi_violations_ratio</th>\n",
       "      <td>0.365864</td>\n",
       "      <td>-0.081202</td>\n",
       "      <td>-0.080729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436161</td>\n",
       "      <td>0.182912</td>\n",
       "      <td>0.208777</td>\n",
       "      <td>0.279603</td>\n",
       "      <td>0.212870</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>0.023906</td>\n",
       "      <td>0.020156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rp_contamination</th>\n",
       "      <td>0.010510</td>\n",
       "      <td>0.206018</td>\n",
       "      <td>0.198882</td>\n",
       "      <td>0.436161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555389</td>\n",
       "      <td>0.068913</td>\n",
       "      <td>-0.033521</td>\n",
       "      <td>-0.034089</td>\n",
       "      <td>0.096693</td>\n",
       "      <td>-0.015572</td>\n",
       "      <td>-0.041038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rp_violations</th>\n",
       "      <td>-0.034537</td>\n",
       "      <td>0.442963</td>\n",
       "      <td>0.429786</td>\n",
       "      <td>0.182912</td>\n",
       "      <td>0.555389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003119</td>\n",
       "      <td>-0.077039</td>\n",
       "      <td>-0.102947</td>\n",
       "      <td>0.030812</td>\n",
       "      <td>-0.043278</td>\n",
       "      <td>-0.084280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd_ratio</th>\n",
       "      <td>0.441776</td>\n",
       "      <td>-0.083530</td>\n",
       "      <td>-0.097636</td>\n",
       "      <td>0.208777</td>\n",
       "      <td>0.068913</td>\n",
       "      <td>-0.003119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408960</td>\n",
       "      <td>0.082740</td>\n",
       "      <td>0.827203</td>\n",
       "      <td>-0.253621</td>\n",
       "      <td>-0.206516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snr</th>\n",
       "      <td>0.607915</td>\n",
       "      <td>-0.213638</td>\n",
       "      <td>-0.206282</td>\n",
       "      <td>0.279603</td>\n",
       "      <td>-0.033521</td>\n",
       "      <td>-0.077039</td>\n",
       "      <td>0.408960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637963</td>\n",
       "      <td>-0.013676</td>\n",
       "      <td>0.209621</td>\n",
       "      <td>0.274974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silhouette</th>\n",
       "      <td>0.340212</td>\n",
       "      <td>-0.258664</td>\n",
       "      <td>-0.239320</td>\n",
       "      <td>0.212870</td>\n",
       "      <td>-0.034089</td>\n",
       "      <td>-0.102947</td>\n",
       "      <td>0.082740</td>\n",
       "      <td>0.637963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.224648</td>\n",
       "      <td>0.153304</td>\n",
       "      <td>0.194565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mad_ratio</th>\n",
       "      <td>0.142342</td>\n",
       "      <td>0.073932</td>\n",
       "      <td>0.051711</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>0.096693</td>\n",
       "      <td>0.030812</td>\n",
       "      <td>0.827203</td>\n",
       "      <td>-0.013676</td>\n",
       "      <td>-0.224648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.457291</td>\n",
       "      <td>-0.425061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_label</th>\n",
       "      <td>-0.061456</td>\n",
       "      <td>0.026902</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.023906</td>\n",
       "      <td>-0.015572</td>\n",
       "      <td>-0.043278</td>\n",
       "      <td>-0.253621</td>\n",
       "      <td>0.209621</td>\n",
       "      <td>0.153304</td>\n",
       "      <td>-0.457291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorting_accuracy</th>\n",
       "      <td>-0.025305</td>\n",
       "      <td>0.012170</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.020156</td>\n",
       "      <td>-0.041038</td>\n",
       "      <td>-0.084280</td>\n",
       "      <td>-0.206516</td>\n",
       "      <td>0.274974</td>\n",
       "      <td>0.194565</td>\n",
       "      <td>-0.425061</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      amplitude_cutoff  firing_range  firing_rate  \\\n",
       "amplitude_cutoff              1.000000     -0.182577    -0.183618   \n",
       "firing_range                 -0.182577      1.000000     0.996525   \n",
       "firing_rate                  -0.183618      0.996525     1.000000   \n",
       "isi_violations_ratio          0.365864     -0.081202    -0.080729   \n",
       "rp_contamination              0.010510      0.206018     0.198882   \n",
       "rp_violations                -0.034537      0.442963     0.429786   \n",
       "sd_ratio                      0.441776     -0.083530    -0.097636   \n",
       "snr                           0.607915     -0.213638    -0.206282   \n",
       "silhouette                    0.340212     -0.258664    -0.239320   \n",
       "mad_ratio                     0.142342      0.073932     0.051711   \n",
       "quality_label                -0.061456      0.026902     0.066000   \n",
       "sorting_accuracy             -0.025305      0.012170     0.052015   \n",
       "\n",
       "                      isi_violations_ratio  rp_contamination  rp_violations  \\\n",
       "amplitude_cutoff                  0.365864          0.010510      -0.034537   \n",
       "firing_range                     -0.081202          0.206018       0.442963   \n",
       "firing_rate                      -0.080729          0.198882       0.429786   \n",
       "isi_violations_ratio              1.000000          0.436161       0.182912   \n",
       "rp_contamination                  0.436161          1.000000       0.555389   \n",
       "rp_violations                     0.182912          0.555389       1.000000   \n",
       "sd_ratio                          0.208777          0.068913      -0.003119   \n",
       "snr                               0.279603         -0.033521      -0.077039   \n",
       "silhouette                        0.212870         -0.034089      -0.102947   \n",
       "mad_ratio                         0.047608          0.096693       0.030812   \n",
       "quality_label                     0.023906         -0.015572      -0.043278   \n",
       "sorting_accuracy                  0.020156         -0.041038      -0.084280   \n",
       "\n",
       "                      sd_ratio       snr  silhouette  mad_ratio  \\\n",
       "amplitude_cutoff      0.441776  0.607915    0.340212   0.142342   \n",
       "firing_range         -0.083530 -0.213638   -0.258664   0.073932   \n",
       "firing_rate          -0.097636 -0.206282   -0.239320   0.051711   \n",
       "isi_violations_ratio  0.208777  0.279603    0.212870   0.047608   \n",
       "rp_contamination      0.068913 -0.033521   -0.034089   0.096693   \n",
       "rp_violations        -0.003119 -0.077039   -0.102947   0.030812   \n",
       "sd_ratio              1.000000  0.408960    0.082740   0.827203   \n",
       "snr                   0.408960  1.000000    0.637963  -0.013676   \n",
       "silhouette            0.082740  0.637963    1.000000  -0.224648   \n",
       "mad_ratio             0.827203 -0.013676   -0.224648   1.000000   \n",
       "quality_label        -0.253621  0.209621    0.153304  -0.457291   \n",
       "sorting_accuracy     -0.206516  0.274974    0.194565  -0.425061   \n",
       "\n",
       "                      quality_label  sorting_accuracy  \n",
       "amplitude_cutoff          -0.061456         -0.025305  \n",
       "firing_range               0.026902          0.012170  \n",
       "firing_rate                0.066000          0.052015  \n",
       "isi_violations_ratio       0.023906          0.020156  \n",
       "rp_contamination          -0.015572         -0.041038  \n",
       "rp_violations             -0.043278         -0.084280  \n",
       "sd_ratio                  -0.253621         -0.206516  \n",
       "snr                        0.209621          0.274974  \n",
       "silhouette                 0.153304          0.194565  \n",
       "mad_ratio                 -0.457291         -0.425061  \n",
       "quality_label              1.000000          0.846842  \n",
       "sorting_accuracy           0.846842          1.000000  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select uncorrelated metrics\n",
    "data_dict[\"dataset\"].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validated regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sorting_accuracy ~ 1 + (amplitude_cutoff + firing_range + firing_rate + isi_violations_ratio + rp_contamination + rp_violations + sd_ratio + snr + silhouette + mad_ratio + quality_label)^2'"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regression_model(predictors):\n",
    "    # list variables\n",
    "    variables = \"\"\n",
    "    for predictor in predictors:\n",
    "        variables += \" + \" + str(predictor)\n",
    "    return f\"\"\"sorting_accuracy ~ 1 {variables}\"\"\"\n",
    "\n",
    "\n",
    "def create_classifier_model(predictors):\n",
    "    # list variables\n",
    "    variables = \"\"\n",
    "    for predictor in predictors:\n",
    "        variables += \" + \" + str(predictor)\n",
    "    return f\"\"\"quality_label ~ 1 {variables}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The mad_ratio is very strongly linearly correlated with the sorting accuracy scores! twice more than SNR !!\n",
    "\n",
    "* as expected, the high-quality label is highly correlated with the sorting accuracy score ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6s) Train & eval regression model\n",
    "\n",
    "* We obtain an R2=0.20 in predicting sorted single-units' sorting accuracy from quality metrics.\n",
    "* z-scoring did not change the r-squared.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting_accuracy ~ 1  + amplitude_cutoff + firing_range + firing_rate + isi_violations_ratio + rp_contamination + rp_violations + sd_ratio + snr + silhouette + mad_ratio\n",
      "mean r2: 0.20358951127069908\n",
      "std r2: 0.17486406624107603\n",
      "95% CI: 0.0342733569832509\n"
     ]
    }
   ],
   "source": [
    "# format dataset\n",
    "dataset_r = copy.copy(dataset)\n",
    "dataset_r = dataset_r.drop(columns=[\"quality_label\"])\n",
    "\n",
    "# (7 seconds) cross-validate\n",
    "seeds = np.arange(0, 100, 1)\n",
    "\n",
    "# create model\n",
    "model = create_regression_model(predictive_metrics)\n",
    "print(model)\n",
    "\n",
    "# evaluate R2\n",
    "r2 = get_crossval_mcf_r2(\n",
    "    dataset=dataset_r,\n",
    "    model_formula=model,\n",
    "    split_ratio=0.75,\n",
    "    seeds=seeds,\n",
    "    scale_data=True,\n",
    ")\n",
    "\n",
    "print(\"mean r2:\", np.nanmedian(r2))\n",
    "print(\"std r2:\", np.nanstd(r2))\n",
    "print(\"95% CI:\", 1.96 * np.std(r2) / np.sqrt(len(r2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'FLR-metrics')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAACGCAYAAAAB3t5yAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAO7UlEQVR4nO2dbUwU1xrH/zsBljJ9sY3Wrihtwm5iYqKtsmPExV1qK6StCAJWlBakicaIlrSkIGnSN7EvNsYmNQ2Wlth4waatS7Qf2oZW1NZGsLc0G5pYJYBI36Kl1uItLPDcD9ydu7vM7J7ZXXbhML/kJDBnOOcw/3nO63POGIiIoDPtEWJdAJ3IoAvJCbqQnKALyQm6kJygC8kJupCcoAvJCdNeyO3bt8e6CFOCaS9kf39/rIswJZj2QuqMowvJCbqQnKALyQm6kJygC8kJupCcoAvJCbqQnKALyQm6kJwQNSGrqqqQkZGBJ554Am63e0L8a6+9hrS0tGgVhzuiIuQPP/yA/v5+nDlzBgsXLsTHH3/sE3/jxg24XK5oFIVboiLk2bNnsWbNGgBAdnY2vvnmG5/4t956C+Xl5dEoCrfERSOTgYEBmEwmAMAdd9yBP/74Q467fv06XC4Xnn/++aDpNDU1oampyeeavow1TlSEnDVrFv766y8A48LdddddctyBAwewc+dOpnSKiopQVFTkcy0nJydyBZ3GRKVqTU9PR0tLCwDg888/x8qVK+W4S5cuYc+ePcjOzsbFixdRW1sbjSLxB0WJyspKstlstGnTJhoaGqKtW7dOuGfZsmWa0127dm0kijftMRBN7008OTk5OH78eKyLEXO4nRBobm6GJEkQRRGSJKG5uTnWRZpcYl0lhItS1ep0OgmATzAYDOR0OqNfwCjBpUXu3bt3wjUiwquvvhqD0kQHLoXs7OzUdD1SxLQ6j3WVEC7+VavT6SRRFCdUrQBIkqRJK0ew6tzpdJLVaqWkpCSyWq0Rr+a5ElLpYXo/1ObmZvm+SD9Uq9WqmK8oipSQkDDpbTZXQgZ6mN4iKt1TXV2tmgeL8ElJSaovkVpQqiFCfcm4ElLtYYqiKN+jJrbHSgRBIJPJRGazmZKSkuiee+5hsqZA6aoF73IRhdfb5kpItYfp/eaHYjks1uR0OslgMISVBkv51eCq17p69WrF6w8++KD88+233x6RvPx7wLm5uaiqqoLRaGT6e4PBgJqamoBpBrvuQ5gGEXO0WGR1dXVErBF+VuJ0OslsNjP9XXx8vNwB8m8Dw7FIroQM1kaqDUtCCcE6T/5BEATFF8l/iOJfPXv3tgPBlZDB3uhIibh79245T1ZLlCRJ9V6LxSL3VM1mM1ksFhJFkSRJYhKRiDMhg73RoVqkyWTyebCeIYLS+FApGAwGTdV6KGNMrjo7AJCamgpBECAIAiwWC5xOJ9atWwcAyMrKYkrDYrHAaDRCFEUYjUbMnz8fR44cwblz50BEyMvLQ3t7O4aHh5nScjqd+PLLL5n/BwplXliL6t999x19//33PtdOnz6t6c2JNN4WiSDtj3+8WjAajappsY4XLRaLT7WoddjjP8YMBrOQFRUVVFRURCUlJfTII4/Q1atXiYgoMzNTU4aRJpCQ8GofQxmwK6XFIojBYJhQTq35a50XZhYyIyND/rmtrY1sNht1dnZOeSE9b3YkJgIEQWDq3Fgslgnl1DJhwNpT9YZZyOXLl9Po6Kj8e19fH9lsNpo/f76mDCNNMCEFQSCr1crcu2R90IHi1URwOp0kCAJTHlo7O8xCnjhxgvr6+nyu9fb20iuvvKIpw0jjLWSgB6x1+ixQ8PRivdMVBGFCu6gEaxWrtWpl7rXGx8dj/fr1kCQJLS0tqKmpQWFhIWbPns2axKRTVVUFURQV44gIJpPJZwrtzjvvlHuoShgMBsXrv/zyCwYHB+V0AWBsbAyXLl0CEckLzImJibj11lthNBrlheaamhrVdL3RvAjOqrgkSXTlyhVyuVx022230dGjRzW9MZNFsKo1UPD0RNV6tKFUxxaLhSk/SZJIFMWILYIze5qLoojk5GQkJydjyZIlePzxx7W9MVMQ+t94jVQ8Qg0GAwwGg2q8El1dXQHzKy4uhtvtRnx8PEZGRrBgwQJ0dXVNyMN7op8JVsXnzJlDhYWFVFBQ4PNzYWEh098/99xzZLPZqLi4mIaHh+Xrx48fJ0mSaOXKlbRr1y5NbyFReBYJjPdqA83RVldXy1YjiiKZTKawOkKsQevsDrOQPT09qiEYHR0dtHnzZiIi2rNnDzU2Nspxvb295Ha7iYho48aN1N7ezlx4ovCFlCRJtQOiVk1uXDH5QnrKxgpz1Xrvvfey3joB/211DQ0N8maclJQU+b6EhAQIQvRmDT1rgkSE9evXT6jeLl++7PO72WxGWVkZnrj3YyxeW4D3338fPT09GBkZke/xTyMcNHV4NL3+IVJbWytXExcvXqSioqIJ97S1tVF2dnbAdBobG2nt2rU+YenSpXK80tSaWhAEwWeo4HQ6A3ZUSktLacTtJvfgVRr7bAW5B6/SiNtNW7dujZgF+geliQU1oiLkwYMH6fDhw0REdP78edqxY4dPfF9fH6Wnp9Nvv/2mOW2WZSyloMXvxmw204jbTXSxjuhoItG/QHQ0kcZ+OkQjbjelpqbGXMiYb6u7ceMGNm7ciLq6Otx9991h5ePvOhEI+l916u1ErFaVlZWVgYavA+d3AaP/jF8c/QeGf+8Cuf/CU089xZRnYmIiJElCXBxbi/bzzz8z3QdEydP8/vvvx9y5c5GRkYHOzk7k5+dj27ZtAMY3unZ3d6O8vBwOhwOnTp0KOZ/c3FwkJCQw309EyM/PlwfrixYtUrzPbDbDcP0HYGzIN2L0H2CgA/fddx9TfosXL8a5c+fgdrvhdDrlXdxqqJVHEc112RTD39M81FUOz+KvUq/z9ddfJ/fNq/+vVj3haCK5b16jvXv3+txvMpmYXTYCtc1ms3lm+rUSqXsJKPmn+gdJkuRZl8TExAlt5NhPh5jbSI/LhtFoJFEUyWg0BnQ4VhN0Rvq1evCeAvO4Z7BMtwVyZC4pKRnvtd68SvR5Orn/c41G3G4qKSnRbP1qlqZ70THAsh4ZzJE5NTWV9u3bR9S6li5cuBBWb9VTlXtvD1DzAWLxFpgxQrK0nd6+poH2kbR99AwRheZdHkrQLdILtYceHx+vai1qInm3W5FwIQkWZpxfazCU2s5Almc0GlVX9D1WMtlWyTopMKOEVCJUXx5RFH38W0VRlLcDxMXFRUxIVm867vxataJp0O3FvHnzfPxbBwcHMTIygp07d6p6HIiiKG9Lr66uZvIUYC5fWK/zFCBciwylajQYDCF5Dyjth/RU9WpjyBm5ZSAQgXYCs7heeOI8bWu4O5SVyqPUhrPCpZD+DynYLij/v2WZXtPaW/U/w4C1PKxwJ6SWrQFq4zMWy9BSJXufYUAU3gyOGtwJqcVStO6v8BBoYyuLNbOcdaAV7oTU0nYFsgC1NjWYxVsslqDWrFukAqFaZKAeYaA2LFj6LFaltlcy0BExweBOSLXOSnV1NXOPMJDFBLN4FqvSLVIB1mUsLQRqw4Kd08OSl95GKjAZJygHshi13qrJZCKLxcJ0YpVukQpMhpDBxpL+Fq9lnMqSfijoQqqgpXoOxcLCrf790c80jwCiKOLmzZuK1//++++olGHGr35EArUVilBXVkJBFzICKG1eVTprbjKJ+dfqRkdHUVZWhoyMDFRUVESrOBElNzcXx44dgyRJ8vk8CQkJqK2tjdpx2DH/Wt2nn36KefPm4cyZMxgcHMS3334bjSJFnNzcXOzevRtDQ0MYHBzE0NAQ2tvbJ2xLmCxi/rW6YF+y86apqQk5OTk+QamTESti+XWDmH+tbmBgQD5D1T/OH6WPnE0l2traYpZ3VCwy0NfqAsXpsBPzbXWB4nTYiUrV6r2tLiUlBZWVldi2bRvq6urw2GOPobm5GRkZGXjggQewYsWKkPPZvn17VD4M2t/fj+Tk5EnPx0NycjLeeeedgPdM+5mdWDAVZpP80ScEOEEXkhN0ITlBFzIEpuJYVu/scIJukZygC8kJupCcoAvJCbqQDPT09GDOnDlwOBywWq347LPPcOLECSxfvhw2mw1PP/10rIuIae9FFw26u7spPz+fiMYPQExLSwv7nNlIE5VJc574888/QUQxPWdWCV1IRk6dOgWbzYaOjg4cO3ZMvt7e3o7ff/8dS5cujWHp9DaSGbvdjq+//hrvvvsuTp48CQC4cuUKKioqcPjw4RiXThdSM0VFRWhpaUFvb2/EzpmNBLqQIbBlyxZ88MEHETtnNhLoc62coFskJ+hCcoIuJCfoQnKCLiQn6EJygi4kJ3ArpPfSk8PhwFdffYXKykqfe0pLS2G1WrFq1SoUFBT47NsMh0OHDile//XXX/HCCy9EJA9/uBUSGJ8fbW1tRWtrq+rqRENDA06fPo1Zs2bhiy++iEi+SkISEebOnYuXXnopInn4w7WQWrh+/fqETwa2trYiKysLeXl5WLJkCT788ENkZWVBkiRcu3YNwPieSLvdjlWrVsHlcsHpdOLChQtwOBxobGxEaWkpduzYgTVr1uD8+fMoKCgAML4Fz2azweFwYN++fejq6kJ6ejoyMzPlz01pIqaroZNId3c3zZ49m+x2O9ntdvrkk0/o2Wef9bmnpKSE0tLSKDU1lVavXu3zpVkiopMnT9JDDz1ERER1dXWUm5tLREQHDhyg9957j1wuFz355JNERNTf3085OTlERLRs2TKfPOrr6+UyeRao09PT6fLly0RENDo6SvX19XTw4EH5d61wbZHeVavavsuGhga4XC643W4MDAxg//79spUA4x8mA8bPMPf8nJycjIGBAfz44484e/YsHA4HNm3apHoUi9VqnXBteHgYCxYsAAAIgoANGzagu7sbmzdvxpEjRzT/r/rCMoBbbrkF5eXlePPNN/HGG2/gmWeeATBetXqf1uH9MxFh4cKFsNvtqK+vBwC5s+R/wodS+2w0GuXteWNjY4iLi5NfnkWLFqG4uFiT18GMEvKjjz5CR0cHAKC4uNgnLi8vDy+//DJefPFFJCUlMaW3ePFiWCwW2O12CIKAhx9+GDU1NcjMzMS6deuwZcsW1b/dv38/NmzYgPj4eDz66KNISUnB22+/DQDIysrS7DqiL2NxAtdt5ExCF5ITdCE5QReSE3QhOUEXkhN0ITlBF5ITdCE5QReSE/4LrH7+pe0SUy4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 70x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot performance\n",
    "fig, ax = plt.subplots(figsize=(0.7, 1))\n",
    "df = pd.DataFrame(data=[r2], index=[\"R2\"]).T\n",
    "sns.stripplot(ax=ax, data=df, jitter=0.04, color=\"k\", size=5)\n",
    "\n",
    "# stats precision\n",
    "ax.errorbar(\n",
    "    x=0,\n",
    "    y=np.mean(r2),\n",
    "    yerr=1.96 * np.std(r2) / np.sqrt(len(r2)),  # 95% ci\n",
    "    marker=\"o\",\n",
    "    color=\"orange\",\n",
    "    markeredgecolor=\"w\",\n",
    "    markersize=5,\n",
    "    zorder=np.inf,\n",
    ")\n",
    "\n",
    "# disconnect axes (R style)\n",
    "ax.spines[[\"right\", \"top\"]].set_visible(False)\n",
    "ax.spines[\"bottom\"].set_position((\"axes\", -0.05))\n",
    "ax.yaxis.set_ticks_position(\"left\")\n",
    "ax.spines[\"left\"].set_position((\"axes\", -0.05))\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "# labels\n",
    "ax.set_ylim([0, 0.5])\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.set_xlabel(\"FLR-metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (10s)Train & eval classifier model\n",
    "\n",
    "* z-scoring the features marginally changed the results. So we used the raw data, to produce more interpretable weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_eval(dataset, predictive_metrics, seeds, scale_data=False):\n",
    "\n",
    "    # create model\n",
    "    model = create_classifier_model(predictive_metrics)\n",
    "    print(model)\n",
    "\n",
    "    # evaluate R2\n",
    "    rez_metrics = get_crossval_flclassifier_metrics(\n",
    "        dataset=dataset,\n",
    "        model_formula=model,\n",
    "        split_ratio=0.75,\n",
    "        seeds=seeds,\n",
    "        thresh=0.8,\n",
    "        scale_data=scale_data,\n",
    "    )\n",
    "\n",
    "    # PERFORMANCE -----------------------------\n",
    "\n",
    "    # make arrays\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for m_i in rez_metrics:\n",
    "        precisions.append(m_i[\"precision\"])\n",
    "        recalls.append(m_i[\"recall\"])\n",
    "\n",
    "    # precision\n",
    "    print(\"\\nprecision:\")\n",
    "    print(\"median:\", np.nanmedian(precisions))\n",
    "    print(\"std:\", np.nanstd(precisions))\n",
    "    print(\"95% CI:\", 1.96 * np.std(precisions) / np.sqrt(len(precisions)))\n",
    "\n",
    "    # recall\n",
    "    print(\"\\nrecall:\")\n",
    "    print(\"median r2:\", np.nanmedian(recalls))\n",
    "    print(\"std r2:\", np.nanstd(recalls))\n",
    "    print(\"95% CI:\", 1.96 * np.std(recalls) / np.sqrt(len(recalls)))\n",
    "\n",
    "    # plot performance\n",
    "    _, ax = plt.subplots(figsize=(0.7, 1))\n",
    "    df = pd.DataFrame(data=[precisions, recalls], index=[\"precision\", \"recall\"]).T\n",
    "    sns.stripplot(ax=ax, data=df, jitter=0.04, color=\"k\", size=3)\n",
    "\n",
    "    # stats precision\n",
    "    ax.errorbar(\n",
    "        x=0,\n",
    "        y=np.nanmedian(precisions),\n",
    "        yerr=1.96 * np.std(precisions) / np.sqrt(len(precisions)),  # 95% ci\n",
    "        marker=\"o\",\n",
    "        color=\"orange\",\n",
    "        markeredgecolor=\"w\",\n",
    "        markersize=5,\n",
    "        zorder=np.inf,\n",
    "    )\n",
    "\n",
    "    # stats recall\n",
    "    ax.errorbar(\n",
    "        x=1,\n",
    "        y=np.nanmedian(recalls),\n",
    "        yerr=1.96 * np.std(recalls) / np.sqrt(len(recalls)),  # 95% ci\n",
    "        marker=\"o\",\n",
    "        color=\"orange\",\n",
    "        markeredgecolor=\"w\",\n",
    "        markersize=5,\n",
    "        zorder=np.inf,\n",
    "    )\n",
    "\n",
    "    # disconnect axes (R style)\n",
    "    ax.spines[[\"right\", \"top\"]].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_position((\"axes\", -0.05))\n",
    "    ax.yaxis.set_ticks_position(\"left\")\n",
    "    ax.spines[\"left\"].set_position((\"axes\", -0.05))\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    # labels\n",
    "    ax.set_ylim([0, 1])\n",
    "    return precisions, recalls\n",
    "\n",
    "\n",
    "def interpret_features_weights(model, dataset, predictive_metrics):\n",
    "\n",
    "    model = create_classifier_model(predictive_metrics)\n",
    "    model_result = train_classifier_on_full_dataset(\n",
    "        model_formula=model, dataset=dataset\n",
    "    )\n",
    "    weights = model_result.params\n",
    "\n",
    "    # build table of features contributions  ---------------\n",
    "\n",
    "    # add feature weights\n",
    "    weights_for_df = weights.drop(index=\"Intercept\")\n",
    "    weights_df = weights_for_df.to_frame()\n",
    "    weights_df.columns = [\"weights\"]\n",
    "\n",
    "    # add p-values (fit to entire dataset)\n",
    "    pvalues_df = model_result.pvalues.drop(index=\"Intercept\")\n",
    "    pvalues_df = pvalues_df.to_frame()\n",
    "    pvalues_df.columns = [\"weight p-value\"]\n",
    "    data_df = pd.merge(\n",
    "        weights_df,\n",
    "        pvalues_df,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # interpret interceptsl\n",
    "    print(\"Intercept:\")\n",
    "    print(\"- logodds of detected HQ units:\", weights[\"Intercept\"])\n",
    "    odds = np.exp(weights[\"Intercept\"])\n",
    "    print(\n",
    "        \"- P(Identified HQ units when all features are null):\",\n",
    "        odds / (1 + odds),\n",
    "    )\n",
    "\n",
    "    # interpret all features\n",
    "    odds = np.exp(weights[\"Intercept\"] + data_df[\"weights\"])\n",
    "    data_df[r\"\\Delta accuracy\"] = np.sign(data_df[\"weights\"]) * odds / (1 + odds)\n",
    "\n",
    "    # display\n",
    "    data_df = data_df.sort_values(by=[r\"\\Delta accuracy\"], ascending=False)\n",
    "    display(data_df)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality_label ~ 1  + amplitude_cutoff + firing_range + firing_rate + isi_violations_ratio + rp_contamination + rp_violations + sd_ratio + snr + silhouette + mad_ratio\n",
      "\n",
      "precision:\n",
      "median: 0.8856209150326797\n",
      "std: 0.08616897126454853\n",
      "95% CI: 0.016889118367851515\n",
      "\n",
      "recall:\n",
      "median r2: 0.631578947368421\n",
      "std r2: 0.10248083503608878\n",
      "95% CI: 0.0200862436670734\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 70x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# parameters\n",
    "seeds = np.arange(0, 100, 1)\n",
    "\n",
    "# curate dataset\n",
    "dataset_c = dataset.drop(columns=[\"sorting_accuracy\"])\n",
    "\n",
    "# (10s)train\n",
    "precisions, recalls = train_test_eval(\n",
    "    dataset_c, predictive_metrics, seeds, scale_data=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (190s)Shuffled control\n",
    "\n",
    "* TODO: repeat shuffling for many random seeds. I expect 50% median values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality_label ~ 1  + amplitude_cutoff + firing_range + firing_rate + isi_violations_ratio + rp_contamination + rp_violations + sd_ratio + snr + silhouette + mad_ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/cebraspike3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision:\n",
      "median: 0.0\n",
      "std: 0.20067220368883512\n",
      "95% CI: 0.03933175192301168\n",
      "\n",
      "recall:\n",
      "median r2: 0.0\n",
      "std r2: 0.024859256430534545\n",
      "95% CI: 0.00487241426038477\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 70x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# parameters\n",
    "np.random.seed(0)\n",
    "\n",
    "# shuffle labels\n",
    "dataset_shuff = copy.copy(dataset_c)\n",
    "dataset_shuff[\"quality_label\"] = np.random.permutation(dataset_c[\"quality_label\"])\n",
    "\n",
    "# train\n",
    "precisions, recalls = train_test_eval(dataset_shuff, predictive_metrics, seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret feature weights\n",
    "\n",
    "* an increase of mad_ratio by 0.1 (scale is 1 in the table) increases p(high-quality) by 0.1.\n",
    "* A unit's combination of spike features determines its p(high-quality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:\n",
      "- logodds of detected HQ units: 12.521598874296838\n",
      "- P(Identified HQ units when all features are null): 0.9999963529886038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weights</th>\n",
       "      <th>weight p-value</th>\n",
       "      <th>\\Delta accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>firing_rate</th>\n",
       "      <td>72.815618</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd_ratio</th>\n",
       "      <td>1.743308</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rp_contamination</th>\n",
       "      <td>0.425957</td>\n",
       "      <td>0.782994</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isi_violations_ratio</th>\n",
       "      <td>0.171358</td>\n",
       "      <td>0.096178</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amplitude_cutoff</th>\n",
       "      <td>-20.966553</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>-0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firing_range</th>\n",
       "      <td>-19.537198</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mad_ratio</th>\n",
       "      <td>-9.706410</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.943491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silhouette</th>\n",
       "      <td>-8.279971</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>-0.985820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rp_violations</th>\n",
       "      <td>-0.260581</td>\n",
       "      <td>0.563979</td>\n",
       "      <td>-0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snr</th>\n",
       "      <td>-0.084350</td>\n",
       "      <td>0.115709</td>\n",
       "      <td>-0.999996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        weights  weight p-value  \\Delta accuracy\n",
       "firing_rate           72.815618        0.000002         1.000000\n",
       "sd_ratio               1.743308        0.000024         0.999999\n",
       "rp_contamination       0.425957        0.782994         0.999998\n",
       "isi_violations_ratio   0.171358        0.096178         0.999997\n",
       "amplitude_cutoff     -20.966553        0.005935        -0.000215\n",
       "firing_range         -19.537198        0.000003        -0.000897\n",
       "mad_ratio             -9.706410        0.000003        -0.943491\n",
       "silhouette            -8.279971        0.006290        -0.985820\n",
       "rp_violations         -0.260581        0.563979        -0.999995\n",
       "snr                   -0.084350        0.115709        -0.999996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_data = interpret_features_weights(model, dataset_c, predictive_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight of shuffled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:\n",
      "- logodds of detected HQ units: -0.8024840139997375\n",
      "- P(Identified HQ units when all features are null): 0.30949441509212844\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weights</th>\n",
       "      <th>weight p-value</th>\n",
       "      <th>\\Delta accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>firing_range</th>\n",
       "      <td>1.479585</td>\n",
       "      <td>0.305337</td>\n",
       "      <td>0.663091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amplitude_cutoff</th>\n",
       "      <td>1.433595</td>\n",
       "      <td>0.611767</td>\n",
       "      <td>0.652741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rp_contamination</th>\n",
       "      <td>1.225288</td>\n",
       "      <td>0.161394</td>\n",
       "      <td>0.604154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silhouette</th>\n",
       "      <td>0.261882</td>\n",
       "      <td>0.886839</td>\n",
       "      <td>0.368047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd_ratio</th>\n",
       "      <td>0.054117</td>\n",
       "      <td>0.602051</td>\n",
       "      <td>0.321177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firing_rate</th>\n",
       "      <td>-4.660949</td>\n",
       "      <td>0.367280</td>\n",
       "      <td>-0.004221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rp_violations</th>\n",
       "      <td>-0.639970</td>\n",
       "      <td>0.151716</td>\n",
       "      <td>-0.191166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mad_ratio</th>\n",
       "      <td>-0.126766</td>\n",
       "      <td>0.670735</td>\n",
       "      <td>-0.283077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isi_violations_ratio</th>\n",
       "      <td>-0.006626</td>\n",
       "      <td>0.920851</td>\n",
       "      <td>-0.308080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snr</th>\n",
       "      <td>-0.003650</td>\n",
       "      <td>0.868936</td>\n",
       "      <td>-0.308715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       weights  weight p-value  \\Delta accuracy\n",
       "firing_range          1.479585        0.305337         0.663091\n",
       "amplitude_cutoff      1.433595        0.611767         0.652741\n",
       "rp_contamination      1.225288        0.161394         0.604154\n",
       "silhouette            0.261882        0.886839         0.368047\n",
       "sd_ratio              0.054117        0.602051         0.321177\n",
       "firing_rate          -4.660949        0.367280        -0.004221\n",
       "rp_violations        -0.639970        0.151716        -0.191166\n",
       "mad_ratio            -0.126766        0.670735        -0.283077\n",
       "isi_violations_ratio -0.006626        0.920851        -0.308080\n",
       "snr                  -0.003650        0.868936        -0.308715"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_data = interpret_features_weights(model, dataset_shuff, predictive_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cebraspike3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
