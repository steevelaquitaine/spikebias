"""Pipeline to compute power spectral densities for the Buccino 
model

Method: 

* Welch method
* Buttwerworth temporal filtering
* entire duration of the recordings

Duration: 6 mins

Usage:

    python src/pipes/validation/psd/multiproc_npx_buccino.py
"""

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore")

import os
import sys
import numpy as np
import spikeinterface as si
from concurrent.futures import ProcessPoolExecutor
import spikeinterface.preprocessing as spre
from scipy import signal
import time 
import yaml
import logging
import logging.config


# move to PROJECT PATH
PROJ_PATH = '/home/steeve/steeve/epfl/code/spikebias/'
os.chdir(PROJ_PATH)

# make custom package importable
sys.path.append('.')

from src.nodes.utils import demean

# setup logging
with open("conf/logging.yml", "r", encoding="utf-8") as logging_conf:
    LOG_CONF = yaml.load(logging_conf, Loader=yaml.FullLoader)
logging.config.dictConfig(LOG_CONF)
logger = logging.getLogger("root")

# setup load paths
RAW_PATH = os.path.join(PROJ_PATH, "dataset/00_raw/recording_buccino/")

# setup save paths
RAW_PSD_PATH = os.path.join(PROJ_PATH, "dataset/01_intermediate/psd_raw_npx_buccino.npy")

# layers    
layers = ["L1", "L2_3", "L4", "L5", "L6"]
            
# sampling frequency
SF = 32000

# SETUP WELCH PSD PARAMETERS

FILT_WINDOW = "hann"
FILT_WIND = SF # 1Hz resolution
FILT_OVERL = int(
    FILT_WIND // 1.5
)


def get_site_welch_psd(trace, site):
    """calculate the welch frequency powers in the input trace

    Args:
        traces (np.ndarray): timepoints x sites voltage trace
        sfreq (_type_): voltage trace sampling frequency
        site: silent, automatically generated by ProcessPoolExecutor()

    Returns:
        _type_: _description_
    """
    (freq, power) = signal.welch(
        trace,
        SF,
        window=FILT_WINDOW,
        nperseg=FILT_WIND,
        noverlap=FILT_OVERL,
    )
    return np.array(power), np.array(freq)


def get_welch_psd_parallelized(traces: np.ndarray):
    """compute power spectrum density

    Args:
        traces (np.ndarray): timepoints x sites voltage traces

    Returns:
        dict: frequencies x sites powers array and frequencies array
        
    note: we typically use 72 cores
    """
    # takes 2 min (instead of 70 min w/o multiprocessing)
    nsites = traces.shape[1]

    # compute power for each site trace
    # in parallel with a pool of workers
    with ProcessPoolExecutor() as executor:
        power_by_site = executor.map(
            get_site_welch_psd,
            traces.T,
            np.arange(0, nsites, 1),
        )
    power_by_sites = list(power_by_site)

    # make an array with powers
    powersd = []
    for site in range(nsites):
        powersd.append(power_by_sites[site][0])
    powers = np.array(powersd)

    # store frequency domain
    freqs = power_by_sites[0][1]
    return {"power": powers, "freq": freqs}


def save_psd(data, write_path:str):
    parent_path = os.path.dirname(write_path)
    if not os.path.isdir(parent_path):
        os.makedirs(parent_path)
    np.save(write_path, data)


def main():

    # Load datasets
    t0 = time.time()

    logger.info(f"Started pipeline..")
    
    Raw = si.load_extractor(RAW_PATH)
    Raw= spre.astype(Raw, "int16")
    
    # Remove the DC component by subtracting the means
    raw_traces = demean(Raw.get_traces())
    logger.info(f"Detrended traces.")
    
    # calculate psd
    out_raw = get_welch_psd_parallelized(raw_traces)
    logger.info(f"Calculated PSDs.")

    # save
    save_psd(out_raw, RAW_PSD_PATH)
    logger.info(f"Completed in {np.round(time.time()-t0,2)} secs")


if __name__== "__main__":
    main()