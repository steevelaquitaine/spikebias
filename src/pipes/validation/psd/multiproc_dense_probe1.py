"""Computs power spectral densities of dense probe 1

Uses multiprocessing on a single machine to speed up 
the computation

Usage:

    python src/pipes/validation/psd/multiproc_dense_probe1.py

Returns:
    (.npy): writes power spectral densities

Execution time: 5 mins

"""

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.filterwarnings("ignore")

import os
import sys
import numpy as np
import spikeinterface as si
from concurrent.futures import ProcessPoolExecutor
import spikeinterface.preprocessing as spre
from scipy import signal
import yaml
import logging
import logging.config
import time

# move to PROJECT PATH
PROJ_PATH = '/home/steeve/steeve/epfl/code/spikebias/'
os.chdir(PROJ_PATH)

# add custom package to path
sys.path.append('.')

from src.nodes.utils import demean

# setup logging
with open("conf/logging.yml", "r", encoding="utf-8") as logging_conf:
    LOG_CONF = yaml.load(logging_conf, Loader=yaml.FullLoader)
logging.config.dictConfig(LOG_CONF)
logger = logging.getLogger("root")

# setup load paths
RAW_PATH = os.path.join(PROJ_PATH, "dataset/00_raw/recording_dense_probe1/")

# setup save paths
RAW_PSD_PATH = os.path.join(PROJ_PATH, "dataset/01_intermediate/psd_raw_dense_probe1.npy")

#Â SETUP PARAMETERS
SF = 20000

# SETUP WELCH PSD PARAMETERS *******************
FILT_WINDOW = "hann"

# vivo
FILT_WIND_SIZE = SF # 1Hz freq. resolution
FILT_WIND_OVERLAP = int(
    FILT_WIND_SIZE // 1.5
)

def get_welch_psd_parallelized(traces: np.ndarray):
    """compute power spectrum density
    using parallel computing

    Args:
        traces (np.ndarray): timepoints x sites voltage traces

    Returns:
        dict: frequencies x sites powers arraay and frequencies array
    """
    # takes 2 min (instead of 70 min w/o multiprocessing)
    nsites = traces.shape[1]

    # compute power for each site trace
    # in parallel with a pool of workers
    with ProcessPoolExecutor() as executor:
        power_by_site = executor.map(
            get_site_welch_psd,
            traces.T,
            np.arange(0, nsites, 1),
        )
    power_by_sites = list(power_by_site)

    # make an array with powers
    powersd = []
    for site in range(nsites):
        powersd.append(power_by_sites[site][0])
    powers = np.array(powersd)

    # store frequency domain
    freqs = power_by_sites[0][1]
    return {"power": powers, "freq": freqs}


def get_site_welch_psd(trace, site):
    """calculate the welch frequency powers in the input trace

    Args:
        traces (np.ndarray): timepoints x sites voltage trace
        sfreq (_type_): voltage trace sampling frequency
        site: silent, automatically generated by ProcessPoolExecutor()

    Returns:
        _type_: _description_
    """
    (freq, power) = signal.welch(
        trace,
        SF,
        window=FILT_WINDOW,
        nperseg=FILT_WIND_SIZE,
        noverlap=FILT_WIND_OVERLAP,
    )
    return np.array(power), np.array(freq)


def save_psd(data, write_path: str):
    parent_path = os.path.dirname(write_path)
    if not os.path.isdir(parent_path):
        os.makedirs(parent_path)
    np.save(write_path, data)
    
    
def main():
    
    # Load datasets
    t0 = time.time()

    logger.info(f"Started pipeline")

    # compress from floats to integers
    Raw = si.load_extractor(RAW_PATH)
    Raw = spre.astype(Raw, "int16")
    logger.info("Compressed traces")

    # select sites in cortex
    layers = ["L1", "L2_3"]
    sites = Raw.get_property("layers")
    sites = [
        "L2_3" if l_i == "L2" or l_i == "L3" else l_i for l_i in sites
    ]
    sites = np.where(np.isin(sites, layers))[0]

    #- Remove DC component by subtracting the mean
    raw_traces = demean(Raw.get_traces()[:, sites])
    logger.info("Detrended")

    # compute psd
    out_raw = get_welch_psd_parallelized(raw_traces)
    logger.info("Computed PSD for raw traces")

    # save
    save_psd(out_raw, RAW_PSD_PATH)
   
    logger.info(f"Completed in {np.round(time.time()-t0,2)} secs")


if __name__ == "__main__":
    main()