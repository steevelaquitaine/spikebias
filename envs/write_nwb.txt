
# author: steeve.laquitaine@epfl.ch
#
# most recent environment:
# - Kilsort 4
# - ability to disable preprocessing
#
# 1. Install python3.9
#   
#   module purge
#   module load archive/2022-09 # load old archive (no need to use spack)
#   module load python-dev/0.4 # load python 3.9
#
# 2. Setup a virtual env "write_nwb":
#
#   # if you use vscode, clear vscode automatic settings, this prevents 
#   # an env to automatically associate with the project you open in vscode
#   rm -rf  /gpfs/bbp.cscs.ch/home/laquitai/.vscode-server 
#
#   # create your working python3.9 environment
#   mkdir /gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs # create envs folder
#   python3.9 -m venv /gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/write_nwb 
#
#   # restart the node here, else pip freeze will not show the content of your newly created python env
#   # but the content of the base environment. Actiavet environment. pip freeze should display nothing.
#   source /gpfs/bbp.cscs.ch/project/proj85/laquitai/spikebias_paper/envs/write_nwb/bin/activate
#   pip install -r /gpfs/bbp.cscs.ch/project/proj85/home/laquitai/spikebias/envs/write_nwb.txt
#
# 3. Install bluepy
#
#   pip install /gpfs/bbp.cscs.ch/project/proj85/home/laquitai/spikebias/assets/bluepy-configfile/
#   cd /gpfs/bbp.cscs.ch/project/proj85/home/laquitai/spikebias/assets/bluepy/
#   git checkout lfp-reports  # checkout the lfp package
#   python3.9 -m pip install . #Â install
#   cd /gpfs/bbp.cscs.ch/project/proj85/home/laquitai/spikebias/
#
#   # the env get automatically associated with the project after it is selected as interpreter 
#   # and selected as kernel the first time to a jupyter 
#   # notebook
#

# nwb
pynwb==2.8.2                # read nwb datasets
neuroconv                   # convert dataset to nwb 

# jupyter notebook
ipykernel===6.29.5                   
ipywidgets==8.0.6           # version important; or notebook and bluepy fail
jupyter==1.0.0              # version important: or notebook and and bluepy fail

# data wrangling
pandas==1.5.2               # version important; bluepy fails with 1.5.3

# config
pyyaml                      # read yaml config files

# h5 files
tables                      # read h5 files

# machine learning and stats
scikit-learn                # machine learning
statsmodels                 # stats
networkx

# plotting
seaborn                     # plotting
matplotlib==3.8.4           # plotting

# simulations
MEAutility==1.5.1           # simulate recording probes
PyWavelets==1.6.0
neurom[plotly]              # simulate cell morphologies
tmd                         # simulate cell morphologies
wget                        # simulate cell morphologies
spikeinterface==0.101.2     # contains the newly released spikeinterface to enable the use of neuroconv
numpy                       # 1.26.4
herdingspikes==0.3.102      # spike sorter
kilosort==4.0.6             # spike sorter install Kilosort 4.0
# git+https://github.com/SpikeInterface/spikeinterface.git@refs/pull/2827/merge
scikit-posthocs==0.9.0      # posthoc statistics
mpi4py-mpich                # distributed computing on multiple computer nodes
numba==0.59.1               # parallelized computing
fastparquet==2024.11.0      # save metadata
pyarrow                     # save metadata

# for spike clustering [TODO: to add]
umap-learn==0.5.3
python-louvain==0.16

# on dandihub
remfile