# Setup python virtual environment for cebraspike pipeline
#
# author: steeve.laquitaine@epfl.ch
#
# Duration: 5 min
#
# TODO: list all dependencies and subdependencies with their versions
# to bypass the search for compatibility. Else this can take a while.
#
# 1. Setup a spack environment with python 3.9:
#
#   module purge
#   module load spack
#   . /gpfs/bbp.cscs.ch/ssd/apps/bsd/2024-02-01/spack/share/spack/setup-env.sh
#   # spack reindex
#   # spack env create spack_python3_9 envs/spack_python3_9.yaml
#   spack env activate spack_python3_9 -p
#   # spack install

# 2. Setup cebraspike virtual environment:
# 
#   mkdir /gpfs/bbp.cscs.ch/project/proj85/scratch/laquitai/preprint_2024/envs # create envs folder
#   python3.9 -m venv /gpfs/bbp.cscs.ch/project/proj85/scratch/laquitai/preprint_2024/envs/cebraspike3 # create env
#   source /gpfs/bbp.cscs.ch/project/proj85/scratch/laquitai/preprint_2024/envs/cebraspike3/bin/activate
#   python3.9 -m pip install -r /gpfs/bbp.cscs.ch/project/proj85/home/laquitai/spikebias/envs/cebraspike.txt
#
# 3. install cebra at the end

pynwb==2.8.2                # read nwb datasets
ipykernel==6.29.5           # setup notebook  
ipywidgets==8.0.6           # version important; or notebook and bluepy fail
jupyter==1.0.0              # version important: or notebook and and bluepy fail
pandas==1.3.4               # version important; bluepy fails with 1.5.3, works with 1.5.2
pyyaml==6.0.2               # setup config
scikit-learn==1.5.2         # machine learning
networkx==3.2.1             # graph machine learning
spikeinterface==0.100.5     # analysis and spike sorting of extracellular recordings
matplotlib==3.9.2           # plotting
ipython-autotime==0.3.2     # time track colab notebook cells
cebra==0.4.0
seaborn==0.13.2             # plotting
numba==0.60.0               # parallel computing
#--pre                       
#cebra[datasets,demos]      # dimensionality reduction
statsmodels==0.14.2         # baseline models