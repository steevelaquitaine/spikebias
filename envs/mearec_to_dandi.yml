# author: laquitainesteeve@gmail.com
# 
# purpose: create mearec_to_dandi virtual environment, dandi package requires at least python 3.10.8 and is not compatible with python 3.9.7 used by the spikebias package.
# 
# usage: 
#
# 1. move to repo and create env with $ mamba env create -f envs/mearec_to_dandi.yml --prefix envs/mearec_to_dandi
# 2. activate env: $ mamba activate envs/mearec_to_dandi

name: demo
channels:
  - conda-forge
dependencies:
  - python=3.10.8              # version >=3.10.8 required by dandi
  - pynwb=3.0.0                # read nwb files
  - ipykernel=6.29.5           # jupyter notebook                   
  - matplotlib=3.8.4           # plotting  
  - nwbinspector=0.6.3         # validate nwb file
  - scikit-posthocs=0.9.0      # post-hoc tests 
  - pytorch=2.4.0              # pytorch on cpu only
  - numpy=2.1                  # numerical computing, version<=2.1 required by umap
  - scikit-learn=1.6.1         # machine learning  
  - umap-learn=0.5.3           # machine learning: spike waveform clustering
  - python-louvain=0.16        # machine learning: Louvain community detection
  - pip:
    - spikeinterface==0.101.2 # newly released compatible with neuroconv (spikebias works with 0.100.5, not compatible with neuroconv)
    - dandi==0.69.3            # download and upload nwb files to dandi archive cloud
    - neuroconv==0.6.5        # to convert spikeinterface extractors to nwb, compatible with spikeinterface >= 0.101.2
    - remfile==0.1.13         # to read rem files
    - hdmf==4.1.0
    - hdmf-zarr==0.11.1
    - mearec==1.8.0